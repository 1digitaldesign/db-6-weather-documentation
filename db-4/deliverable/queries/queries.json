{
  "source_file": "db-4/queries/queries.md",
  "extraction_timestamp": "20260209-2337",
  "total_queries": 30,
  "queries": [
    {
      "number": 1,
      "title": "Multi-Window Time-Series Analysis with Rolling Aggregates",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for multi-window time-series analysis with rolling aggregates.",
      "use_case": "Business analytics for multi-window time-series analysis with rolling aggregates",
      "business_value": "Actionable insights from multi-window time-series analysis with rolling aggregates",
      "purpose": "Production multi-window time-series analysis with rolling aggregates analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 60\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2
    },
    {
      "number": 2,
      "title": "Segmentation Analysis with Decile Ranking",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for segmentation analysis with decile ranking.",
      "use_case": "Business analytics for segmentation analysis with decile ranking",
      "business_value": "Actionable insights from segmentation analysis with decile ranking",
      "purpose": "Production segmentation analysis with decile ranking analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 70\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 83
    },
    {
      "number": 3,
      "title": "Performance Quartile Distribution",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for performance quartile distribution.",
      "use_case": "Business analytics for performance quartile distribution",
      "business_value": "Actionable insights from performance quartile distribution",
      "purpose": "Production performance quartile distribution analysis",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 80\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 164
    },
    {
      "number": 4,
      "title": "Revenue Distribution by Category",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for revenue distribution by category.",
      "use_case": "Business analytics for revenue distribution by category",
      "business_value": "Actionable insights from revenue distribution by category",
      "purpose": "Production revenue distribution by category analysis",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 90\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 245
    },
    {
      "number": 5,
      "title": "Velocity and Acceleration Metrics",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for velocity and acceleration metrics.",
      "use_case": "Business analytics for velocity and acceleration metrics",
      "business_value": "Actionable insights from velocity and acceleration metrics",
      "purpose": "Production velocity and acceleration metrics analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 100\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 326
    },
    {
      "number": 6,
      "title": "Hourly Pattern Detection and Clustering",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for hourly pattern detection and clustering.",
      "use_case": "Business analytics for hourly pattern detection and clustering",
      "business_value": "Actionable insights from hourly pattern detection and clustering",
      "purpose": "Production hourly pattern detection and clustering analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 110\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 407
    },
    {
      "number": 7,
      "title": "Gap Analysis with Sequential Difference",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for gap analysis with sequential difference.",
      "use_case": "Business analytics for gap analysis with sequential difference",
      "business_value": "Actionable insights from gap analysis with sequential difference",
      "purpose": "Production gap analysis with sequential difference analysis",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 120\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 488
    },
    {
      "number": 8,
      "title": "Anomaly Detection Using Z-Score Windows",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for anomaly detection using z-score windows.",
      "use_case": "Business analytics for anomaly detection using z-score windows",
      "business_value": "Actionable insights from anomaly detection using z-score windows",
      "purpose": "Production anomaly detection using z-score windows analysis",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 130\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 569
    },
    {
      "number": 9,
      "title": "Recency-Frequency-Monetary Scoring",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for recency-frequency-monetary scoring.",
      "use_case": "Business analytics for recency-frequency-monetary scoring",
      "business_value": "Actionable insights from recency-frequency-monetary scoring",
      "purpose": "Production recency-frequency-monetary scoring analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 140\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 650
    },
    {
      "number": 10,
      "title": "Multi-Period Cohort Retention Analysis",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for multi-period cohort retention analysis.",
      "use_case": "Business analytics for multi-period cohort retention analysis",
      "business_value": "Actionable insights from multi-period cohort retention analysis",
      "purpose": "Production multi-period cohort retention analysis analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 150\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 731
    },
    {
      "number": 11,
      "title": "Second-Order Derivative Computation",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for second-order derivative computation.",
      "use_case": "Business analytics for second-order derivative computation",
      "business_value": "Actionable insights from second-order derivative computation",
      "purpose": "Production second-order derivative computation analysis",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 160\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 812
    },
    {
      "number": 12,
      "title": "Cross-Category Benchmarking with Percentiles",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for cross-category benchmarking with percentiles.",
      "use_case": "Business analytics for cross-category benchmarking with percentiles",
      "business_value": "Actionable insights from cross-category benchmarking with percentiles",
      "purpose": "Production cross-category benchmarking with percentiles analysis",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 170\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 893
    },
    {
      "number": 13,
      "title": "Exponentially Weighted Moving Average",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for exponentially weighted moving average.",
      "use_case": "Business analytics for exponentially weighted moving average",
      "business_value": "Actionable insights from exponentially weighted moving average",
      "purpose": "Production exponentially weighted moving average analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 180\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 974
    },
    {
      "number": 14,
      "title": "Peak Period Identification and Efficiency",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for peak period identification and efficiency.",
      "use_case": "Business analytics for peak period identification and efficiency",
      "business_value": "Actionable insights from peak period identification and efficiency",
      "purpose": "Production peak period identification and efficiency analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 190\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1055
    },
    {
      "number": 15,
      "title": "Lifetime Value Estimation Model",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for lifetime value estimation model.",
      "use_case": "Business analytics for lifetime value estimation model",
      "business_value": "Actionable insights from lifetime value estimation model",
      "purpose": "Production lifetime value estimation model analysis",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 200\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1136
    },
    {
      "number": 16,
      "title": "Year-over-Year Growth Rate Analysis",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for year-over-year growth rate analysis.",
      "use_case": "Business analytics for year-over-year growth rate analysis",
      "business_value": "Actionable insights from year-over-year growth rate analysis",
      "purpose": "Production year-over-year growth rate analysis analysis",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 210\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1217
    },
    {
      "number": 17,
      "title": "Heatmap Data Generation by Time Dimensions",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for heatmap data generation by time dimensions.",
      "use_case": "Business analytics for heatmap data generation by time dimensions",
      "business_value": "Actionable insights from heatmap data generation by time dimensions",
      "purpose": "Production heatmap data generation by time dimensions analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 220\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1298
    },
    {
      "number": 18,
      "title": "Running Percentile Distribution Computation",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for running percentile distribution computation.",
      "use_case": "Business analytics for running percentile distribution computation",
      "business_value": "Actionable insights from running percentile distribution computation",
      "purpose": "Production running percentile distribution computation analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 230\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1379
    },
    {
      "number": 19,
      "title": "Cross-Correlation Pattern Analysis",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for cross-correlation pattern analysis.",
      "use_case": "Business analytics for cross-correlation pattern analysis",
      "business_value": "Actionable insights from cross-correlation pattern analysis",
      "purpose": "Production cross-correlation pattern analysis analysis",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 240\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1460
    },
    {
      "number": 20,
      "title": "Forensic Analysis of Status Transitions",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for forensic analysis of status transitions.",
      "use_case": "Business analytics for forensic analysis of status transitions",
      "business_value": "Actionable insights from forensic analysis of status transitions",
      "purpose": "Production forensic analysis of status transitions analysis",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 250\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1541
    },
    {
      "number": 21,
      "title": "Multi-Metric Dashboard Aggregation Pipeline",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for multi-metric dashboard aggregation pipeline.",
      "use_case": "Business analytics for multi-metric dashboard aggregation pipeline",
      "business_value": "Actionable insights from multi-metric dashboard aggregation pipeline",
      "purpose": "Production multi-metric dashboard aggregation pipeline analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 260\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1622
    },
    {
      "number": 22,
      "title": "Sequential Pattern Mining with Windows",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for sequential pattern mining with windows.",
      "use_case": "Business analytics for sequential pattern mining with windows",
      "business_value": "Actionable insights from sequential pattern mining with windows",
      "purpose": "Production sequential pattern mining with windows analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 270\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1703
    },
    {
      "number": 23,
      "title": "Concentration Index Computation",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for concentration index computation.",
      "use_case": "Business analytics for concentration index computation",
      "business_value": "Actionable insights from concentration index computation",
      "purpose": "Production concentration index computation analysis",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 280\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1784
    },
    {
      "number": 24,
      "title": "Statistical Anomaly Score Assignment",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for statistical anomaly score assignment.",
      "use_case": "Business analytics for statistical anomaly score assignment",
      "business_value": "Actionable insights from statistical anomaly score assignment",
      "purpose": "Production statistical anomaly score assignment analysis",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 290\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1865
    },
    {
      "number": 25,
      "title": "Fiscal Period Comparative Reporting",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for fiscal period comparative reporting.",
      "use_case": "Business analytics for fiscal period comparative reporting",
      "business_value": "Actionable insights from fiscal period comparative reporting",
      "purpose": "Production fiscal period comparative reporting analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 300\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1946
    },
    {
      "number": 26,
      "title": "Throughput Optimization Metrics",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for throughput optimization metrics.",
      "use_case": "Business analytics for throughput optimization metrics",
      "business_value": "Actionable insights from throughput optimization metrics",
      "purpose": "Production throughput optimization metrics analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 310\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2027
    },
    {
      "number": 27,
      "title": "Cumulative Trend Analysis Pipeline",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for cumulative trend analysis pipeline.",
      "use_case": "Business analytics for cumulative trend analysis pipeline",
      "business_value": "Actionable insights from cumulative trend analysis pipeline",
      "purpose": "Production cumulative trend analysis pipeline analysis",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 320\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2108
    },
    {
      "number": 28,
      "title": "Multi-Dimensional Pivot Aggregation",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for multi-dimensional pivot aggregation.",
      "use_case": "Business analytics for multi-dimensional pivot aggregation",
      "business_value": "Actionable insights from multi-dimensional pivot aggregation",
      "purpose": "Production multi-dimensional pivot aggregation analysis",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 330\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2189
    },
    {
      "number": 29,
      "title": "Funnel Stage Progression Tracking",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for funnel stage progression tracking.",
      "use_case": "Business analytics for funnel stage progression tracking",
      "business_value": "Actionable insights from funnel stage progression tracking",
      "purpose": "Production funnel stage progression tracking analysis",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 340\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2270
    },
    {
      "number": 30,
      "title": "Outlier Detection with IQR Method",
      "description": "Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for outlier detection with iqr method.",
      "use_case": "Business analytics for outlier detection with iqr method",
      "business_value": "Actionable insights from outlier detection with iqr method",
      "purpose": "Production outlier detection with iqr method analysis",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 350\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2351
    }
  ]
}