{
  "source_file": "/Users/machine/Documents/AQ/db/db-4/queries/queries.md",
  "extraction_timestamp": "20260210-0118",
  "total_queries": 30,
  "queries": [
    {
      "number": 1,
      "title": "Multi-Window Time-Series Analysis with Rolling Aggregates",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for multi-window time-series analysis with rolling aggregates. Use Case: Business analytics for multi-window time-series analysis with rolling aggregates Business Value: Actionable insights from multi-window time-series analysis with rolling aggregates Purpose: Production multi-window time-series analysis with rolling aggregates analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, d",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 60\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2
    },
    {
      "number": 2,
      "title": "Segmentation Analysis with Decile Ranking",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for segmentation analysis with decile ranking. Use Case: Business analytics for segmentation analysis with decile ranking Business Value: Actionable insights from segmentation analysis with decile ranking Purpose: Production segmentation analysis with decile ranking analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by w",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 70\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 83
    },
    {
      "number": 3,
      "title": "Performance Quartile Distribution",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for performance quartile distribution. Use Case: Business analytics for performance quartile distribution Business Value: Actionable insights from performance quartile distribution Purpose: Production performance quartile distribution analysis Complexity: 4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and name",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 80\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 164
    },
    {
      "number": 4,
      "title": "Revenue Distribution by Category",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for revenue distribution by category. Use Case: Business analytics for revenue distribution by category Business Value: Actionable insights from revenue distribution by category Purpose: Production revenue distribution by category analysis Complexity: 4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and user_id",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 90\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 245
    },
    {
      "number": 5,
      "title": "Velocity and Acceleration Metrics",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for velocity and acceleration metrics. Use Case: Business analytics for velocity and acceleration metrics Business Value: Actionable insights from velocity and acceleration metrics Purpose: Production velocity and acceleration metrics analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by week and name",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 100\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 326
    },
    {
      "number": 6,
      "title": "Hourly Pattern Detection and Clustering",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for hourly pattern detection and clustering. Use Case: Business analytics for hourly pattern detection and clustering Business Value: Actionable insights from hourly pattern detection and clustering Purpose: Production hourly pattern detection and clustering analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and us",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 110\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 407
    },
    {
      "number": 7,
      "title": "Gap Analysis with Sequential Difference",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for gap analysis with sequential difference. Use Case: Business analytics for gap analysis with sequential difference Business Value: Actionable insights from gap analysis with sequential difference Purpose: Production gap analysis with sequential difference analysis Complexity: 4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month an",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 120\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 488
    },
    {
      "number": 8,
      "title": "Anomaly Detection Using Z-Score Windows",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for anomaly detection using z-score windows. Use Case: Business analytics for anomaly detection using z-score windows Business Value: Actionable insights from anomaly detection using z-score windows Purpose: Production anomaly detection using z-score windows analysis Complexity: 4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and us",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 130\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 569
    },
    {
      "number": 9,
      "title": "Recency-Frequency-Monetary Scoring",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for recency-frequency-monetary scoring. Use Case: Business analytics for recency-frequency-monetary scoring Business Value: Actionable insights from recency-frequency-monetary scoring Purpose: Production recency-frequency-monetary scoring analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by week and name",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 140\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 650
    },
    {
      "number": 10,
      "title": "Multi-Period Cohort Retention Analysis",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for multi-period cohort retention analysis. Use Case: Business analytics for multi-period cohort retention analysis Business Value: Actionable insights from multi-period cohort retention analysis Purpose: Production multi-period cohort retention analysis analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and us",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 150\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 731
    },
    {
      "number": 11,
      "title": "Second-Order Derivative Computation",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for second-order derivative computation. Use Case: Business analytics for second-order derivative computation Business Value: Actionable insights from second-order derivative computation Purpose: Production second-order derivative computation analysis Complexity: 4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and name",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 160\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 812
    },
    {
      "number": 12,
      "title": "Cross-Category Benchmarking with Percentiles",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for cross-category benchmarking with percentiles. Use Case: Business analytics for cross-category benchmarking with percentiles Business Value: Actionable insights from cross-category benchmarking with percentiles Purpose: Production cross-category benchmarking with percentiles analysis Complexity: 4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics ",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 170\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 893
    },
    {
      "number": 13,
      "title": "Exponentially Weighted Moving Average",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for exponentially weighted moving average. Use Case: Business analytics for exponentially weighted moving average Business Value: Actionable insights from exponentially weighted moving average Purpose: Production exponentially weighted moving average analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and name",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 180\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 974
    },
    {
      "number": 14,
      "title": "Peak Period Identification and Efficiency",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for peak period identification and efficiency. Use Case: Business analytics for peak period identification and efficiency Business Value: Actionable insights from peak period identification and efficiency Purpose: Production peak period identification and efficiency analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by da",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 190\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1055
    },
    {
      "number": 15,
      "title": "Lifetime Value Estimation Model",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for lifetime value estimation model. Use Case: Business analytics for lifetime value estimation model Business Value: Actionable insights from lifetime value estimation model Purpose: Production lifetime value estimation model analysis Complexity: 4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by week and name",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 200\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1136
    },
    {
      "number": 16,
      "title": "Year-over-Year Growth Rate Analysis",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for year-over-year growth rate analysis. Use Case: Business analytics for year-over-year growth rate analysis Business Value: Actionable insights from year-over-year growth rate analysis Purpose: Production year-over-year growth rate analysis analysis Complexity: 4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and user_id",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 210\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1217
    },
    {
      "number": 17,
      "title": "Heatmap Data Generation by Time Dimensions",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for heatmap data generation by time dimensions. Use Case: Business analytics for heatmap data generation by time dimensions Business Value: Actionable insights from heatmap data generation by time dimensions Purpose: Production heatmap data generation by time dimensions analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped b",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 220\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1298
    },
    {
      "number": 18,
      "title": "Running Percentile Distribution Computation",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for running percentile distribution computation. Use Case: Business analytics for running percentile distribution computation Business Value: Actionable insights from running percentile distribution computation Purpose: Production running percentile distribution computation analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grou",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 230\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1379
    },
    {
      "number": 19,
      "title": "Cross-Correlation Pattern Analysis",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for cross-correlation pattern analysis. Use Case: Business analytics for cross-correlation pattern analysis Business Value: Actionable insights from cross-correlation pattern analysis Purpose: Production cross-correlation pattern analysis analysis Complexity: 4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and name",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 240\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1460
    },
    {
      "number": 20,
      "title": "Forensic Analysis of Status Transitions",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for forensic analysis of status transitions. Use Case: Business analytics for forensic analysis of status transitions Business Value: Actionable insights from forensic analysis of status transitions Purpose: Production forensic analysis of status transitions analysis Complexity: 4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and us",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 250\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1541
    },
    {
      "number": 21,
      "title": "Multi-Metric Dashboard Aggregation Pipeline",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for multi-metric dashboard aggregation pipeline. Use Case: Business analytics for multi-metric dashboard aggregation pipeline Business Value: Actionable insights from multi-metric dashboard aggregation pipeline Purpose: Production multi-metric dashboard aggregation pipeline analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grou",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 260\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1622
    },
    {
      "number": 22,
      "title": "Sequential Pattern Mining with Windows",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for sequential pattern mining with windows. Use Case: Business analytics for sequential pattern mining with windows Business Value: Actionable insights from sequential pattern mining with windows Purpose: Production sequential pattern mining with windows analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and us",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 270\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1703
    },
    {
      "number": 23,
      "title": "Concentration Index Computation",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for concentration index computation. Use Case: Business analytics for concentration index computation Business Value: Actionable insights from concentration index computation Purpose: Production concentration index computation analysis Complexity: 4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and name",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 280\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1784
    },
    {
      "number": 24,
      "title": "Statistical Anomaly Score Assignment",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for statistical anomaly score assignment. Use Case: Business analytics for statistical anomaly score assignment Business Value: Actionable insights from statistical anomaly score assignment Purpose: Production statistical anomaly score assignment analysis Complexity: 4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by week and user_id",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 290\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1865
    },
    {
      "number": 25,
      "title": "Fiscal Period Comparative Reporting",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for fiscal period comparative reporting. Use Case: Business analytics for fiscal period comparative reporting Business Value: Actionable insights from fiscal period comparative reporting Purpose: Production fiscal period comparative reporting analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and name",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 7 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 300\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(5) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.name\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 1946
    },
    {
      "number": 26,
      "title": "Throughput Optimization Metrics",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for throughput optimization metrics. Use Case: Business analytics for throughput optimization metrics Business Value: Actionable insights from throughput optimization metrics Purpose: Production throughput optimization metrics analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and user_id",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 310\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(6) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2027
    },
    {
      "number": 27,
      "title": "Cumulative Trend Analysis Pipeline",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for cumulative trend analysis pipeline. Use Case: Business analytics for cumulative trend analysis pipeline Business Value: Actionable insights from cumulative trend analysis pipeline Purpose: Production cumulative trend analysis pipeline analysis Complexity: 4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by week and name",
      "complexity": "4 CTEs, 9 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 320\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(7) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.name\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2108
    },
    {
      "number": 28,
      "title": "Multi-Dimensional Pivot Aggregation",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and month-level grouping for multi-dimensional pivot aggregation. Use Case: Business analytics for multi-dimensional pivot aggregation Business Value: Actionable insights from multi-dimensional pivot aggregation Purpose: Production multi-dimensional pivot aggregation analysis Complexity: 4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by month and user_id",
      "complexity": "4 CTEs, 6 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by month and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 330\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(8) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('month', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('month', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 2\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2189
    },
    {
      "number": 29,
      "title": "Funnel Stage Progression Tracking",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and day-level grouping for funnel stage progression tracking. Use Case: Business analytics for funnel stage progression tracking Business Value: Actionable insights from funnel stage progression tracking Purpose: Production funnel stage progression tracking analysis Complexity: 4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by day and name",
      "complexity": "4 CTEs, 7 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by day and name",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY name ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.name) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.name ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 340\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.name ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.name) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.name) AS partition_stddev,\n        NTILE(9) OVER (PARTITION BY c2.name ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.name ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('day', c4.created_at) AS period,\n    c4.name,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('day', c4.created_at), c4.name\nHAVING COUNT(*) >= 3\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2270
    },
    {
      "number": 30,
      "title": "Outlier Detection with IQR Method",
      "description": "Description: Uses 4 CTEs with window functions, statistical aggregations, and week-level grouping for outlier detection with iqr method. Use Case: Business analytics for outlier detection with iqr method Business Value: Actionable insights from outlier detection with iqr method Purpose: Production outlier detection with iqr method analysis Complexity: 4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic Expected Output: Aggregated metrics grouped by week and user_id",
      "complexity": "4 CTEs, 8 window functions, GROUP BY with HAVING, date arithmetic",
      "expected_output": "Aggregated metrics grouped by week and user_id",
      "sql": "WITH cte_level_1 AS (\n    SELECT \n        *,\n        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n        DATE_TRUNC('day', created_at) AS day_bucket,\n        DATE_TRUNC('week', created_at) AS week_bucket,\n        EXTRACT(HOUR FROM created_at) AS hour_val,\n        EXTRACT(DOW FROM created_at) AS dow_val\n    FROM models\n    WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '365 days'\n),\ncte_level_2 AS (\n    SELECT\n        c1.*,\n        COUNT(*) OVER (PARTITION BY c1.day_bucket, c1.user_id) AS daily_partition_count,\n        AVG(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS rolling_avg,\n        SUM(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum,\n        FIRST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at) AS first_val,\n        LAST_VALUE(c1.id) OVER (PARTITION BY c1.user_id ORDER BY c1.created_at ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_val\n    FROM cte_level_1 c1\n    WHERE c1.rn <= 350\n),\ncte_level_3 AS (\n    SELECT\n        c2.*,\n        LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS prev_value,\n        LEAD(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS next_value,\n        c2.id - LAG(c2.id, 1) OVER (PARTITION BY c2.user_id ORDER BY c2.created_at) AS delta_value,\n        AVG(c2.id) OVER (PARTITION BY c2.user_id) AS partition_avg,\n        STDDEV(c2.id) OVER (PARTITION BY c2.user_id) AS partition_stddev,\n        NTILE(4) OVER (PARTITION BY c2.user_id ORDER BY c2.id) AS ntile_bucket,\n        RANK() OVER (PARTITION BY c2.day_bucket ORDER BY c2.id DESC) AS daily_rank\n    FROM cte_level_2 c2\n),\ncte_level_4 AS (\n    SELECT\n        c3.*,\n        CASE \n            WHEN c3.partition_stddev > 0 THEN (c3.id - c3.partition_avg) / c3.partition_stddev\n            ELSE 0 \n        END AS z_score,\n        DENSE_RANK() OVER (ORDER BY c3.cumulative_sum DESC) AS overall_rank,\n        PERCENT_RANK() OVER (PARTITION BY c3.user_id ORDER BY c3.id) AS pct_rank,\n        CASE\n            WHEN c3.delta_value > 0 THEN 'Increasing'\n            WHEN c3.delta_value < 0 THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS trend_direction\n    FROM cte_level_3 c3\n)\nSELECT\n    DATE_TRUNC('week', c4.created_at) AS period,\n    c4.user_id,\n    COUNT(*) AS record_count,\n    AVG(c4.id) AS avg_value,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY c4.id) AS q1_value,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY c4.id) AS median_value,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY c4.id) AS q3_value,\n    STDDEV(c4.id) AS stddev_value,\n    MIN(c4.id) AS min_value,\n    MAX(c4.id) AS max_value,\n    SUM(CASE WHEN c4.z_score > 2 THEN 1 ELSE 0 END) AS outlier_count,\n    SUM(CASE WHEN c4.trend_direction = 'Increasing' THEN 1 ELSE 0 END) AS increasing_count,\n    AVG(c4.rolling_avg) AS avg_rolling,\n    MAX(c4.cumulative_sum) AS max_cumulative\nFROM cte_level_4 c4\nGROUP BY DATE_TRUNC('week', c4.created_at), c4.user_id\nHAVING COUNT(*) >= 1\nORDER BY period DESC, avg_value DESC\nLIMIT 100",
      "line_number": 2351
    }
  ]
}