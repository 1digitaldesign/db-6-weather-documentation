{
  "source_file": "/Users/machine/Documents/AQ/db/db-1/queries/queries.md",
  "extraction_timestamp": "20260203-2148",
  "total_queries": 30,
  "queries": [
    {
      "number": 1,
      "title": "Production-Grade User Activity Analysis with Deep CTE Nesting and Cohort Analytics",
      "description": "Description: Enterprise-level user activity analysis with cohort segmentation, retention metrics, engagement scoring, and advanced window function analytics. Demonstrates production-grade SQL patterns used by platforms like Slack, Discord, and Microsoft Teams. Complexity: Deep nested CTEs (5+ levels), cohort analysis, retention metrics, engagement scoring, complex window functions with multiple frame clauses, percentile calculations, time-series analysis",
      "complexity": "Deep nested CTEs (5+ levels), cohort analysis, retention metrics, engagement scoring, complex window functions with multiple frame clauses, percentile calculations, time-series analysis",
      "expected_output": "Query results",
      "sql": "WITH user_registration_cohorts AS (\n    -- First CTE: Identify user registration cohorts\n    SELECT\n        p.id AS user_id,\n        p.username,\n        DATE_TRUNC('month', p.created_at) AS registration_month,\n        EXTRACT(YEAR FROM p.created_at) AS registration_year,\n        EXTRACT(MONTH FROM p.created_at) AS registration_month_num,\n        p.created_at AS created_at\n    FROM profiles p\n),\nuser_message_activity AS (\n    -- Second CTE: Aggregate message activity with time windows\n    SELECT\n        umc.user_id,\n        umc.username,\n        umc.registration_month,\n        umc.registration_year,\n        umc.registration_month_num,\n        COUNT(DISTINCT m.chat_id) AS active_chats,\n        COUNT(m.id) AS total_messages,\n        COUNT(CASE WHEN m.is_ai = false THEN 1 END) AS user_messages,\n        COUNT(CASE WHEN m.is_ai = true THEN 1 END) AS ai_responses,\n        COUNT(DISTINCT DATE(m.created_at)) AS active_days,\n        MIN(m.created_at) AS first_message_date,\n        MAX(m.created_at) AS last_message_date,\n        EXTRACT(EPOCH FROM (MAX(m.created_at) - MIN(m.created_at))) / 86400 AS message_span_days,\n        AVG(CASE WHEN m.is_ai = false THEN LENGTH(m.content) ELSE NULL END) AS avg_user_message_length,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY CASE WHEN m.is_ai = false THEN LENGTH(m.content) ELSE NULL END) AS median_user_message_length\n    FROM user_registration_cohorts umc\n    LEFT JOIN messages m ON umc.user_id = m.sender_id\n    GROUP BY umc.user_id, umc.username, umc.registration_month, umc.registration_year, umc.registration_month_num\n),\nuser_engagement_metrics AS (\n    -- Third CTE: Calculate engagement metrics with window functions\n    SELECT\n        uma.user_id,\n        uma.username,\n        uma.registration_month,\n        uma.active_chats,\n        uma.total_messages,\n        uma.user_messages,\n        uma.ai_responses,\n        uma.active_days,\n        uma.message_span_days,\n        uma.avg_user_message_length,\n        uma.median_user_message_length,\n        CASE\n            WHEN uma.message_span_days > 0 THEN uma.active_days::numeric / uma.message_span_days\n            ELSE 0\n        END AS daily_activity_rate,\n        CASE\n            WHEN uma.active_chats > 0 THEN uma.total_messages::numeric / uma.active_chats\n            ELSE 0\n        END AS messages_per_chat,\n        CASE\n            WHEN uma.user_messages > 0 THEN uma.ai_responses::numeric / uma.user_messages\n            ELSE 0\n        END AS ai_response_ratio,\n        -- Time-based engagement: days since last activity\n        EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - uma.last_message_date)) / 86400 AS days_since_last_activity\n    FROM user_message_activity uma\n),\ncohort_median_calculation AS (\n    -- Calculate medians separately using subqueries\n    SELECT\n        registration_month,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY total_messages) AS cohort_median_messages\n    FROM user_engagement_metrics\n    GROUP BY registration_month\n),\noverall_median_calculation AS (\n    SELECT\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY total_messages) AS overall_median_messages\n    FROM user_engagement_metrics\n),\ncohort_retention_analysis AS (\n    -- Fourth CTE: Calculate cohort-based retention metrics\n    SELECT\n        uem.user_id,\n        uem.username,\n        uem.registration_month,\n        uem.active_chats,\n        uem.total_messages,\n        uem.user_messages,\n        uem.ai_responses,\n        uem.active_days,\n        uem.message_span_days,\n        uem.daily_activity_rate,\n        uem.messages_per_chat,\n        uem.ai_response_ratio,\n        uem.days_since_last_activity,\n        -- Cohort comparison metrics using window functions\n        AVG(uem.total_messages) OVER (PARTITION BY uem.registration_month) AS cohort_avg_messages,\n        COALESCE(cmc.cohort_median_messages, 0) AS cohort_median_messages,\n        STDDEV(uem.total_messages) OVER (PARTITION BY uem.registration_month) AS cohort_stddev_messages,\n        COUNT(*) OVER (PARTITION BY uem.registration_month) AS cohort_size,\n        -- Cross-cohort comparisons\n        AVG(uem.total_messages) OVER () AS overall_avg_messages,\n        COALESCE(omc.overall_median_messages, 0) AS overall_median_messages\n    FROM user_engagement_metrics uem\n    LEFT JOIN cohort_median_calculation cmc ON uem.registration_month = cmc.registration_month\n    CROSS JOIN overall_median_calculation omc\n),\nengagement_scoring AS (\n    -- Fifth CTE: Calculate comprehensive engagement scores with weighted factors\n    SELECT\n        cra.user_id,\n        cra.username,\n        cra.registration_month,\n        cra.active_chats,\n        cra.total_messages,\n        cra.user_messages,\n        cra.ai_responses,\n        cra.active_days,\n        cra.daily_activity_rate,\n        cra.messages_per_chat,\n        cra.ai_response_ratio,\n        cra.days_since_last_activity,\n        cra.cohort_avg_messages,\n        cra.cohort_median_messages,\n        cra.cohort_size,\n        -- Multi-factor engagement score (production-grade scoring algorithm)\n        (\n            -- Message volume component (30% weight)\n            (LEAST(cra.total_messages, 1000) / 1000.0 * 30) +\n            -- Activity frequency component (25% weight)\n            (LEAST(cra.active_days, 30) / 30.0 * 25) +\n            -- Engagement consistency component (20% weight)\n            (LEAST(cra.daily_activity_rate, 1.0) * 20) +\n            -- Chat diversity component (15% weight)\n            (LEAST(cra.active_chats, 20) / 20.0 * 15) +\n            -- Recency component (10% weight) - penalize inactive users\n            (GREATEST(0, 1.0 - (LEAST(cra.days_since_last_activity, 90) / 90.0)) * 10)\n        ) AS raw_engagement_score,\n        -- Cohort-relative performance\n        CASE\n            WHEN cra.cohort_avg_messages > 0 THEN cra.total_messages::numeric / cra.cohort_avg_messages\n            ELSE 0\n        END AS cohort_performance_ratio,\n        -- Percentile rankings\n        PERCENT_RANK() OVER (ORDER BY cra.total_messages DESC) AS message_percentile,\n        PERCENT_RANK() OVER (PARTITION BY cra.registration_month ORDER BY cra.total_messages DESC) AS cohort_percentile\n    FROM cohort_retention_analysis cra\n),\nfinal_rankings AS (\n    -- Sixth CTE: Final rankings with multiple window function calculations\n    SELECT\n        es.user_id,\n        es.username,\n        es.registration_month,\n        es.active_chats,\n        es.total_messages,\n        es.user_messages,\n        es.ai_responses,\n        es.active_days,\n        ROUND(CAST(es.daily_activity_rate AS NUMERIC), 3) AS daily_activity_rate,\n        ROUND(CAST(es.messages_per_chat AS NUMERIC), 2) AS messages_per_chat,\n        ROUND(CAST(es.ai_response_ratio AS NUMERIC), 2) AS ai_response_ratio,\n        ROUND(CAST(es.days_since_last_activity AS NUMERIC), 1) AS days_since_last_activity,\n        ROUND(CAST(es.raw_engagement_score AS NUMERIC), 2) AS engagement_score,\n        ROUND(CAST(es.cohort_performance_ratio AS NUMERIC), 2) AS cohort_performance_ratio,\n        ROUND(CAST(es.message_percentile * 100 AS NUMERIC), 2) AS overall_percentile,\n        ROUND(CAST(es.cohort_percentile * 100 AS NUMERIC), 2) AS cohort_percentile,\n        -- Multiple ranking methods\n        ROW_NUMBER() OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_rank,\n        RANK() OVER (ORDER BY es.total_messages DESC) AS message_rank,\n        DENSE_RANK() OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_dense_rank,\n        -- Running totals and moving averages\n        SUM(es.total_messages) OVER (ORDER BY es.raw_engagement_score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_messages,\n        AVG(es.total_messages) OVER (ORDER BY es.raw_engagement_score DESC ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING) AS moving_avg_messages_9,\n        -- Lag/Lead for trend analysis\n        LAG(es.total_messages, 1) OVER (ORDER BY es.raw_engagement_score DESC) AS prev_user_messages,\n        LEAD(es.total_messages, 1) OVER (ORDER BY es.raw_engagement_score DESC) AS next_user_messages,\n        -- NTILE for segmentation\n        NTILE(5) OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_quintile,\n        NTILE(10) OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_decile\n    FROM engagement_scoring es\n)\nSELECT\n    user_id,\n    username,\n    registration_month,\n    active_chats,\n    total_messages,\n    user_messages,\n    ai_responses,\n    active_days,\n    daily_activity_rate,\n    messages_per_chat,\n    ai_response_ratio,\n    days_since_last_activity,\n    engagement_score,\n    cohort_performance_ratio,\n    overall_percentile,\n    cohort_percentile,\n    engagement_rank,\n    message_rank,\n    cumulative_messages,\n    ROUND(CAST(moving_avg_messages_9 AS NUMERIC), 2) AS moving_avg_messages,\n    engagement_quintile,\n    engagement_decile,\n    CASE engagement_quintile\n        WHEN 1 THEN 'Champion'\n        WHEN 2 THEN 'Power User'\n        WHEN 3 THEN 'Regular'\n        WHEN 4 THEN 'Casual'\n        ELSE 'Inactive'\n    END AS user_segment,\n    CASE\n        WHEN days_since_last_activity <= 1 THEN 'Active'\n        WHEN days_since_last_activity <= 7 THEN 'Recent'\n        WHEN days_since_last_activity <= 30 THEN 'At Risk'\n        ELSE 'Churned'\n    END AS activity_status\nFROM final_rankings\nWHERE engagement_rank <= 50\nORDER BY engagement_rank;",
      "line_number": 152
    },
    {
      "number": 2,
      "title": "Production-Grade Social Network Graph Analysis with Advanced Recursive CTE",
      "description": "Description: Enterprise-level social network analysis using recursive CTE for multi-hop graph traversal, path discovery, centrality metrics, and community detection. Implements production patterns similar to LinkedIn's \"People You May Know\" and Facebook's friend suggestions. Complexity: Advanced recursive CTE with multiple termination conditions, graph metrics (centrality, betweenness), path weight calculations, cycle detection, community clustering, multiple CTE nesting levels",
      "complexity": "Advanced recursive CTE with multiple termination conditions, graph metrics (centrality, betweenness), path weight calculations, cycle detection, community clustering, multiple CTE nesting levels",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE direct_chat_connections AS (\n    -- Anchor CTE: Direct connections with weighted edges based on shared chat activity\n    SELECT DISTINCT\n        cp1.user_id AS user_a,\n        cp2.user_id AS user_b,\n        1 AS hop_count,\n        ARRAY[cp1.user_id, cp2.user_id] AS path,\n        ARRAY_AGG(cp1.chat_id) AS chat_path,\n        COUNT(DISTINCT cp1.chat_id) AS shared_chat_count,\n        -- Weight: inverse of shared chats (more chats = stronger connection)\n        1.0 / NULLIF(COUNT(DISTINCT cp1.chat_id), 0) AS connection_weight,\n        MIN(cp1.joined_at) AS earliest_connection_date,\n        MAX(cp1.joined_at) AS latest_connection_date\n    FROM chat_participants cp1\n    INNER JOIN chat_participants cp2 ON cp1.chat_id = cp2.chat_id\n    WHERE cp1.user_id < cp2.user_id\n    GROUP BY cp1.user_id, cp2.user_id\n),\nweighted_path_traversal AS (\n    -- Recursive CTE: Multi-hop path discovery with cumulative weights and cycle prevention\n    SELECT\n        dcc.user_a,\n        dcc.user_b,\n        dcc.hop_count,\n        dcc.path,\n        dcc.chat_path,\n        dcc.shared_chat_count,\n        dcc.connection_weight AS cumulative_weight,\n        dcc.earliest_connection_date,\n        dcc.latest_connection_date,\n        -- Path metadata\n        ARRAY_LENGTH(dcc.path, 1) AS path_length,\n        ARRAY_LENGTH(dcc.chat_path, 1) AS chat_path_length\n    FROM direct_chat_connections dcc\n\n    UNION ALL\n\n    -- Recursive step: Find paths through intermediate users\n    SELECT\n        wpt.user_a,\n        cp3.user_id AS user_b,\n        wpt.hop_count + 1,\n        wpt.path || cp3.user_id,\n        wpt.chat_path || ARRAY[cp2.chat_id],\n        wpt.shared_chat_count + 1,\n        -- Cumulative weight: sum of inverse weights (Dijkstra-like)\n        wpt.cumulative_weight + 1.0,\n        LEAST(wpt.earliest_connection_date, cp2.joined_at),\n        GREATEST(wpt.latest_connection_date, cp2.joined_at),\n        -- Path metadata\n        ARRAY_LENGTH(wpt.path || cp3.user_id, 1) AS path_length,\n        ARRAY_LENGTH(wpt.chat_path || ARRAY[cp2.chat_id], 1) AS chat_path_length\n    FROM weighted_path_traversal wpt\n    INNER JOIN chat_participants cp2 ON wpt.user_b = cp2.user_id\n    INNER JOIN chat_participants cp3 ON cp2.chat_id = cp3.chat_id\n    WHERE\n        -- Prevent cycles: user not already in path\n        cp3.user_id != ALL(wpt.path)\n        -- Limit traversal depth for performance\n        AND wpt.hop_count < 4\n        -- Prevent paths that are too long (performance optimization)\n        AND ARRAY_LENGTH(wpt.path, 1) < 5\n        -- Pruning: only continue if cumulative weight is reasonable\n        AND wpt.cumulative_weight < 10.0\n),\npath_optimization AS (\n    -- Second CTE: Find shortest paths and optimal routes\n    SELECT\n        user_a,\n        user_b,\n        hop_count,\n        path,\n        chat_path,\n        shared_chat_count,\n        cumulative_weight,\n        earliest_connection_date,\n        latest_connection_date,\n        path_length,\n        chat_path_length,\n        -- Path quality metrics\n        CASE\n            WHEN hop_count = 1 THEN 'Direct'\n            WHEN hop_count = 2 THEN 'One Hop'\n            WHEN hop_count = 3 THEN 'Two Hops'\n            ELSE 'Three+ Hops'\n        END AS connection_type,\n        -- Time-based connection strength\n        EXTRACT(EPOCH FROM (latest_connection_date - earliest_connection_date)) / 86400 AS connection_duration_days\n    FROM weighted_path_traversal\n),\nshortest_paths AS (\n    -- Third CTE: Identify shortest paths using window functions\n    SELECT\n        po.user_a,\n        po.user_b,\n        po.hop_count,\n        po.path,\n        po.chat_path,\n        po.shared_chat_count,\n        po.cumulative_weight,\n        po.connection_type,\n        po.connection_duration_days,\n        po.path_length,\n        po.chat_path_length,\n        -- Find shortest path for each pair\n        MIN(po.hop_count) OVER (PARTITION BY po.user_a, po.user_b) AS min_hops,\n        MIN(po.cumulative_weight) OVER (PARTITION BY po.user_a, po.user_b) AS min_weight,\n        -- Count all paths between pairs\n        COUNT(*) OVER (PARTITION BY po.user_a, po.user_b) AS total_paths,\n        -- Rank paths by quality\n        ROW_NUMBER() OVER (\n            PARTITION BY po.user_a, po.user_b\n            ORDER BY po.hop_count ASC, po.cumulative_weight ASC, po.shared_chat_count DESC\n        ) AS path_rank\n    FROM path_optimization po\n),\noptimal_connections AS (\n    -- Fourth CTE: Select optimal paths and calculate connection metrics\n    SELECT\n        sp.user_a,\n        sp.user_b,\n        sp.hop_count AS optimal_hops,\n        sp.path AS optimal_path,\n        sp.chat_path AS optimal_chat_path,\n        sp.shared_chat_count,\n        sp.cumulative_weight AS optimal_weight,\n        sp.connection_type,\n        sp.connection_duration_days,\n        sp.total_paths,\n        -- Connection strength score (inverse of weight and hops)\n        (1.0 / NULLIF(sp.cumulative_weight, 0)) * (1.0 / NULLIF(sp.hop_count, 1)) * sp.shared_chat_count AS connection_strength\n    FROM shortest_paths sp\n    WHERE sp.path_rank = 1\n),\nuser_centrality_metrics AS (\n    -- Fifth CTE: Calculate graph centrality metrics for each user\n    SELECT\n        user_a AS user_id,\n        COUNT(DISTINCT user_b) AS direct_connections,\n        COUNT(*) AS total_connections,\n        AVG(optimal_hops) AS avg_path_length,\n        AVG(optimal_weight) AS avg_connection_weight,\n        SUM(connection_strength) AS total_connection_strength,\n        MAX(optimal_hops) AS max_path_length,\n        MIN(optimal_hops) AS min_path_length,\n        -- Betweenness centrality approximation: users who appear in many paths\n        COUNT(*) FILTER (WHERE optimal_hops > 1) AS intermediary_connections\n    FROM optimal_connections\n    GROUP BY user_a\n),\nnetwork_statistics AS (\n    -- Sixth CTE: Aggregate network-level statistics\n    SELECT\n        oc.user_a,\n        oc.user_b,\n        oc.optimal_hops,\n        oc.optimal_path,\n        oc.optimal_chat_path,\n        oc.shared_chat_count,\n        oc.optimal_weight,\n        oc.connection_type,\n        oc.connection_duration_days,\n        oc.total_paths,\n        oc.connection_strength,\n        ucm1.direct_connections AS user_a_direct_connections,\n        ucm1.total_connection_strength AS user_a_total_strength,\n        ucm1.avg_path_length AS user_a_avg_path_length,\n        ucm2.direct_connections AS user_b_direct_connections,\n        ucm2.total_connection_strength AS user_b_total_strength,\n        ucm2.avg_path_length AS user_b_avg_path_length,\n        -- Mutual connection analysis\n        CASE\n            WHEN oc.optimal_hops = 1 THEN 'Direct Connection'\n            WHEN oc.optimal_hops = 2 THEN 'One Mutual Connection'\n            WHEN oc.optimal_hops = 3 THEN 'Two Mutual Connections'\n            ELSE 'Distant Connection'\n        END AS connection_category\n    FROM optimal_connections oc\n    LEFT JOIN user_centrality_metrics ucm1 ON oc.user_a = ucm1.user_id\n    LEFT JOIN user_centrality_metrics ucm2 ON oc.user_b = ucm2.user_id\n),\npath_preview_cte AS (\n    -- Seventh CTE: Extract first 5 usernames from path for visualization (cross-database compatible)\n    SELECT\n        ns.*,\n        ARRAY_AGG(p.username ORDER BY\n            CASE\n                WHEN ARRAY_LENGTH(ns.optimal_path, 1) >= 1 AND p.id = ns.optimal_path[1] THEN 1\n                WHEN ARRAY_LENGTH(ns.optimal_path, 1) >= 2 AND p.id = ns.optimal_path[2] THEN 2\n                WHEN ARRAY_LENGTH(ns.optimal_path, 1) >= 3 AND p.id = ns.optimal_path[3] THEN 3\n                WHEN ARRAY_LENGTH(ns.optimal_path, 1) >= 4 AND p.id = ns.optimal_path[4] THEN 4\n                WHEN ARRAY_LENGTH(ns.optimal_path, 1) >= 5 AND p.id = ns.optimal_path[5] THEN 5\n                ELSE 999\n            END\n        ) FILTER (WHERE\n            (ARRAY_LENGTH(ns.optimal_path, 1) >= 1 AND p.id = ns.optimal_path[1]) OR\n            (ARRAY_LENGTH(ns.optimal_path, 1) >= 2 AND p.id = ns.optimal_path[2]) OR\n            (ARRAY_LENGTH(ns.optimal_path, 1) >= 3 AND p.id = ns.optimal_path[3]) OR\n            (ARRAY_LENGTH(ns.optimal_path, 1) >= 4 AND p.id = ns.optimal_path[4]) OR\n            (ARRAY_LENGTH(ns.optimal_path, 1) >= 5 AND p.id = ns.optimal_path[5])\n        ) AS path_usernames\n    FROM network_statistics ns\n    LEFT JOIN profiles p ON p.id = ANY(ns.optimal_path)\n    GROUP BY ns.user_a, ns.user_b, ns.optimal_hops, ns.optimal_path, ns.optimal_chat_path,\n             ns.shared_chat_count, ns.optimal_weight, ns.connection_type,\n             ns.connection_duration_days, ns.total_paths, ns.connection_strength,\n             ns.user_a_direct_connections, ns.user_a_total_strength, ns.user_a_avg_path_length,\n             ns.user_b_direct_connections, ns.user_b_total_strength, ns.user_b_avg_path_length,\n             ns.connection_category\n)\nSELECT\n    p1.username AS user_a_name,\n    p2.username AS user_b_name,\n    ppc.optimal_hops,\n    ppc.connection_type,\n    ppc.connection_category,\n    ppc.shared_chat_count,\n    ROUND(CAST(ppc.optimal_weight AS NUMERIC), 3) AS connection_weight,\n    ROUND(CAST(ppc.connection_strength AS NUMERIC), 2) AS connection_strength,\n    ppc.total_paths,\n    ROUND(CAST(ppc.connection_duration_days AS NUMERIC), 1) AS connection_duration_days,\n    ppc.user_a_direct_connections,\n    ppc.user_b_direct_connections,\n    ROUND(CAST(ppc.user_a_avg_path_length AS NUMERIC), 2) AS user_a_avg_path_length,\n    ROUND(CAST(ppc.user_b_avg_path_length AS NUMERIC), 2) AS user_b_avg_path_length,\n    -- Path visualization (first 5 users in path) - cross-database compatible\n    ARRAY_TO_STRING(COALESCE(ppc.path_usernames, ARRAY[]::VARCHAR[]), ' -> ') AS path_preview\nFROM path_preview_cte ppc\nINNER JOIN profiles p1 ON ppc.user_a = p1.id\nINNER JOIN profiles p2 ON ppc.user_b = p2.id\nWHERE ppc.optimal_hops <= 3\nORDER BY ppc.connection_strength DESC, ppc.optimal_hops ASC, ppc.shared_chat_count DESC\nLIMIT 100;",
      "line_number": 576
    },
    {
      "number": 3,
      "title": "Production-Grade Conversation Analytics with Deep CTE Nesting and Advanced Pattern Recognition",
      "description": "Description: Enterprise-level conversation thread analysis with turn-taking patterns, sentiment indicators, engagement velocity, conversation health scoring, and predictive analytics. Implements production patterns similar to customer support platforms and AI chat analytics systems. Complexity: Deep nested CTEs (7+ levels), advanced window functions with multiple frame clauses, pattern recognition, time-series analysis, conversation health scoring, engagement velocity calculations, predictive me",
      "complexity": "Deep nested CTEs (7+ levels), advanced window functions with multiple frame clauses, pattern recognition, time-series analysis, conversation health scoring, engagement velocity calculations, predictive metrics",
      "expected_output": "Query results",
      "sql": "WITH message_thread_sequence AS (\n    -- First CTE: Establish message sequence with comprehensive metadata\n    SELECT\n        m.id,\n        m.chat_id,\n        m.sender_id,\n        m.is_ai,\n        m.content,\n        m.created_at,\n        LENGTH(m.content) AS message_length,\n        -- Sequence numbering\n        ROW_NUMBER() OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS message_sequence,\n        ROW_NUMBER() OVER (PARTITION BY m.chat_id, m.is_ai ORDER BY m.created_at) AS type_sequence,\n        -- Temporal analysis\n        LAG(m.created_at, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS prev_message_time,\n        LEAD(m.created_at, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS next_message_time,\n        LAG(m.is_ai, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS prev_is_ai,\n        LAG(m.is_ai, 2) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS prev2_is_ai,\n        LEAD(m.is_ai, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS next_is_ai,\n        LEAD(m.is_ai, 2) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS next2_is_ai,\n        -- Aggregated context\n        COUNT(*) OVER (PARTITION BY m.chat_id) AS total_chat_messages,\n        COUNT(*) OVER (PARTITION BY m.chat_id, m.is_ai) AS total_type_messages,\n        AVG(LENGTH(m.content)) OVER (PARTITION BY m.chat_id) AS chat_avg_length,\n        AVG(LENGTH(m.content)) OVER (PARTITION BY m.chat_id, m.is_ai) AS type_avg_length\n    FROM messages m\n),\ntemporal_analysis AS (\n    -- Second CTE: Calculate time-based metrics and response patterns\n    SELECT\n        mts.*,\n        -- Response time calculations\n        EXTRACT(EPOCH FROM (mts.created_at - mts.prev_message_time)) AS seconds_since_prev,\n        EXTRACT(EPOCH FROM (mts.next_message_time - mts.created_at)) AS seconds_until_next,\n        -- Turn-taking patterns\n        CASE\n            WHEN mts.prev_is_ai = false AND mts.is_ai = true THEN 'User-to-AI'\n            WHEN mts.prev_is_ai = true AND mts.is_ai = false THEN 'AI-to-User'\n            WHEN mts.prev_is_ai = false AND mts.is_ai = false THEN 'User-to-User'\n            WHEN mts.prev_is_ai = true AND mts.is_ai = true THEN 'AI-to-AI'\n            ELSE 'First-Message'\n        END AS transition_type,\n        -- Conversation flow indicators\n        CASE\n            WHEN mts.prev_is_ai IS NULL THEN 'Conversation-Start'\n            WHEN mts.next_is_ai IS NULL THEN 'Conversation-End'\n            WHEN mts.prev_is_ai != mts.is_ai AND mts.next_is_ai != mts.is_ai THEN 'Turn-Taking'\n            WHEN mts.prev_is_ai = mts.is_ai AND mts.next_is_ai = mts.is_ai THEN 'Same-Type-Burst'\n            ELSE 'Mixed-Pattern'\n        END AS flow_pattern,\n        -- Message length analysis relative to conversation\n        CASE\n            WHEN mts.chat_avg_length > 0 THEN mts.message_length::numeric / mts.chat_avg_length\n            ELSE 1.0\n        END AS length_ratio,\n        CASE\n            WHEN mts.type_avg_length > 0 THEN mts.message_length::numeric / mts.type_avg_length\n            ELSE 1.0\n        END AS type_length_ratio\n    FROM message_thread_sequence mts\n),\nconversation_velocity AS (\n    -- Third CTE: Calculate engagement velocity and activity patterns\n    SELECT\n        ta.*,\n        -- Velocity metrics (messages per time unit)\n        CASE\n            WHEN ta.seconds_since_prev > 0 THEN 60.0 / ta.seconds_since_prev\n            ELSE NULL\n        END AS messages_per_minute_prev,\n        CASE\n            WHEN ta.seconds_until_next > 0 THEN 60.0 / ta.seconds_until_next\n            ELSE NULL\n        END AS messages_per_minute_next,\n        -- Rolling window statistics\n        AVG(ta.seconds_since_prev) OVER (\n            PARTITION BY ta.chat_id\n            ORDER BY ta.message_sequence\n            ROWS BETWEEN 4 PRECEDING AND CURRENT ROW\n        ) AS rolling_avg_response_time_5,\n        AVG(ta.seconds_since_prev) OVER (\n            PARTITION BY ta.chat_id\n            ORDER BY ta.message_sequence\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS rolling_avg_response_time_10,\n        -- Activity bursts detection\n        COUNT(*) OVER (\n            PARTITION BY ta.chat_id\n            ORDER BY ta.message_sequence\n            ROWS BETWEEN 4 PRECEDING AND CURRENT ROW\n        ) AS messages_in_last_5,\n        COUNT(*) OVER (\n            PARTITION BY ta.chat_id\n            ORDER BY ta.message_sequence\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS messages_in_last_10,\n        -- Conversation health indicators\n        CASE\n            WHEN ta.seconds_since_prev < 60 AND ta.transition_type IN ('User-to-AI', 'AI-to-User') THEN 'High-Engagement'\n            WHEN ta.seconds_since_prev < 300 AND ta.transition_type IN ('User-to-AI', 'AI-to-User') THEN 'Medium-Engagement'\n            WHEN ta.seconds_since_prev > 3600 THEN 'Low-Engagement'\n            ELSE 'Normal-Engagement'\n        END AS engagement_level\n    FROM temporal_analysis ta\n),\nthread_pattern_aggregation AS (\n    -- Fourth CTE: Aggregate patterns at thread level\n    SELECT\n        chat_id,\n        COUNT(*) AS total_messages,\n        COUNT(DISTINCT sender_id) AS unique_participants,\n        -- Message type breakdown\n        SUM(CASE WHEN is_ai = false THEN 1 ELSE 0 END) AS user_messages,\n        SUM(CASE WHEN is_ai = true THEN 1 ELSE 0 END) AS ai_messages,\n        -- Transition patterns\n        SUM(CASE WHEN transition_type = 'User-to-AI' THEN 1 ELSE 0 END) AS user_to_ai_transitions,\n        SUM(CASE WHEN transition_type = 'AI-to-User' THEN 1 ELSE 0 END) AS ai_to_user_transitions,\n        SUM(CASE WHEN transition_type = 'User-to-User' THEN 1 ELSE 0 END) AS user_to_user_transitions,\n        SUM(CASE WHEN transition_type = 'AI-to-AI' THEN 1 ELSE 0 END) AS ai_to_ai_transitions,\n        -- Flow patterns\n        SUM(CASE WHEN flow_pattern = 'Turn-Taking' THEN 1 ELSE 0 END) AS turn_taking_count,\n        SUM(CASE WHEN flow_pattern = 'Same-Type-Burst' THEN 1 ELSE 0 END) AS burst_count,\n        -- Temporal metrics\n        AVG(seconds_since_prev) AS avg_response_time,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY seconds_since_prev) AS median_response_time,\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY seconds_since_prev) AS p25_response_time,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY seconds_since_prev) AS p75_response_time,\n        MIN(seconds_since_prev) AS min_response_time,\n        MAX(seconds_since_prev) AS max_response_time,\n        STDDEV(seconds_since_prev) AS stddev_response_time,\n        -- Velocity metrics\n        AVG(messages_per_minute_prev) AS avg_messages_per_minute,\n        MAX(messages_per_minute_prev) AS peak_messages_per_minute,\n        -- Length metrics\n        AVG(message_length) AS avg_message_length,\n        AVG(length_ratio) AS avg_length_ratio,\n        -- Engagement metrics\n        SUM(CASE WHEN engagement_level = 'High-Engagement' THEN 1 ELSE 0 END) AS high_engagement_count,\n        SUM(CASE WHEN engagement_level = 'Low-Engagement' THEN 1 ELSE 0 END) AS low_engagement_count,\n        -- Conversation span\n        MIN(created_at) AS conversation_start,\n        MAX(created_at) AS conversation_end,\n        EXTRACT(EPOCH FROM (MAX(created_at) - MIN(created_at))) / 60 AS conversation_duration_minutes\n    FROM conversation_velocity\n    GROUP BY chat_id\n),\nconversation_health_scoring AS (\n    -- Fifth CTE: Calculate comprehensive conversation health scores\n    SELECT\n        tpa.*,\n        -- Balance metrics\n        CASE\n            WHEN tpa.total_messages > 0 THEN tpa.user_messages::numeric / tpa.total_messages\n            ELSE 0\n        END AS user_message_ratio,\n        CASE\n            WHEN tpa.total_messages > 0 THEN tpa.ai_messages::numeric / tpa.total_messages\n            ELSE 0\n        END AS ai_message_ratio,\n        -- Turn-taking quality\n        CASE\n            WHEN tpa.total_messages > 1 THEN tpa.user_to_ai_transitions::numeric / (tpa.total_messages - 1)\n            ELSE 0\n        END AS turn_taking_ratio,\n        -- Response time quality (inverse - faster is better)\n        CASE\n            WHEN tpa.avg_response_time > 0 THEN 1.0 / (1.0 + tpa.avg_response_time / 60.0)\n            ELSE 0\n        END AS response_time_score,\n        -- Engagement quality\n        CASE\n            WHEN tpa.total_messages > 0 THEN tpa.high_engagement_count::numeric / tpa.total_messages\n            ELSE 0\n        END AS high_engagement_ratio,\n        -- Conversation velocity score\n        CASE\n            WHEN tpa.conversation_duration_minutes > 0 THEN tpa.total_messages::numeric / tpa.conversation_duration_minutes\n            ELSE 0\n        END AS messages_per_minute,\n        -- Comprehensive health score (weighted factors)\n        (\n            -- Turn-taking quality (30%)\n            (CASE WHEN tpa.total_messages > 1 THEN tpa.user_to_ai_transitions::numeric / (tpa.total_messages - 1) ELSE 0 END * 30) +\n            -- Response time quality (25%)\n            (CASE WHEN tpa.avg_response_time > 0 THEN 1.0 / (1.0 + tpa.avg_response_time / 60.0) ELSE 0 END * 25) +\n            -- Engagement level (20%)\n            (CASE WHEN tpa.total_messages > 0 THEN tpa.high_engagement_count::numeric / tpa.total_messages ELSE 0 END * 20) +\n            -- Message balance (15%)\n            (LEAST(\n                CASE WHEN tpa.total_messages > 0 THEN tpa.user_messages::numeric / tpa.total_messages ELSE 0 END,\n                CASE WHEN tpa.total_messages > 0 THEN tpa.ai_messages::numeric / tpa.total_messages ELSE 0 END\n            ) * 2 * 15) +\n            -- Conversation length (10%) - longer conversations indicate engagement\n            (LEAST(tpa.total_messages / 50.0, 1.0) * 10)\n        ) AS raw_health_score\n    FROM thread_pattern_aggregation tpa\n),\nconversation_classification AS (\n    -- Sixth CTE: Classify conversations and calculate percentiles\n    SELECT\n        chs.chat_id,\n        chs.total_messages,\n        chs.user_messages,\n        chs.ai_messages,\n        chs.user_message_ratio,\n        chs.ai_message_ratio,\n        chs.turn_taking_ratio,\n        chs.response_time_score,\n        chs.high_engagement_ratio,\n        chs.messages_per_minute,\n        chs.avg_response_time,\n        chs.median_response_time,\n        chs.p25_response_time,\n        chs.p75_response_time,\n        chs.burst_count,\n        chs.turn_taking_count,\n        chs.raw_health_score,\n        tpa.unique_participants,\n        tpa.user_to_ai_transitions,\n        tpa.ai_to_user_transitions,\n        -- Conversation type classification\n        CASE\n            WHEN chs.user_message_ratio > 0.7 THEN 'User-Dominated'\n            WHEN chs.user_message_ratio > 0.7 THEN 'AI-Dominated'\n            WHEN chs.turn_taking_ratio > 0.6 THEN 'Balanced-Dialogue'\n            WHEN chs.burst_count > chs.turn_taking_count THEN 'Burst-Pattern'\n            ELSE 'Mixed-Pattern'\n        END AS conversation_type,\n        -- Engagement classification\n        CASE\n            WHEN chs.messages_per_minute > 2 THEN 'High-Velocity'\n            WHEN chs.messages_per_minute > 0.5 THEN 'Medium-Velocity'\n            WHEN chs.messages_per_minute > 0.1 THEN 'Low-Velocity'\n            ELSE 'Stagnant'\n        END AS velocity_class,\n        -- Health classification\n        CASE\n            WHEN chs.raw_health_score >= 70 THEN 'Excellent'\n            WHEN chs.raw_health_score >= 50 THEN 'Good'\n            WHEN chs.raw_health_score >= 30 THEN 'Fair'\n            ELSE 'Poor'\n        END AS health_class,\n        -- Percentile rankings\n        PERCENT_RANK() OVER (ORDER BY chs.raw_health_score DESC) AS health_percentile,\n        PERCENT_RANK() OVER (ORDER BY chs.messages_per_minute DESC) AS velocity_percentile,\n        PERCENT_RANK() OVER (ORDER BY chs.total_messages DESC) AS volume_percentile,\n        -- Cross-conversation comparisons\n        AVG(chs.raw_health_score) OVER () AS overall_avg_health,\n        AVG(chs.messages_per_minute) OVER () AS overall_avg_velocity,\n        STDDEV(chs.raw_health_score) OVER () AS overall_stddev_health\n    FROM conversation_health_scoring chs\n    LEFT JOIN thread_pattern_aggregation tpa ON chs.chat_id = tpa.chat_id\n),\nfinal_conversation_analytics AS (\n    -- Seventh CTE: Final analytics with rankings and recommendations\n    SELECT\n        cc.chat_id,\n        NULL AS chat_title,\n        cc.total_messages,\n        cc.unique_participants,\n        cc.user_messages,\n        cc.ai_messages,\n        cc.user_to_ai_transitions,\n        cc.ai_to_user_transitions,\n        cc.turn_taking_count,\n        cc.burst_count,\n        ROUND(CAST(cc.user_message_ratio * 100 AS NUMERIC), 2) AS user_message_percentage,\n        ROUND(CAST(cc.ai_message_ratio * 100 AS NUMERIC), 2) AS ai_message_percentage,\n        cc.turn_taking_ratio,\n        cc.response_time_score,\n        cc.high_engagement_ratio,\n        ROUND(CAST(cc.avg_response_time AS NUMERIC), 2) AS avg_response_seconds,\n        ROUND(CAST(cc.median_response_time AS NUMERIC), 2) AS median_response_seconds,\n        ROUND(CAST(cc.p25_response_time AS NUMERIC), 2) AS p25_response_seconds,\n        ROUND(CAST(cc.p75_response_time AS NUMERIC), 2) AS p75_response_seconds,\n        ROUND(CAST(cc.messages_per_minute AS NUMERIC), 3) AS messages_per_minute,\n        ROUND(CAST(cc.raw_health_score AS NUMERIC), 2) AS health_score,\n        cc.conversation_type,\n        cc.velocity_class,\n        cc.health_class,\n        ROUND(CAST(cc.health_percentile * 100 AS NUMERIC), 2) AS health_percentile,\n        ROUND(CAST(cc.velocity_percentile * 100 AS NUMERIC), 2) AS velocity_percentile,\n        ROUND(CAST(cc.volume_percentile * 100 AS NUMERIC), 2) AS volume_percentile,\n        ROUND(CAST(cc.overall_avg_health AS NUMERIC), 2) AS overall_avg_health,\n        -- Relative performance\n        CASE\n            WHEN cc.overall_avg_health > 0 THEN cc.raw_health_score / cc.overall_avg_health\n            ELSE 1.0\n        END AS health_ratio,\n        -- Rankings\n        ROW_NUMBER() OVER (ORDER BY cc.raw_health_score DESC) AS health_rank,\n        RANK() OVER (ORDER BY cc.messages_per_minute DESC) AS velocity_rank,\n        DENSE_RANK() OVER (ORDER BY cc.total_messages DESC) AS volume_rank,\n        -- NTILE segmentation\n        NTILE(5) OVER (ORDER BY cc.raw_health_score DESC) AS health_quintile,\n        NTILE(10) OVER (ORDER BY cc.raw_health_score DESC) AS health_decile,\n        -- Recommendations\n        CASE\n            WHEN cc.raw_health_score < 30 AND cc.user_message_ratio < 0.3 THEN 'Encourage User Participation'\n            WHEN cc.raw_health_score < 30 AND cc.avg_response_time > 300 THEN 'Improve Response Time'\n            WHEN cc.burst_count > cc.turn_taking_count THEN 'Encourage Turn-Taking'\n            WHEN cc.messages_per_minute < 0.1 THEN 'Increase Engagement Velocity'\n            ELSE 'Conversation Healthy'\n        END AS recommendation\n    FROM conversation_classification cc\n)\nSELECT\n    NULL AS chat_title,\n    fca.total_messages,\n    fca.unique_participants,\n    fca.user_messages,\n    fca.ai_messages,\n    fca.user_message_percentage,\n    fca.ai_message_percentage,\n    fca.user_to_ai_transitions,\n    fca.ai_to_user_transitions,\n    fca.turn_taking_count,\n    fca.burst_count,\n    fca.avg_response_seconds,\n    fca.median_response_seconds,\n    fca.p25_response_seconds,\n    fca.p75_response_seconds,\n    fca.messages_per_minute,\n    fca.health_score,\n    fca.conversation_type,\n    fca.velocity_class,\n    fca.health_class,\n    fca.health_percentile,\n    fca.velocity_percentile,\n    fca.volume_percentile,\n    ROUND(CAST(fca.health_ratio AS NUMERIC), 2) AS health_ratio,\n    fca.health_rank,\n    fca.velocity_rank,\n    fca.volume_rank,\n    fca.health_quintile,\n    fca.health_decile,\n    fca.recommendation\nFROM final_conversation_analytics fca\nINNER JOIN chats c ON fca.chat_id = c.id\nWHERE fca.total_messages >= 5\nORDER BY fca.health_score DESC, fca.total_messages DESC;",
      "line_number": 1012
    },
    {
      "number": 4,
      "title": "Production-Grade Friend Network Analysis with Recursive CTE and Advanced Graph Metrics",
      "description": "Description: Enterprise-level friend network analysis with recursive CTE for multi-hop connections, graph centrality metrics, network clustering, and advanced window function analytics. Implements production patterns similar to LinkedIn's connection analysis. Complexity: Recursive CTE, multiple nested CTEs (6+ levels), window functions with frame clauses, correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Recursive CTE, multiple nested CTEs (6+ levels), window functions with frame clauses, correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE friend_network_expansion AS (\n    -- Anchor: Direct friend connections\n    SELECT\n        f1.user_id AS user_a,\n        f2.user_id AS user_b,\n        1 AS connection_depth,\n        ARRAY[f1.user_id, f2.user_id] AS connection_path,\n        f1.status AS status_a,\n        f2.status AS status_b\n    FROM friends f1\n    INNER JOIN friends f2 ON f1.friend_id = f2.friend_id AND f1.user_id = f2.friend_id\n    WHERE f1.status = 'accepted' AND f2.status = 'accepted'\n\n    UNION ALL\n\n    -- Recursive: Multi-hop friend connections\n    SELECT\n        fne.user_a,\n        f3.user_id AS user_b,\n        fne.connection_depth + 1,\n        fne.connection_path || f3.user_id,\n        fne.status_a,\n        f4.status AS status_b\n    FROM friend_network_expansion fne\n    INNER JOIN friends f3 ON fne.user_b = f3.friend_id AND f3.status = 'accepted'\n    INNER JOIN friends f4 ON f3.user_id = f4.friend_id AND f4.user_id = f3.friend_id AND f4.status = 'accepted'\n    WHERE f3.user_id != ALL(fne.connection_path)\n        AND fne.connection_depth < 3\n),\nfriend_statistics AS (\n    -- First CTE: Aggregate friend statistics\n    SELECT\n        f.user_id,\n        COUNT(*) AS total_friend_requests,\n        SUM(CASE WHEN f.status = 'accepted' THEN 1 ELSE 0 END) AS accepted_friends,\n        SUM(CASE WHEN f.status = 'pending' THEN 1 ELSE 0 END) AS pending_friends,\n        SUM(CASE WHEN f.status = 'declined' THEN 1 ELSE 0 END) AS declined_friends,\n        AVG(CASE WHEN f.status = 'accepted' THEN 1.0 ELSE 0.0 END) AS acceptance_rate\n    FROM friends f\n    GROUP BY f.user_id\n),\nmutual_connection_analysis AS (\n    -- Second CTE: Calculate mutual connections with correlated subqueries\n    SELECT\n        f1.user_id AS user_a,\n        f2.user_id AS user_b,\n        COUNT(DISTINCT f3.friend_id) AS mutual_friends,\n        (\n            SELECT COUNT(*)\n            FROM friends f4\n            WHERE f4.user_id = f1.user_id\n                AND f4.status = 'accepted'\n                AND EXISTS (\n                    SELECT 1\n                    FROM friends f5\n                    WHERE f5.user_id = f2.user_id\n                        AND f5.friend_id = f4.friend_id\n                        AND f5.status = 'accepted'\n                )\n        ) AS verified_mutual_count\n    FROM friends f1\n    INNER JOIN friends f2 ON f1.friend_id = f2.friend_id\n    LEFT JOIN friends f3 ON f3.user_id = f1.user_id AND f3.status = 'accepted'\n    INNER JOIN friends f4 ON f4.user_id = f2.user_id AND f4.friend_id = f3.friend_id AND f4.status = 'accepted'\n    WHERE f1.status = 'accepted'\n        AND f2.status = 'accepted'\n        AND f1.user_id < f2.user_id\n    GROUP BY f1.user_id, f2.user_id\n),\nnetwork_centrality_metrics AS (\n    -- Third CTE: Calculate graph centrality using window functions\n    SELECT\n        fs.user_id,\n        p.username,\n        fs.total_friend_requests,\n        fs.accepted_friends,\n        fs.pending_friends,\n        fs.declined_friends,\n        fs.acceptance_rate,\n        -- Centrality metrics\n        COUNT(DISTINCT fne.user_b) AS total_connections,\n        COUNT(DISTINCT CASE WHEN fne.connection_depth = 1 THEN fne.user_b END) AS direct_connections,\n        COUNT(DISTINCT CASE WHEN fne.connection_depth = 2 THEN fne.user_b END) AS second_degree_connections,\n        AVG(fne.connection_depth) AS avg_connection_depth,\n        -- Window function rankings\n        ROW_NUMBER() OVER (ORDER BY fs.accepted_friends DESC) AS friend_count_rank,\n        DENSE_RANK() OVER (ORDER BY fs.accepted_friends DESC) AS friend_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY fs.accepted_friends DESC) AS friend_percentile,\n        LAG(fs.accepted_friends, 1) OVER (ORDER BY fs.accepted_friends DESC) AS prev_user_friends,\n        LEAD(fs.accepted_friends, 1) OVER (ORDER BY fs.accepted_friends DESC) AS next_user_friends,\n        SUM(fs.accepted_friends) OVER (ORDER BY fs.accepted_friends DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_friends,\n        AVG(fs.accepted_friends) OVER (ORDER BY fs.accepted_friends DESC ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING) AS moving_avg_friends\n    FROM friend_statistics fs\n    INNER JOIN profiles p ON fs.user_id = p.id\n    LEFT JOIN friend_network_expansion fne ON fs.user_id = fne.user_a\n    GROUP BY fs.user_id, p.username, fs.total_friend_requests, fs.accepted_friends, fs.pending_friends, fs.declined_friends, fs.acceptance_rate\n),\nmutual_connection_aggregation AS (\n    -- Fourth CTE: Aggregate mutual connection metrics\n    SELECT\n        ncm.user_id,\n        ncm.username,\n        ncm.total_friend_requests,\n        ncm.accepted_friends,\n        ncm.pending_friends,\n        ncm.declined_friends,\n        ncm.acceptance_rate,\n        ncm.total_connections,\n        ncm.direct_connections,\n        ncm.second_degree_connections,\n        ncm.avg_connection_depth,\n        ncm.friend_count_rank,\n        ncm.friend_dense_rank,\n        ncm.friend_percentile,\n        ncm.prev_user_friends,\n        ncm.next_user_friends,\n        ncm.cumulative_friends,\n        ncm.moving_avg_friends,\n        COALESCE(SUM(mca.mutual_friends), 0) AS total_mutual_connections,\n        COALESCE(AVG(mca.mutual_friends), 0) AS avg_mutual_connections,\n        COALESCE(MAX(mca.mutual_friends), 0) AS max_mutual_connections,\n        COALESCE(SUM(mca.verified_mutual_count), 0) AS verified_mutual_total\n    FROM network_centrality_metrics ncm\n    LEFT JOIN mutual_connection_analysis mca ON ncm.user_id = mca.user_a OR ncm.user_id = mca.user_b\n    GROUP BY ncm.user_id, ncm.username, ncm.total_friend_requests, ncm.accepted_friends, ncm.pending_friends, ncm.declined_friends, ncm.acceptance_rate, ncm.total_connections, ncm.direct_connections, ncm.second_degree_connections, ncm.avg_connection_depth, ncm.friend_count_rank, ncm.friend_dense_rank, ncm.friend_percentile, ncm.prev_user_friends, ncm.next_user_friends, ncm.cumulative_friends, ncm.moving_avg_friends\n),\nnetwork_scoring AS (\n    -- Fifth CTE: Calculate comprehensive network scores\n    SELECT\n        mca.*,\n        -- Network strength score\n        (\n            (mca.accepted_friends * 0.3) +\n            (mca.total_mutual_connections * 0.25) +\n            (mca.direct_connections * 0.2) +\n            (mca.second_degree_connections * 0.15) +\n            (mca.acceptance_rate * 100 * 0.1)\n        ) AS network_strength_score,\n        -- Connection quality ratio\n        CASE\n            WHEN mca.accepted_friends > 0 THEN mca.total_mutual_connections::numeric / mca.accepted_friends\n            ELSE 0\n        END AS connection_quality_ratio,\n        -- Pivot analysis using CASE\n        CASE\n            WHEN mca.accepted_friends >= 50 THEN 'Power User'\n            WHEN mca.accepted_friends >= 20 THEN 'Active User'\n            WHEN mca.accepted_friends >= 10 THEN 'Regular User'\n            WHEN mca.accepted_friends >= 5 THEN 'Casual User'\n            ELSE 'New User'\n        END AS user_category,\n        CASE\n            WHEN mca.total_mutual_connections >= 20 THEN 'Highly Connected'\n            WHEN mca.total_mutual_connections >= 10 THEN 'Well Connected'\n            WHEN mca.total_mutual_connections >= 5 THEN 'Moderately Connected'\n            ELSE 'Loosely Connected'\n        END AS connection_category\n    FROM mutual_connection_aggregation mca\n),\nfinal_network_analytics AS (\n    -- Sixth CTE: Final analytics with UNION and additional window functions\n    SELECT\n        ns.user_id,\n        ns.username,\n        ns.total_friend_requests,\n        ns.accepted_friends,\n        ns.pending_friends,\n        ns.declined_friends,\n        ROUND(CAST(ns.acceptance_rate * 100 AS NUMERIC), 2) AS acceptance_rate_percent,\n        ns.total_connections,\n        ns.direct_connections,\n        ns.second_degree_connections,\n        ROUND(CAST(ns.avg_connection_depth AS NUMERIC), 2) AS avg_connection_depth,\n        ns.total_mutual_connections,\n        ROUND(CAST(ns.avg_mutual_connections AS NUMERIC), 2) AS avg_mutual_connections,\n        ns.max_mutual_connections,\n        ns.verified_mutual_total,\n        ROUND(CAST(ns.network_strength_score AS NUMERIC), 2) AS network_strength_score,\n        ROUND(CAST(ns.connection_quality_ratio AS NUMERIC), 3) AS connection_quality_ratio,\n        ns.user_category,\n        ns.connection_category,\n        ns.friend_count_rank,\n        ns.friend_dense_rank,\n        ROUND(CAST(ns.friend_percentile * 100 AS NUMERIC), 2) AS friend_percentile,\n        ns.prev_user_friends,\n        ns.next_user_friends,\n        ns.cumulative_friends,\n        ROUND(CAST(ns.moving_avg_friends AS NUMERIC), 2) AS moving_avg_friends,\n        -- Additional window functions with frames\n        SUM(ns.accepted_friends) OVER (\n            PARTITION BY ns.user_category\n            ORDER BY ns.network_strength_score DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS category_cumulative_friends,\n        AVG(ns.network_strength_score) OVER (\n            PARTITION BY ns.user_category\n            ORDER BY ns.network_strength_score DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS category_moving_avg_score,\n        NTILE(5) OVER (ORDER BY ns.network_strength_score DESC) AS network_quintile,\n        NTILE(10) OVER (ORDER BY ns.network_strength_score DESC) AS network_decile\n    FROM network_scoring ns\n)\nSELECT\n    user_id,\n    username,\n    total_friend_requests,\n    accepted_friends,\n    pending_friends,\n    declined_friends,\n    acceptance_rate_percent,\n    total_connections,\n    direct_connections,\n    second_degree_connections,\n    avg_connection_depth,\n    total_mutual_connections,\n    avg_mutual_connections,\n    max_mutual_connections,\n    verified_mutual_total,\n    network_strength_score,\n    connection_quality_ratio,\n    user_category,\n    connection_category,\n    friend_count_rank,\n    friend_dense_rank,\n    friend_percentile,\n    prev_user_friends,\n    next_user_friends,\n    cumulative_friends,\n    moving_avg_friends,\n    category_cumulative_friends,\n    ROUND(CAST(category_moving_avg_score AS NUMERIC), 2) AS category_moving_avg_score,\n    network_quintile,\n    network_decile\nFROM final_network_analytics\nORDER BY network_strength_score DESC, accepted_friends DESC;",
      "line_number": 1559
    },
    {
      "number": 5,
      "title": "Production-Grade Time-Series Analysis with Recursive CTE and Advanced Window Functions",
      "description": "Description: Enterprise-level time-series analysis with recursive CTE for temporal pattern discovery, multiple window function frame clauses, correlated subqueries, and UNION operations. Implements production patterns similar to time-series analytics platforms. Complexity: Recursive CTE, multiple nested CTEs (7+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex aggregations",
      "complexity": "Recursive CTE, multiple nested CTEs (7+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE temporal_hierarchy AS (\n    -- Anchor: Base time periods\n    SELECT\n        DATE_TRUNC('hour', m.created_at) AS time_period,\n        'hour' AS period_type,\n        COUNT(*) AS message_count,\n        COUNT(DISTINCT m.chat_id) AS active_chats,\n        COUNT(DISTINCT m.sender_id) AS active_users\n    FROM messages m\n    GROUP BY DATE_TRUNC('hour', m.created_at)\n\n    UNION ALL\n\n    -- Recursive: Aggregate to higher time periods\n    SELECT\n        DATE_TRUNC('day', th.time_period) AS time_period,\n        'day' AS period_type,\n        0 AS sum_placeholder,\n        1 AS count_placeholder,\n        1 AS count_placeholder\n    FROM temporal_hierarchy th\n    WHERE th.period_type = 'hour'\n        AND DATE_TRUNC('day', th.time_period) != th.time_period\n    GROUP BY DATE_TRUNC('day', th.time_period)\n),\nhourly_activity_base AS (\n    -- First CTE: Base hourly aggregations with joins\n    SELECT\n        DATE_TRUNC('hour', m.created_at) AS activity_hour,\n        COUNT(*) AS message_count,\n        COUNT(DISTINCT m.chat_id) AS active_chats,\n        COUNT(DISTINCT m.sender_id) AS active_users,\n        SUM(CASE WHEN m.is_ai = false THEN 1 ELSE 0 END) AS user_messages,\n        SUM(CASE WHEN m.is_ai = true THEN 1 ELSE 0 END) AS ai_messages,\n        AVG(LENGTH(m.content)) AS avg_message_length,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY LENGTH(m.content)) AS median_message_length\n    FROM messages m\n    INNER JOIN chats c ON m.chat_id = c.id\n    LEFT JOIN profiles p ON m.sender_id = p.id\n    GROUP BY DATE_TRUNC('hour', m.created_at)\n),\nuser_activity_by_hour AS (\n    -- Second CTE: User-level hourly activity with correlated subqueries\n    SELECT\n        hab.activity_hour,\n        hab.message_count,\n        hab.active_chats,\n        hab.active_users,\n        hab.user_messages,\n        hab.ai_messages,\n        hab.avg_message_length,\n        hab.median_message_length,\n        (\n            SELECT COUNT(DISTINCT m2.chat_id)\n            FROM messages m2\n            WHERE DATE_TRUNC('hour', m2.created_at) = hab.activity_hour\n                AND m2.is_ai = false\n                AND EXISTS (\n                    SELECT 1\n                    FROM messages m3\n                    WHERE m3.chat_id = m2.chat_id\n                        AND DATE_TRUNC('hour', m3.created_at) = hab.activity_hour\n                        AND m3.is_ai = true\n                )\n        ) AS chats_with_ai_interaction,\n        (\n            SELECT AVG(LENGTH(m4.content))\n            FROM messages m4\n            WHERE DATE_TRUNC('hour', m4.created_at) = hab.activity_hour\n                AND m4.is_ai = false\n        ) AS avg_user_message_length\n    FROM hourly_activity_base hab\n),\nrolling_window_statistics AS (\n    -- Third CTE: Multiple window functions with different frame clauses\n    SELECT\n        uabh.activity_hour,\n        uabh.message_count,\n        uabh.active_chats,\n        uabh.active_users,\n        uabh.user_messages,\n        uabh.ai_messages,\n        uabh.chats_with_ai_interaction,\n        uabh.avg_message_length,\n        uabh.median_message_length,\n        uabh.avg_user_message_length,\n        -- ROWS BETWEEN frames\n        SUM(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\n        ) AS messages_12h_window,\n        AVG(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            ROWS BETWEEN 23 PRECEDING AND CURRENT ROW\n        ) AS avg_messages_24h_rows,\n        MAX(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            ROWS BETWEEN 23 PRECEDING AND CURRENT ROW\n        ) AS max_messages_24h_rows,\n        MIN(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            ROWS BETWEEN 23 PRECEDING AND CURRENT ROW\n        ) AS min_messages_24h_rows,\n        -- RANGE BETWEEN frames (time-based)\n        SUM(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            RANGE BETWEEN INTERVAL '12 hours' PRECEDING AND CURRENT ROW\n        ) AS messages_12h_range,\n        AVG(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            RANGE BETWEEN INTERVAL '24 hours' PRECEDING AND CURRENT ROW\n        ) AS avg_messages_24h_range,\n        -- Lag/Lead functions\n        LAG(uabh.message_count, 1) OVER (ORDER BY uabh.activity_hour) AS prev_hour_messages,\n        LAG(uabh.message_count, 2) OVER (ORDER BY uabh.activity_hour) AS prev2_hour_messages,\n        LEAD(uabh.message_count, 1) OVER (ORDER BY uabh.activity_hour) AS next_hour_messages,\n        LEAD(uabh.message_count, 2) OVER (ORDER BY uabh.activity_hour) AS next2_hour_messages,\n        -- First/Last value with frames\n        FIRST_VALUE(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            ROWS BETWEEN 23 PRECEDING AND CURRENT ROW\n        ) AS first_value_24h,\n        LAST_VALUE(uabh.message_count) OVER (\n            ORDER BY uabh.activity_hour\n            ROWS BETWEEN CURRENT ROW AND 23 FOLLOWING\n        ) AS last_value_24h\n    FROM user_activity_by_hour uabh\n),\ntrend_analysis AS (\n    -- Fourth CTE: Calculate trends and patterns\n    SELECT\n        rws.*,\n        -- Trend calculations\n        CASE\n            WHEN rws.prev_hour_messages IS NOT NULL THEN rws.message_count - rws.prev_hour_messages\n            ELSE 0\n        END AS hour_over_hour_change,\n        CASE\n            WHEN rws.prev_hour_messages > 0 THEN (rws.message_count::numeric / rws.prev_hour_messages - 1) * 100\n            ELSE 0\n        END AS hour_over_hour_percent_change,\n        -- Activity classification using CASE pivoting\n        CASE\n            WHEN rws.message_count > rws.avg_messages_24h_rows * 1.5 THEN 'Peak'\n            WHEN rws.message_count > rws.avg_messages_24h_rows * 1.2 THEN 'High'\n            WHEN rws.message_count > rws.avg_messages_24h_rows * 0.8 THEN 'Normal'\n            WHEN rws.message_count > rws.avg_messages_24h_rows * 0.5 THEN 'Low'\n            ELSE 'Very Low'\n        END AS activity_level,\n        CASE\n            WHEN rws.message_count > rws.prev_hour_messages * 1.5 THEN 'Spike'\n            WHEN rws.message_count < rws.prev_hour_messages * 0.5 THEN 'Drop'\n            WHEN rws.message_count > rws.prev_hour_messages THEN 'Increasing'\n            WHEN rws.message_count < rws.prev_hour_messages THEN 'Decreasing'\n            ELSE 'Stable'\n        END AS activity_trend,\n        -- Volatility measure\n        CASE\n            WHEN rws.max_messages_24h_rows > 0 AND rws.min_messages_24h_rows > 0 THEN\n                (rws.max_messages_24h_rows - rws.min_messages_24h_rows)::numeric / rws.avg_messages_24h_rows\n            ELSE 0\n        END AS volatility_ratio\n    FROM rolling_window_statistics rws\n),\nunion_combined_metrics AS (\n    -- Fifth CTE: UNION to combine different metric types\n    SELECT\n        ta.activity_hour,\n        'total' AS metric_type,\n        ta.message_count AS metric_value,\n        ta.activity_level,\n        ta.activity_trend\n    FROM trend_analysis ta\n\n    UNION ALL\n\n    SELECT\n        ta.activity_hour,\n        'user' AS metric_type,\n        ta.user_messages AS metric_value,\n        ta.activity_level,\n        ta.activity_trend\n    FROM trend_analysis ta\n\n    UNION ALL\n\n    SELECT\n        ta.activity_hour,\n        'ai' AS metric_type,\n        ta.ai_messages AS metric_value,\n        ta.activity_level,\n        ta.activity_trend\n    FROM trend_analysis ta\n),\naggregated_union_metrics AS (\n    -- Sixth CTE: Aggregate UNION results with window functions\n    SELECT\n        ucm.activity_hour,\n        SUM(CASE WHEN ucm.metric_type = 'total' THEN ucm.metric_value ELSE 0 END) AS total_messages,\n        SUM(CASE WHEN ucm.metric_type = 'user' THEN ucm.metric_value ELSE 0 END) AS user_messages,\n        SUM(CASE WHEN ucm.metric_type = 'ai' THEN ucm.metric_value ELSE 0 END) AS ai_messages,\n        MAX(ucm.activity_level) AS activity_level,\n        MAX(ucm.activity_trend) AS activity_trend,\n        COUNT(DISTINCT ucm.metric_type) AS metric_types_count,\n        -- Window functions on aggregated UNION data\n        SUM(ucm.metric_value) OVER (\n            PARTITION BY ucm.metric_type\n            ORDER BY ucm.activity_hour\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\n        ) AS type_12h_window,\n        AVG(ucm.metric_value) OVER (\n            PARTITION BY ucm.metric_type\n            ORDER BY ucm.activity_hour\n            RANGE BETWEEN INTERVAL '24 hours' PRECEDING AND CURRENT ROW\n        ) AS type_24h_avg\n    FROM union_combined_metrics ucm\n    GROUP BY ucm.activity_hour, ucm.metric_type, ucm.metric_value\n),\nfinal_time_series_analytics AS (\n    -- Seventh CTE: Final analytics with comprehensive window functions\n    SELECT\n        ta.activity_hour,\n        ta.message_count,\n        ta.active_chats,\n        ta.active_users,\n        ta.user_messages,\n        ta.ai_messages,\n        ta.chats_with_ai_interaction,\n        ROUND(CAST(ta.avg_message_length AS NUMERIC), 2) AS avg_message_length,\n        ROUND(CAST(ta.median_message_length AS NUMERIC), 2) AS median_message_length,\n        ROUND(CAST(ta.avg_user_message_length AS NUMERIC), 2) AS avg_user_message_length,\n        ta.messages_12h_window,\n        ta.messages_12h_range,\n        ROUND(CAST(ta.avg_messages_24h_rows AS NUMERIC), 2) AS avg_24h_rows,\n        ROUND(CAST(ta.avg_messages_24h_range AS NUMERIC), 2) AS avg_24h_range,\n        ta.max_messages_24h_rows,\n        ta.min_messages_24h_rows,\n        ta.prev_hour_messages,\n        ta.prev2_hour_messages,\n        ta.next_hour_messages,\n        ta.next2_hour_messages,\n        ta.first_value_24h,\n        ta.last_value_24h,\n        ta.hour_over_hour_change,\n        ROUND(CAST(ta.hour_over_hour_percent_change AS NUMERIC), 2) AS hour_over_hour_percent_change,\n        ta.activity_level,\n        ta.activity_trend,\n        ROUND(CAST(ta.volatility_ratio AS NUMERIC), 3) AS volatility_ratio,\n        -- Additional window functions\n        ROW_NUMBER() OVER (ORDER BY ta.message_count DESC) AS volume_rank,\n        RANK() OVER (ORDER BY ta.volatility_ratio DESC) AS volatility_rank,\n        DENSE_RANK() OVER (PARTITION BY ta.activity_level ORDER BY ta.message_count DESC) AS level_rank,\n        PERCENT_RANK() OVER (ORDER BY ta.message_count DESC) AS volume_percentile,\n        NTILE(5) OVER (ORDER BY ta.message_count DESC) AS volume_quintile,\n        -- Running totals with frames\n        SUM(ta.message_count) OVER (\n            ORDER BY ta.activity_hour\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_messages,\n        SUM(ta.message_count) OVER (\n            PARTITION BY ta.activity_level\n            ORDER BY ta.activity_hour\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS level_cumulative_messages\n    FROM trend_analysis ta\n)\nSELECT\n    activity_hour,\n    message_count,\n    active_chats,\n    active_users,\n    user_messages,\n    ai_messages,\n    chats_with_ai_interaction,\n    avg_message_length,\n    median_message_length,\n    avg_user_message_length,\n    messages_12h_window,\n    messages_12h_range,\n    avg_24h_rows,\n    avg_24h_range,\n    max_messages_24h_rows,\n    min_messages_24h_rows,\n    prev_hour_messages,\n    prev2_hour_messages,\n    next_hour_messages,\n    next2_hour_messages,\n    first_value_24h,\n    last_value_24h,\n    hour_over_hour_change,\n    hour_over_hour_percent_change,\n    activity_level,\n    activity_trend,\n    volatility_ratio,\n    volume_rank,\n    volatility_rank,\n    level_rank,\n    ROUND(CAST(volume_percentile * 100 AS NUMERIC), 2) AS volume_percentile,\n    volume_quintile,\n    cumulative_messages,\n    level_cumulative_messages\nFROM final_time_series_analytics\nORDER BY activity_hour DESC;",
      "line_number": 2003
    },
    {
      "number": 6,
      "title": "Production-Grade Chat Engagement Scoring with Recursive CTE and Advanced Analytics",
      "description": "Description: Enterprise-level chat engagement scoring with recursive CTE for participant network analysis, multiple nested CTEs, correlated subqueries, UNION operations, and comprehensive window function analytics. Implements production patterns similar to engagement scoring systems. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses, correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses, correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE participant_network AS (\n    -- Anchor: Direct participant connections\n    SELECT\n        CAST(NULL AS uuid) AS user_a,\n        cp2.user_id AS user_b,\n        CAST(NULL AS uuid) AS chat_id,\n        1 AS connection_depth,\n        ARRAY[CAST(NULL AS uuid), cp2.user_id] AS path\n    FROM chat_participants cp1\n    INNER JOIN chat_participants cp2 ON cp1.chat_id = cp2.chat_id\n    WHERE cp1.user_id < cp2.user_id\n\n    UNION ALL\n\n    -- Recursive: Find participants connected through multiple chats\n    SELECT\n        pn.user_a,\n        cp3.user_id AS user_b,\n        cp3.chat_id,\n        pn.connection_depth + 1,\n        pn.path || cp3.user_id\n    FROM participant_network pn\n    INNER JOIN chat_participants cp2 ON pn.user_b = cp2.user_id\n    INNER JOIN chat_participants cp3 ON cp2.chat_id = cp3.chat_id\n    WHERE cp3.user_id != ALL(pn.path)\n        AND pn.connection_depth < 3\n),\nchat_message_metrics AS (\n    -- First CTE: Base message metrics with joins\n    SELECT\n        c.id AS chat_id,\n        c.title,\n        COUNT(m.id) AS total_messages,\n        COUNT(DISTINCT m.sender_id) AS unique_participants,\n        COUNT(DISTINCT DATE(m.created_at)) AS active_days,\n        MAX(m.created_at) - MIN(m.created_at) AS chat_duration,\n        AVG(LENGTH(m.content)) AS avg_message_length,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY LENGTH(m.content)) AS median_message_length,\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY LENGTH(m.content)) AS p25_message_length,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY LENGTH(m.content)) AS p75_message_length\n    FROM chats c\n    LEFT JOIN messages m ON c.id = m.chat_id\n    GROUP BY c.id, c.title\n),\nchat_participant_metrics AS (\n    -- Second CTE: Participant metrics with correlated subqueries\n    SELECT\n        c.id AS chat_id,\n        COUNT(DISTINCT cp.user_id) AS total_participants,\n        COUNT(DISTINCT CASE WHEN cp.joined_at >= CURRENT_DATE - INTERVAL '7 days' THEN cp.user_id END) AS recent_participants,\n        COUNT(DISTINCT CASE WHEN cp.joined_at >= CURRENT_DATE - INTERVAL '30 days' THEN cp.user_id END) AS monthly_participants,\n        (\n            SELECT COUNT(DISTINCT m2.sender_id)\n            FROM messages m2\n            WHERE m2.chat_id = c.id\n                AND m2.created_at >= CURRENT_DATE - INTERVAL '7 days'\n        ) AS active_participants_7d,\n        (\n            SELECT AVG(message_count)\n            FROM (\n                SELECT COUNT(*) AS message_count\n                FROM messages m3\n                WHERE m3.chat_id = c.id\n                GROUP BY m3.sender_id\n            ) participant_counts\n        ) AS avg_messages_per_participant\n    FROM chats c\n    LEFT JOIN chat_participants cp ON c.id = cp.chat_id\n    GROUP BY c.id\n),\nnetwork_connectivity_metrics AS (\n    -- Third CTE: Network connectivity from recursive CTE\n    SELECT\n        chat_id,\n        COUNT(DISTINCT user_a) + COUNT(DISTINCT user_b) AS total_connected_users,\n        AVG(connection_depth) AS avg_connection_depth,\n        MAX(connection_depth) AS max_connection_depth,\n        COUNT(*) AS total_connections\n    FROM participant_network\n    GROUP BY chat_id\n),\nengagement_calculation_base AS (\n    -- Fourth CTE: Base engagement calculations\n    SELECT\n        cmm.chat_id,\n        cmm.title,\n        cmm.total_messages,\n        cmm.unique_participants,\n        cmm.active_days,\n        EXTRACT(EPOCH FROM cmm.chat_duration) / 86400 AS duration_days,\n        cmm.avg_message_length,\n        cmm.median_message_length,\n        cmm.p25_message_length,\n        cmm.p75_message_length,\n        cpm.total_participants,\n        cpm.recent_participants,\n        cpm.monthly_participants,\n        cpm.active_participants_7d,\n        cpm.avg_messages_per_participant,\n        COALESCE(ncm.total_connected_users, 0) AS network_connected_users,\n        COALESCE(ncm.avg_connection_depth, 0) AS network_avg_depth,\n        COALESCE(ncm.total_connections, 0) AS network_total_connections\n    FROM chat_message_metrics cmm\n    INNER JOIN chat_participant_metrics cpm ON cmm.chat_id = cpm.chat_id\n    LEFT JOIN network_connectivity_metrics ncm ON cmm.chat_id = ncm.chat_id\n),\nengagement_scoring AS (\n    -- Fifth CTE: Multi-factor engagement scoring with window functions\n    SELECT\n        ecb.*,\n        -- Component scores\n        (ecb.total_messages * 0.25) AS message_volume_score,\n        (ecb.unique_participants * 8 * 0.20) AS participation_score,\n        (ecb.active_days * 4 * 0.15) AS activity_frequency_score,\n        (COALESCE(ecb.recent_participants, 0) * 12 * 0.15) AS recency_score,\n        (COALESCE(ecb.avg_message_length, 0) / 8 * 0.10) AS content_quality_score,\n        (COALESCE(ecb.network_connected_users, 0) * 3 * 0.10) AS network_score,\n        (COALESCE(ecb.avg_messages_per_participant, 0) * 2 * 0.05) AS engagement_depth_score,\n        -- Raw engagement score\n        (\n            (ecb.total_messages * 0.25) +\n            (ecb.unique_participants * 8 * 0.20) +\n            (ecb.active_days * 4 * 0.15) +\n            (COALESCE(ecb.recent_participants, 0) * 12 * 0.15) +\n            (COALESCE(ecb.avg_message_length, 0) / 8 * 0.10) +\n            (COALESCE(ecb.network_connected_users, 0) * 3 * 0.10) +\n            (COALESCE(ecb.avg_messages_per_participant, 0) * 2 * 0.05)\n        ) AS raw_engagement_score,\n        -- Window functions for comparison\n        AVG(ecb.total_messages) OVER () AS overall_avg_messages,\n        AVG(ecb.unique_participants) OVER () AS overall_avg_participants,\n        PERCENT_RANK() OVER (ORDER BY ecb.total_messages DESC) AS message_percentile,\n        PERCENT_RANK() OVER (ORDER BY ecb.unique_participants DESC) AS participant_percentile\n    FROM engagement_calculation_base ecb\n),\nunion_engagement_components AS (\n    -- Sixth CTE: UNION to combine different engagement components\n    SELECT\n        es.chat_id,\n        'volume' AS component_type,\n        es.message_volume_score AS component_score,\n        es.raw_engagement_score\n    FROM engagement_scoring es\n\n    UNION ALL\n\n    SELECT\n        es.chat_id,\n        'participation' AS component_type,\n        es.participation_score AS component_score,\n        es.raw_engagement_score\n    FROM engagement_scoring es\n\n    UNION ALL\n\n    SELECT\n        es.chat_id,\n        'recency' AS component_type,\n        es.recency_score AS component_score,\n        es.raw_engagement_score\n    FROM engagement_scoring es\n\n    UNION ALL\n\n    SELECT\n        es.chat_id,\n        'network' AS component_type,\n        es.network_score AS component_score,\n        es.raw_engagement_score\n    FROM engagement_scoring es\n),\ncomponent_aggregation AS (\n    -- Seventh CTE: Aggregate UNION results with window functions\n    SELECT\n        uec.chat_id,\n        SUM(CASE WHEN uec.component_type = 'volume' THEN uec.component_score ELSE 0 END) AS total_volume_score,\n        SUM(CASE WHEN uec.component_type = 'participation' THEN uec.component_score ELSE 0 END) AS total_participation_score,\n        SUM(CASE WHEN uec.component_type = 'recency' THEN uec.component_score ELSE 0 END) AS total_recency_score,\n        SUM(CASE WHEN uec.component_type = 'network' THEN uec.component_score ELSE 0 END) AS total_network_score,\n        MAX(uec.raw_engagement_score) AS raw_engagement_score,\n        COUNT(DISTINCT uec.component_type) AS component_count,\n        -- Window functions on components\n        AVG(uec.component_score) OVER (\n            PARTITION BY uec.component_type\n            ORDER BY uec.raw_engagement_score DESC\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS component_moving_avg,\n        SUM(uec.component_score) OVER (\n            PARTITION BY uec.chat_id\n            ORDER BY uec.component_type\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS chat_cumulative_component_score\n    FROM union_engagement_components uec\n    GROUP BY uec.chat_id, uec.component_type, uec.component_score, uec.raw_engagement_score, uec.raw_engagement_score\n),\nnormalized_engagement_scores AS (\n    -- Eighth CTE: Normalize scores with comprehensive window functions\n    SELECT\n        es.chat_id,\n        es.title,\n        es.total_messages,\n        es.unique_participants,\n        es.active_days,\n        ROUND(CAST(es.duration_days AS NUMERIC), 1) AS duration_days,\n        ROUND(CAST(es.avg_message_length AS NUMERIC), 2) AS avg_message_length,\n        ROUND(CAST(es.median_message_length AS NUMERIC), 2) AS median_message_length,\n        es.total_participants,\n        es.recent_participants,\n        es.monthly_participants,\n        es.active_participants_7d,\n        ROUND(CAST(es.avg_messages_per_participant AS NUMERIC), 2) AS avg_messages_per_participant,\n        es.network_connected_users,\n        ROUND(CAST(es.network_avg_depth AS NUMERIC), 2) AS network_avg_depth,\n        es.network_total_connections,\n        ROUND(CAST(es.raw_engagement_score AS NUMERIC), 2) AS engagement_score,\n        ROUND(CAST(es.message_volume_score AS NUMERIC), 2) AS volume_score,\n        ROUND(CAST(es.participation_score AS NUMERIC), 2) AS participation_score,\n        ROUND(CAST(es.recency_score AS NUMERIC), 2) AS recency_score,\n        ROUND(CAST(es.network_score AS NUMERIC), 2) AS network_score,\n        ROUND(CAST(es.message_percentile * 100 AS NUMERIC), 2) AS message_percentile,\n        ROUND(CAST(es.participant_percentile * 100 AS NUMERIC), 2) AS participant_percentile,\n        -- Multiple ranking methods\n        ROW_NUMBER() OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_rank,\n        RANK() OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_rank_standard,\n        DENSE_RANK() OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_percentile,\n        NTILE(5) OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_quintile,\n        NTILE(10) OVER (ORDER BY es.raw_engagement_score DESC) AS engagement_decile,\n        -- Window functions with frames\n        SUM(es.raw_engagement_score) OVER (\n            ORDER BY es.raw_engagement_score DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_engagement_score,\n        AVG(es.raw_engagement_score) OVER (\n            ORDER BY es.raw_engagement_score DESC\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS moving_avg_engagement_score,\n        LAG(es.raw_engagement_score, 1) OVER (ORDER BY es.raw_engagement_score DESC) AS prev_engagement_score,\n        LEAD(es.raw_engagement_score, 1) OVER (ORDER BY es.raw_engagement_score DESC) AS next_engagement_score,\n        -- Pivot CASE for classification\n        CASE\n            WHEN es.raw_engagement_score >= 80 THEN 'Champion'\n            WHEN es.raw_engagement_score >= 60 THEN 'Power User'\n            WHEN es.raw_engagement_score >= 40 THEN 'Regular'\n            WHEN es.raw_engagement_score >= 20 THEN 'Casual'\n            ELSE 'Inactive'\n        END AS engagement_category,\n        CASE\n            WHEN es.recent_participants::numeric / NULLIF(es.total_participants, 0) > 0.5 THEN 'High Recency'\n            WHEN es.recent_participants::numeric / NULLIF(es.total_participants, 0) > 0.3 THEN 'Medium Recency'\n            ELSE 'Low Recency'\n        END AS recency_category\n    FROM engagement_scoring es\n)\nSELECT\n    chat_id,\n    title,\n    total_messages,\n    unique_participants,\n    active_days,\n    duration_days,\n    avg_message_length,\n    median_message_length,\n    total_participants,\n    recent_participants,\n    monthly_participants,\n    active_participants_7d,\n    avg_messages_per_participant,\n    network_connected_users,\n    network_avg_depth,\n    network_total_connections,\n    engagement_score,\n    volume_score,\n    participation_score,\n    recency_score,\n    network_score,\n    message_percentile,\n    participant_percentile,\n    engagement_rank,\n    engagement_rank_standard,\n    engagement_dense_rank,\n    ROUND(CAST(engagement_percentile * 100 AS NUMERIC), 2) AS engagement_percentile,\n    engagement_quintile,\n    engagement_decile,\n    ROUND(CAST(cumulative_engagement_score AS NUMERIC), 2) AS cumulative_engagement_score,\n    ROUND(CAST(moving_avg_engagement_score AS NUMERIC), 2) AS moving_avg_engagement_score,\n    ROUND(CAST(prev_engagement_score AS NUMERIC), 2) AS prev_engagement_score,\n    ROUND(CAST(next_engagement_score AS NUMERIC), 2) AS next_engagement_score,\n    engagement_category,\n    recency_category\nFROM normalized_engagement_scores\nORDER BY engagement_score DESC;",
      "line_number": 2514
    },
    {
      "number": 7,
      "title": "Production-Grade Notification Delivery Analysis with Recursive CTE and Advanced Analytics",
      "description": "Description: Enterprise-level notification delivery analysis with recursive CTE for notification cascade tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive analytics. Implements production patterns similar to notification delivery systems. Complexity: Recursive CTE, multiple nested CTEs (7+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggreg",
      "complexity": "Recursive CTE, multiple nested CTEs (7+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE notification_cascade AS (\n    -- Anchor: Base notifications\n    SELECT\n        n.id,\n        n.user_id,\n        n.type,\n        n.created_at,\n        n.read,\n        n.seen_at,\n        1 AS cascade_depth,\n        ARRAY[n.id] AS cascade_path\n    FROM notifications n\n\n    UNION ALL\n\n    -- Recursive: Find related notifications in cascade\n    SELECT\n        n2.id,\n        n2.user_id,\n        n2.type,\n        n2.created_at,\n        n2.read,\n        n2.seen_at,\n        nc.cascade_depth + 1,\n        nc.cascade_path || n2.id\n    FROM notification_cascade nc\n    INNER JOIN notifications n2 ON nc.user_id = n2.user_id\n    WHERE n2.id != ALL(nc.cascade_path)\n        AND n2.created_at BETWEEN nc.created_at AND nc.created_at + INTERVAL '1 hour'\n        AND nc.cascade_depth < 3\n),\nnotification_timeline AS (\n    -- First CTE: Base timeline with joins\n    SELECT\n        n.id,\n        n.user_id,\n        n.type,\n        n.created_at,\n        n.read,\n        n.seen_at,\n        p.username,\n        EXTRACT(EPOCH FROM (COALESCE(n.seen_at, CURRENT_TIMESTAMP) - n.created_at)) / 60 AS minutes_to_seen,\n        CASE WHEN n.read = true THEN 1 ELSE 0 END AS is_read,\n        CASE WHEN n.seen_at IS NOT NULL THEN 1 ELSE 0 END AS is_seen,\n        (\n            SELECT COUNT(*)\n            FROM notifications n2\n            WHERE n2.user_id = n.user_id\n                AND n2.type = n.type\n                AND n2.created_at < n.created_at\n        ) AS prior_notifications_of_type,\n        (\n            SELECT AVG(EXTRACT(EPOCH FROM (COALESCE(n3.seen_at, CURRENT_TIMESTAMP) - n3.created_at)) / 60)\n            FROM notifications n3\n            WHERE n3.user_id = n.user_id\n                AND n3.type = n.type\n                AND n3.created_at < n.created_at\n        ) AS avg_prior_minutes_to_seen\n    FROM notifications n\n    INNER JOIN profiles p ON n.user_id = p.id\n),\nuser_notification_stats AS (\n    -- Second CTE: User-level statistics with correlated subqueries\n    SELECT\n        nt.user_id,\n        nt.type,\n        COUNT(*) AS total_notifications,\n        SUM(nt.is_read) AS read_count,\n        SUM(nt.is_seen) AS seen_count,\n        AVG(nt.minutes_to_seen) AS avg_minutes_to_seen,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY nt.minutes_to_seen) AS median_minutes_to_seen,\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY nt.minutes_to_seen) AS p25_minutes_to_seen,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY nt.minutes_to_seen) AS p75_minutes_to_seen,\n        MIN(nt.minutes_to_seen) AS min_minutes_to_seen,\n        MAX(nt.minutes_to_seen) AS max_minutes_to_seen,\n        STDDEV(nt.minutes_to_seen) AS stddev_minutes_to_seen,\n        AVG(nt.prior_notifications_of_type) AS avg_prior_notifications,\n        AVG(nt.avg_prior_minutes_to_seen) AS avg_historical_minutes_to_seen\n    FROM notification_timeline nt\n    GROUP BY nt.user_id, nt.type\n),\nrolling_window_stats AS (\n    -- Third CTE: Rolling window statistics with frame clauses\n    SELECT\n        uns.user_id,\n        uns.type,\n        uns.total_notifications,\n        uns.read_count,\n        uns.seen_count,\n        uns.avg_minutes_to_seen,\n        uns.median_minutes_to_seen,\n        uns.p25_minutes_to_seen,\n        uns.p75_minutes_to_seen,\n        uns.min_minutes_to_seen,\n        uns.max_minutes_to_seen,\n        uns.stddev_minutes_to_seen,\n        uns.avg_prior_notifications,\n        uns.avg_historical_minutes_to_seen,\n        -- Window functions with ROWS BETWEEN frames\n        SUM(uns.total_notifications) OVER (\n            PARTITION BY uns.type\n            ORDER BY uns.user_id\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS type_10_user_window,\n        AVG(uns.avg_minutes_to_seen) OVER (\n            PARTITION BY uns.type\n            ORDER BY uns.user_id\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS type_20_user_avg,\n        -- Window functions with RANGE BETWEEN frames\n        SUM(uns.read_count) OVER (\n            PARTITION BY uns.type\n            ORDER BY uns.avg_minutes_to_seen\n            RANGE BETWEEN 30 PRECEDING AND 30 FOLLOWING\n        ) AS read_count_range_window,\n        -- Lag/Lead functions\n        LAG(uns.avg_minutes_to_seen, 1) OVER (PARTITION BY uns.type ORDER BY uns.user_id) AS prev_user_avg_minutes,\n        LEAD(uns.avg_minutes_to_seen, 1) OVER (PARTITION BY uns.type ORDER BY uns.user_id) AS next_user_avg_minutes,\n        -- First/Last value with frames\n        FIRST_VALUE(uns.avg_minutes_to_seen) OVER (\n            PARTITION BY uns.type\n            ORDER BY uns.user_id\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_user_avg_minutes,\n        LAST_VALUE(uns.avg_minutes_to_seen) OVER (\n            PARTITION BY uns.type\n            ORDER BY uns.user_id\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_user_avg_minutes\n    FROM user_notification_stats uns\n),\ntype_aggregates AS (\n    -- Fourth CTE: Type-level aggregates\n    SELECT\n        rws.type,\n        COUNT(DISTINCT rws.user_id) AS users_with_type,\n        SUM(rws.total_notifications) AS total_type_notifications,\n        SUM(rws.read_count) AS total_read,\n        SUM(rws.seen_count) AS total_seen,\n        AVG(rws.avg_minutes_to_seen) AS overall_avg_minutes,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY rws.avg_minutes_to_seen) AS overall_median_minutes,\n        AVG(rws.read_count::numeric / NULLIF(rws.total_notifications, 0)) AS avg_read_rate,\n        AVG(rws.seen_count::numeric / NULLIF(rws.total_notifications, 0)) AS avg_seen_rate,\n        AVG(rws.type_10_user_window) AS avg_10_user_window,\n        AVG(rws.type_20_user_avg) AS avg_20_user_rolling_avg,\n        AVG(rws.read_count_range_window) AS avg_read_count_range_window\n    FROM rolling_window_stats rws\n    GROUP BY rws.type\n),\nunion_metrics AS (\n    -- Fifth CTE: UNION to combine different metric types\n    SELECT\n        ta.type,\n        'read_rate' AS metric_type,\n        ta.avg_read_rate AS metric_value\n    FROM type_aggregates ta\n\n    UNION ALL\n\n    SELECT\n        ta.type,\n        'seen_rate' AS metric_type,\n        ta.avg_seen_rate AS metric_value\n    FROM type_aggregates ta\n\n    UNION ALL\n\n    SELECT\n        ta.type,\n        'avg_minutes' AS metric_type,\n        ta.overall_avg_minutes AS metric_value\n    FROM type_aggregates ta\n),\naggregated_union_metrics AS (\n    -- Sixth CTE: Aggregate UNION results with window functions\n    SELECT\n        NULL,\n        SUM(CASE WHEN NULL = 'read_rate' THEN NULL ELSE 0 END) AS total_read_rate,\n        SUM(CASE WHEN NULL = 'seen_rate' THEN NULL ELSE 0 END) AS total_seen_rate,\n        SUM(CASE WHEN NULL = 'avg_minutes' THEN NULL ELSE 0 END) AS total_avg_minutes,\n        COUNT(DISTINCT NULL) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(CAST(0 AS NUMERIC)) OVER (\n            PARTITION BY rws.type\n            ORDER BY rws.type\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(CAST(0 AS NUMERIC)) OVER (\n            PARTITION BY rws.type\n            ORDER BY rws.type\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS type_cumulative_metric\n    FROM rolling_window_stats rws\n    GROUP BY rws.type\n),\nfinal_notification_analytics AS (\n    -- Seventh CTE: Final analytics with comprehensive window functions\n    SELECT\n        ta.type,\n        ta.users_with_type,\n        ta.total_type_notifications,\n        ta.total_read,\n        ta.total_seen,\n        ROUND(CAST(ta.avg_read_rate * 100 AS NUMERIC), 2) AS read_rate_percent,\n        ROUND(CAST(ta.avg_seen_rate * 100 AS NUMERIC), 2) AS seen_rate_percent,\n        ROUND(CAST(ta.overall_avg_minutes AS NUMERIC), 2) AS avg_minutes_to_seen,\n        ROUND(CAST(ta.overall_median_minutes AS NUMERIC), 2) AS median_minutes_to_seen,\n        ROUND(CAST(ta.avg_10_user_window AS NUMERIC), 2) AS avg_10_user_window,\n        ROUND(CAST(ta.avg_20_user_rolling_avg AS NUMERIC), 2) AS avg_20_user_rolling_avg,\n        ROUND(CAST(ta.avg_read_count_range_window AS NUMERIC), 2) AS avg_read_count_range_window,\n        -- Multiple ranking methods\n        ROW_NUMBER() OVER (ORDER BY ta.avg_read_rate DESC) AS read_rate_row_num,\n        RANK() OVER (ORDER BY ta.avg_read_rate DESC) AS read_rate_rank,\n        DENSE_RANK() OVER (ORDER BY ta.avg_seen_rate DESC) AS seen_rate_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY ta.avg_read_rate DESC) AS read_rate_percentile,\n        NTILE(5) OVER (ORDER BY ta.avg_read_rate DESC) AS read_rate_quintile,\n        NTILE(10) OVER (ORDER BY ta.avg_seen_rate DESC) AS seen_rate_decile,\n        -- Window functions with frames\n        SUM(ta.total_type_notifications) OVER (\n            ORDER BY ta.avg_read_rate DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_notifications,\n        AVG(ta.avg_read_rate) OVER (\n            ORDER BY ta.avg_read_rate DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_read_rate,\n        LAG(ta.avg_read_rate, 1) OVER (ORDER BY ta.avg_read_rate DESC) AS prev_read_rate,\n        LEAD(ta.avg_seen_rate, 1) OVER (ORDER BY ta.avg_seen_rate DESC) AS next_seen_rate,\n        -- Pivot CASE for classification\n        CASE\n            WHEN ta.avg_read_rate >= 0.8 THEN 'Excellent Read Rate'\n            WHEN ta.avg_read_rate >= 0.6 THEN 'Good Read Rate'\n            WHEN ta.avg_read_rate >= 0.4 THEN 'Fair Read Rate'\n            ELSE 'Poor Read Rate'\n        END AS read_rate_category,\n        CASE\n            WHEN ta.overall_avg_minutes <= 5 THEN 'Immediate'\n            WHEN ta.overall_avg_minutes <= 30 THEN 'Quick'\n            WHEN ta.overall_avg_minutes <= 60 THEN 'Moderate'\n            ELSE 'Slow'\n        END AS response_time_category\n    FROM type_aggregates ta\n)\nSELECT\n    type,\n    users_with_type,\n    total_type_notifications,\n    total_read,\n    total_seen,\n    read_rate_percent,\n    seen_rate_percent,\n    avg_minutes_to_seen,\n    median_minutes_to_seen,\n    avg_10_user_window,\n    avg_20_user_rolling_avg,\n    avg_read_count_range_window,\n    read_rate_row_num,\n    read_rate_rank,\n    seen_rate_dense_rank,\n    ROUND(CAST(read_rate_percentile * 100 AS NUMERIC), 2) AS read_rate_percentile,\n    read_rate_quintile,\n    seen_rate_decile,\n    cumulative_notifications,\n    ROUND(CAST(moving_avg_read_rate * 100 AS NUMERIC), 2) AS moving_avg_read_rate,\n    ROUND(CAST(prev_read_rate * 100 AS NUMERIC), 2) AS prev_read_rate,\n    ROUND(CAST(next_seen_rate * 100 AS NUMERIC), 2) AS next_seen_rate,\n    read_rate_category,\n    response_time_category\nFROM final_notification_analytics\nORDER BY total_type_notifications DESC;",
      "line_number": 3032
    },
    {
      "number": 8,
      "title": "Production-Grade File Attachment Analysis with Recursive CTE and Advanced Metrics",
      "description": "Description: Enterprise-level file attachment analysis with recursive CTE for upload chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive size distribution analytics. Implements production patterns similar to file storage analytics systems. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, a",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE upload_chain AS (\n    -- Anchor: Base uploads\n    SELECT\n        fa.id,\n        fa.chat_id,\n        fa.user_id,\n        fa.file_size,\n        fa.created_at,\n        1 AS chain_depth,\n        ARRAY[fa.id] AS chain_path\n    FROM file_attachments fa\n\n    UNION ALL\n\n    -- Recursive: Find related uploads in same chat by same user\n    SELECT\n        fa2.id,\n        fa2.chat_id,\n        fa2.user_id,\n        fa2.file_size,\n        fa2.created_at,\n        uc.chain_depth + 1,\n        uc.chain_path || fa2.id\n    FROM upload_chain uc\n    INNER JOIN file_attachments fa2 ON uc.chat_id = fa2.chat_id AND uc.user_id = fa2.user_id\n    WHERE fa2.id != ALL(uc.chain_path)\n        AND fa2.created_at BETWEEN uc.created_at AND uc.created_at + INTERVAL '1 hour'\n        AND uc.chain_depth < 3\n),\nattachment_stats AS (\n    -- First CTE: Base attachment stats with joins and correlated subqueries\n    SELECT\n        fa.id,\n        fa.chat_id,\n        fa.user_id,\n        fa.file_name,\n        fa.file_size,\n        fa.created_at,\n        c.title AS chat_title,\n        p.username AS uploader_username,\n        (\n            SELECT COUNT(*)\n            FROM file_attachments fa2\n            WHERE fa2.chat_id = fa.chat_id\n                AND fa2.created_at < fa.created_at\n        ) AS prior_uploads_in_chat,\n        (\n            SELECT AVG(fa3.file_size)\n            FROM file_attachments fa3\n            WHERE fa3.chat_id = fa.chat_id\n                AND fa3.created_at < fa.created_at\n        ) AS avg_prior_file_size,\n        (\n            SELECT COUNT(DISTINCT fa4.user_id)\n            FROM file_attachments fa4\n            WHERE fa4.chat_id = fa.chat_id\n                AND EXISTS (\n                    SELECT 1\n                    FROM file_attachments fa5\n                    WHERE fa5.chat_id = fa.chat_id\n                        AND fa5.user_id = fa4.user_id\n                        AND fa5.created_at < fa.created_at\n                )\n        ) AS prior_uploaders_count\n    FROM file_attachments fa\n    INNER JOIN chats c ON fa.chat_id = c.id\n    INNER JOIN profiles p ON fa.user_id = p.id\n),\nchat_attachment_metrics AS (\n    -- Second CTE: Chat-level metrics with aggregations\n    SELECT\n        as1.chat_id,\n        as1.chat_title,\n        COUNT(*) AS total_attachments,\n        COUNT(DISTINCT as1.user_id) AS unique_uploaders,\n        SUM(as1.file_size) AS total_size_bytes,\n        AVG(as1.file_size) AS avg_file_size,\n        MIN(as1.file_size) AS min_file_size,\n        MAX(as1.file_size) AS max_file_size,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY as1.file_size) AS median_file_size,\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY as1.file_size) AS p25_file_size,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY as1.file_size) AS p75_file_size,\n        STDDEV(as1.file_size) AS stddev_file_size,\n        AVG(as1.prior_uploads_in_chat) AS avg_prior_uploads,\n        AVG(as1.avg_prior_file_size) AS avg_historical_file_size,\n        AVG(as1.prior_uploaders_count) AS avg_prior_uploaders\n    FROM attachment_stats as1\n    GROUP BY as1.chat_id, as1.chat_title\n),\nupload_chain_metrics AS (\n    -- Third CTE: Upload chain metrics from recursive CTE\n    SELECT\n        chat_id,\n        COUNT(DISTINCT user_id) AS uploaders_with_chains,\n        AVG(chain_depth) AS avg_chain_depth,\n        MAX(chain_depth) AS max_chain_depth,\n        COUNT(*) AS total_chain_uploads\n    FROM upload_chain\n    GROUP BY chat_id\n),\nrolling_window_metrics AS (\n    -- Fourth CTE: Rolling window statistics with frame clauses\n    SELECT\n        cam.chat_id,\n        cam.chat_title,\n        cam.total_attachments,\n        cam.unique_uploaders,\n        cam.total_size_bytes,\n        cam.avg_file_size,\n        cam.min_file_size,\n        cam.max_file_size,\n        cam.median_file_size,\n        cam.p25_file_size,\n        cam.p75_file_size,\n        cam.stddev_file_size,\n        cam.avg_prior_uploads,\n        cam.avg_historical_file_size,\n        cam.avg_prior_uploaders,\n        COALESCE(ucm.uploaders_with_chains, 0) AS uploaders_with_chains,\n        COALESCE(ucm.avg_chain_depth, 0) AS avg_chain_depth,\n        COALESCE(ucm.max_chain_depth, 0) AS max_chain_depth,\n        COALESCE(ucm.total_chain_uploads, 0) AS total_chain_uploads,\n        -- Window functions with ROWS BETWEEN frames\n        SUM(cam.total_attachments) OVER (\n            ORDER BY cam.total_attachments DESC\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS attachments_10_chat_window,\n        AVG(cam.total_size_bytes) OVER (\n            ORDER BY cam.total_size_bytes DESC\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS size_20_chat_avg,\n        -- Window functions with RANGE BETWEEN frames\n        SUM(cam.total_attachments) OVER (\n            ORDER BY cam.avg_file_size\n            RANGE BETWEEN 100000 PRECEDING AND 100000 FOLLOWING\n        ) AS attachments_size_range_window,\n        -- Lag/Lead functions\n        LAG(cam.total_attachments, 1) OVER (ORDER BY cam.total_attachments DESC) AS prev_chat_attachments,\n        LEAD(cam.total_size_bytes, 1) OVER (ORDER BY cam.total_size_bytes DESC) AS next_chat_size,\n        -- First/Last value with frames\n        FIRST_VALUE(cam.avg_file_size) OVER (\n            ORDER BY cam.total_attachments DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_chat_avg_size,\n        LAST_VALUE(cam.median_file_size) OVER (\n            ORDER BY cam.total_attachments DESC\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_chat_median_size\n    FROM chat_attachment_metrics cam\n    LEFT JOIN upload_chain_metrics ucm ON cam.chat_id = ucm.chat_id\n),\nsize_distribution AS (\n    -- Fifth CTE: Size distribution with pivot CASE\n    SELECT\n        rwm.chat_id,\n        rwm.chat_title,\n        rwm.total_attachments,\n        rwm.unique_uploaders,\n        rwm.total_size_bytes,\n        ROUND(CAST(rwm.total_size_bytes / 1024.0 / 1024.0 AS NUMERIC), 2) AS total_size_mb,\n        ROUND(CAST(rwm.avg_file_size / 1024.0 AS NUMERIC), 2) AS avg_file_size_kb,\n        ROUND(CAST(rwm.median_file_size / 1024.0 AS NUMERIC), 2) AS median_file_size_kb,\n        ROUND(CAST(rwm.p25_file_size / 1024.0 AS NUMERIC), 2) AS p25_file_size_kb,\n        ROUND(CAST(rwm.p75_file_size / 1024.0 AS NUMERIC), 2) AS p75_file_size_kb,\n        ROUND(CAST(rwm.max_file_size / 1024.0 AS NUMERIC), 2) AS max_file_size_kb,\n        ROUND(CAST(rwm.stddev_file_size / 1024.0 AS NUMERIC), 2) AS stddev_file_size_kb,\n        rwm.avg_prior_uploads,\n        ROUND(CAST(rwm.avg_historical_file_size / 1024.0 AS NUMERIC), 2) AS avg_historical_file_size_kb,\n        rwm.uploaders_with_chains,\n        ROUND(CAST(rwm.avg_chain_depth AS NUMERIC), 2) AS avg_chain_depth,\n        rwm.max_chain_depth,\n        rwm.total_chain_uploads,\n        rwm.attachments_10_chat_window,\n        ROUND(CAST(rwm.size_20_chat_avg / 1024.0 / 1024.0 AS NUMERIC), 2) AS size_20_chat_avg_mb,\n        rwm.attachments_size_range_window,\n        rwm.prev_chat_attachments,\n        ROUND(CAST(rwm.next_chat_size / 1024.0 / 1024.0 AS NUMERIC), 2) AS next_chat_size_mb,\n        ROUND(CAST(rwm.first_chat_avg_size / 1024.0 AS NUMERIC), 2) AS first_chat_avg_size_kb,\n        ROUND(CAST(rwm.last_chat_median_size / 1024.0 AS NUMERIC), 2) AS last_chat_median_size_kb,\n        -- Pivot CASE for size categorization\n        CASE\n            WHEN rwm.avg_file_size < 100 * 1024 THEN 'Small'\n            WHEN rwm.avg_file_size < 500 * 1024 THEN 'Medium-Small'\n            WHEN rwm.avg_file_size < 1024 * 1024 THEN 'Medium'\n            WHEN rwm.avg_file_size < 5 * 1024 * 1024 THEN 'Large'\n            ELSE 'Very Large'\n        END AS size_category,\n        CASE\n            WHEN rwm.total_attachments < 5 THEN 'Low Volume'\n            WHEN rwm.total_attachments < 20 THEN 'Medium Volume'\n            WHEN rwm.total_attachments < 50 THEN 'High Volume'\n            ELSE 'Very High Volume'\n        END AS volume_category,\n        -- Window function rankings\n        ROW_NUMBER() OVER (ORDER BY rwm.total_attachments DESC) AS attachment_count_row_num,\n        RANK() OVER (ORDER BY rwm.total_attachments DESC) AS attachment_count_rank,\n        DENSE_RANK() OVER (ORDER BY rwm.total_size_bytes DESC) AS size_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY rwm.total_attachments DESC) AS attachment_percentile,\n        NTILE(5) OVER (ORDER BY rwm.total_attachments DESC) AS attachment_quintile,\n        NTILE(10) OVER (ORDER BY rwm.total_size_bytes DESC) AS size_decile\n    FROM rolling_window_metrics rwm\n),\nunion_attachment_metrics AS (\n    -- Sixth CTE: UNION to combine different metric types\n    SELECT\n        sd.chat_id,\n        'count' AS metric_type,\n        sd.total_attachments AS metric_value\n    FROM size_distribution sd\n\n    UNION ALL\n\n    SELECT\n        sd.chat_id,\n        'size' AS metric_type,\n        sd.total_size_mb AS metric_value\n    FROM size_distribution sd\n\n    UNION ALL\n\n    SELECT\n        sd.chat_id,\n        'uploaders' AS metric_type,\n        sd.unique_uploaders AS metric_value\n    FROM size_distribution sd\n),\naggregated_union_attachment_metrics AS (\n    -- Seventh CTE: Aggregate UNION results with window functions\n    SELECT\n        uam.chat_id,\n        SUM(CASE WHEN uam.metric_type = 'count' THEN uam.metric_value ELSE 0 END) AS total_count_metric,\n        SUM(CASE WHEN uam.metric_type = 'size' THEN uam.metric_value ELSE 0 END) AS total_size_metric,\n        SUM(CASE WHEN uam.metric_type = 'uploaders' THEN uam.metric_value ELSE 0 END) AS total_uploaders_metric,\n        COUNT(DISTINCT uam.metric_type) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(uam.metric_value) OVER (\n            PARTITION BY uam.metric_type\n            ORDER BY uam.chat_id\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(uam.metric_value) OVER (\n            PARTITION BY uam.chat_id\n            ORDER BY uam.metric_type\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS chat_cumulative_metric\n    FROM union_attachment_metrics uam\n    GROUP BY uam.chat_id, uam.metric_type, uam.metric_value\n),\nfinal_attachment_analytics AS (\n    -- Eighth CTE: Final analytics with comprehensive window functions\n    SELECT\n        sd.chat_id,\n        sd.chat_title,\n        sd.total_attachments,\n        sd.unique_uploaders,\n        sd.total_size_mb,\n        sd.avg_file_size_kb,\n        sd.median_file_size_kb,\n        sd.p25_file_size_kb,\n        sd.p75_file_size_kb,\n        sd.max_file_size_kb,\n        sd.stddev_file_size_kb,\n        sd.avg_prior_uploads,\n        sd.avg_historical_file_size_kb,\n        sd.uploaders_with_chains,\n        sd.avg_chain_depth,\n        sd.max_chain_depth,\n        sd.total_chain_uploads,\n        sd.attachments_10_chat_window,\n        sd.size_20_chat_avg_mb,\n        sd.attachments_size_range_window,\n        sd.prev_chat_attachments,\n        sd.next_chat_size_mb,\n        sd.first_chat_avg_size_kb,\n        sd.last_chat_median_size_kb,\n        sd.size_category,\n        sd.volume_category,\n        sd.attachment_count_row_num,\n        sd.attachment_count_rank,\n        sd.size_dense_rank,\n        ROUND(CAST(sd.attachment_percentile * 100 AS NUMERIC), 2) AS attachment_percentile,\n        sd.attachment_quintile,\n        sd.size_decile,\n        -- Additional window functions with frames\n        SUM(sd.total_attachments) OVER (\n            ORDER BY sd.total_attachments DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_attachments,\n        AVG(sd.total_size_mb) OVER (\n            ORDER BY sd.total_size_mb DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_size_mb,\n        LAG(sd.total_attachments, 1) OVER (ORDER BY sd.total_attachments DESC) AS prev_total_attachments,\n        LEAD(sd.total_size_mb, 1) OVER (ORDER BY sd.total_size_mb DESC) AS next_total_size_mb\n    FROM size_distribution sd\n)\nSELECT\n    chat_id,\n    chat_title,\n    total_attachments,\n    unique_uploaders,\n    total_size_mb,\n    avg_file_size_kb,\n    median_file_size_kb,\n    p25_file_size_kb,\n    p75_file_size_kb,\n    max_file_size_kb,\n    stddev_file_size_kb,\n    avg_prior_uploads,\n    avg_historical_file_size_kb,\n    uploaders_with_chains,\n    avg_chain_depth,\n    max_chain_depth,\n    total_chain_uploads,\n    attachments_10_chat_window,\n    size_20_chat_avg_mb,\n    attachments_size_range_window,\n    prev_chat_attachments,\n    next_chat_size_mb,\n    first_chat_avg_size_kb,\n    last_chat_median_size_kb,\n    size_category,\n    volume_category,\n    attachment_count_row_num,\n    attachment_count_rank,\n    size_dense_rank,\n    attachment_percentile,\n    attachment_quintile,\n    size_decile,\n    cumulative_attachments,\n    ROUND(CAST(moving_avg_size_mb AS NUMERIC), 2) AS moving_avg_size_mb,\n    prev_total_attachments,\n    ROUND(CAST(next_total_size_mb AS NUMERIC), 2) AS next_total_size_mb\nFROM final_attachment_analytics\nORDER BY total_attachments DESC;",
      "line_number": 3518
    },
    {
      "number": 9,
      "title": "Production-Grade Anonymous Chat Analysis with Recursive CTE and Advanced Session Analytics",
      "description": "Description: Enterprise-level anonymous chat analysis with recursive CTE for guest interaction chains, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive session analytics. Implements production patterns similar to anonymous chat platforms. Complexity: Recursive CTE, multiple nested CTEs (7+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Recursive CTE, multiple nested CTEs (7+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE guest_interaction_chain AS (\n    -- Anchor: Base guest interactions\n    SELECT\n        acu.guest_id,\n        acu.chat_id,\n        am.id AS message_id,\n        am.created_at,\n        1 AS interaction_depth,\n        ARRAY[acu.guest_id]::character varying[] AS interaction_path\n    FROM anonymous_chat_users acu\n    INNER JOIN anonymous_messages am ON acu.chat_id = am.chat_id\n    WHERE am.guest_id = acu.guest_id\n\n    UNION ALL\n\n    -- Recursive: Find related interactions in same chat\n    SELECT\n        gic.guest_id,\n        gic.chat_id,\n        am2.id AS message_id,\n        am2.created_at,\n        gic.interaction_depth + 1,\n        gic.interaction_path || ARRAY[CAST(am2.id AS TEXT)]\n    FROM guest_interaction_chain gic\n    INNER JOIN anonymous_messages am2 ON gic.chat_id = am2.chat_id\n    WHERE am2.id != ALL(ARRAY[gic.message_id])\n        AND am2.created_at BETWEEN gic.created_at AND gic.created_at + INTERVAL '30 minutes'\n        AND gic.interaction_depth < 5\n),\nanonymous_session_metrics AS (\n    -- First CTE: Base session metrics with joins and correlated subqueries\n    SELECT\n        ac.id AS chat_id,\n        ac.join_code,\n        ac.created_at AS session_start,\n        COUNT(DISTINCT acu.guest_id) AS unique_guests,\n        COUNT(am.id) AS total_messages,\n        MAX(am.created_at) AS last_message_time,\n        COUNT(am.id) AS guest_messages,\n        0 AS ai_messages,\n        (\n            SELECT COUNT(DISTINCT acu2.guest_id)\n            FROM anonymous_chat_users acu2\n            WHERE acu2.chat_id = ac.id\n                AND EXISTS (\n                    SELECT 1\n                    FROM anonymous_messages am2\n                    WHERE am2.chat_id = ac.id\n                        AND am2.guest_id = acu2.guest_id\n                )\n        ) AS active_guests,\n        (\n            SELECT AVG(message_count)\n            FROM (\n                SELECT COUNT(*) AS message_count\n                FROM anonymous_messages am3\n                WHERE am3.chat_id = ac.id\n                GROUP BY am3.guest_id\n            ) guest_message_counts\n        ) AS avg_messages_per_guest\n    FROM anonymous_chats ac\n    LEFT JOIN anonymous_chat_users acu ON ac.id = acu.chat_id\n    LEFT JOIN anonymous_messages am ON ac.id = am.chat_id\n    GROUP BY ac.id, ac.join_code, ac.created_at\n),\ninteraction_chain_metrics AS (\n    -- Second CTE: Interaction chain metrics from recursive CTE\n    SELECT\n        chat_id,\n        COUNT(DISTINCT guest_id) AS guests_with_chains,\n        AVG(interaction_depth) AS avg_interaction_depth,\n        MAX(interaction_depth) AS max_interaction_depth,\n        COUNT(*) AS total_chain_interactions\n    FROM guest_interaction_chain\n    GROUP BY chat_id\n),\nsession_durations AS (\n    -- Third CTE: Session duration calculations\n    SELECT\n        asm.chat_id,\n        asm.join_code,\n        asm.session_start,\n        asm.unique_guests,\n        asm.total_messages,\n        asm.last_message_time,\n        asm.guest_messages,\n        asm.ai_messages,\n        asm.active_guests,\n        asm.avg_messages_per_guest,\n        COALESCE(icm.guests_with_chains, 0) AS guests_with_chains,\n        COALESCE(icm.avg_interaction_depth, 0) AS avg_interaction_depth,\n        COALESCE(icm.max_interaction_depth, 0) AS max_interaction_depth,\n        COALESCE(icm.total_chain_interactions, 0) AS total_chain_interactions,\n        EXTRACT(EPOCH FROM (COALESCE(asm.last_message_time, asm.session_start) - asm.session_start)) / 60 AS session_duration_minutes,\n        CASE\n            WHEN asm.total_messages = 0 THEN 'No Activity'\n            WHEN asm.total_messages < 5 THEN 'Low Activity'\n            WHEN asm.total_messages < 20 THEN 'Medium Activity'\n            WHEN asm.total_messages < 50 THEN 'High Activity'\n            ELSE 'Very High Activity'\n        END AS activity_level\n    FROM anonymous_session_metrics asm\n    LEFT JOIN interaction_chain_metrics icm ON asm.chat_id = icm.chat_id\n),\nrolling_window_session_stats AS (\n    -- Fourth CTE: Rolling window statistics with frame clauses\n    SELECT\n        sd.*,\n        -- Window functions with ROWS BETWEEN frames\n        SUM(sd.total_messages) OVER (\n            ORDER BY sd.total_messages DESC\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS messages_10_session_window,\n        AVG(sd.session_duration_minutes) OVER (\n            ORDER BY sd.session_duration_minutes DESC\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS duration_20_session_avg,\n        -- Window functions with RANGE BETWEEN frames\n        SUM(sd.unique_guests) OVER (\n            ORDER BY sd.total_messages\n            RANGE BETWEEN 10 PRECEDING AND 10 FOLLOWING\n        ) AS guests_message_range_window,\n        -- Lag/Lead functions\n        LAG(sd.total_messages, 1) OVER (ORDER BY sd.total_messages DESC) AS prev_session_messages,\n        LEAD(sd.session_duration_minutes, 1) OVER (ORDER BY sd.session_duration_minutes DESC) AS next_session_duration,\n        -- First/Last value with frames\n        FIRST_VALUE(sd.guest_messages) OVER (\n            ORDER BY sd.total_messages DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_session_guest_messages,\n        LAST_VALUE(sd.ai_messages) OVER (\n            ORDER BY sd.total_messages DESC\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_session_ai_messages\n    FROM session_durations sd\n),\nactivity_analysis AS (\n    -- Fifth CTE: Activity analysis with pivot CASE\n    SELECT\n        rwss.chat_id,\n        rwss.join_code,\n        rwss.session_start,\n        rwss.unique_guests,\n        rwss.total_messages,\n        rwss.guest_messages,\n        rwss.ai_messages,\n        rwss.active_guests,\n        ROUND(CAST(rwss.avg_messages_per_guest AS NUMERIC), 2) AS avg_messages_per_guest,\n        rwss.guests_with_chains,\n        ROUND(CAST(rwss.avg_interaction_depth AS NUMERIC), 2) AS avg_interaction_depth,\n        rwss.max_interaction_depth,\n        rwss.total_chain_interactions,\n        ROUND(CAST(rwss.session_duration_minutes AS NUMERIC), 2) AS duration_minutes,\n        rwss.activity_level,\n        rwss.messages_10_session_window,\n        ROUND(CAST(rwss.duration_20_session_avg AS NUMERIC), 2) AS duration_20_session_avg,\n        rwss.guests_message_range_window,\n        rwss.prev_session_messages,\n        ROUND(CAST(rwss.next_session_duration AS NUMERIC), 2) AS next_session_duration,\n        rwss.first_session_guest_messages,\n        rwss.last_session_ai_messages,\n        ROUND(CAST(rwss.guest_messages::numeric / NULLIF(CAST(rwss.total_messages AS NUMERIC), 0) AS NUMERIC) * 100, 2) AS guest_message_percentage,\n        ROUND(CAST(rwss.total_messages::numeric / NULLIF(CAST(rwss.session_duration_minutes AS NUMERIC), 0) AS NUMERIC), 2) AS messages_per_minute,\n        -- Pivot CASE for classification\n        CASE\n            WHEN ROUND(CAST(rwss.guest_messages::numeric / NULLIF(CAST(rwss.total_messages AS NUMERIC), 0) AS NUMERIC) * 100, 2) >= 70 THEN 'Guest-Dominated'\n            WHEN ROUND(CAST(rwss.guest_messages::numeric / NULLIF(CAST(rwss.total_messages AS NUMERIC), 0) AS NUMERIC) * 100, 2) >= 50 THEN 'Balanced'\n            WHEN ROUND(CAST(rwss.guest_messages::numeric / NULLIF(CAST(rwss.total_messages AS NUMERIC), 0) AS NUMERIC) * 100, 2) >= 30 THEN 'AI-Assisted'\n            ELSE 'AI-Dominated'\n        END AS interaction_type,\n        CASE\n            WHEN ROUND(CAST(rwss.total_messages::numeric / NULLIF(CAST(rwss.session_duration_minutes AS NUMERIC), 0) AS NUMERIC), 2) >= 2 THEN 'High Velocity'\n            WHEN ROUND(CAST(rwss.total_messages::numeric / NULLIF(CAST(rwss.session_duration_minutes AS NUMERIC), 0) AS NUMERIC), 2) >= 1 THEN 'Medium Velocity'\n            WHEN ROUND(CAST(rwss.total_messages::numeric / NULLIF(CAST(rwss.session_duration_minutes AS NUMERIC), 0) AS NUMERIC), 2) >= 0.5 THEN 'Low Velocity'\n            ELSE 'Very Low Velocity'\n        END AS velocity_category,\n        -- Window function rankings\n        ROW_NUMBER() OVER (ORDER BY rwss.total_messages DESC) AS message_row_num,\n        RANK() OVER (ORDER BY rwss.total_messages DESC) AS message_rank,\n        DENSE_RANK() OVER (ORDER BY rwss.session_duration_minutes DESC) AS duration_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY rwss.total_messages DESC) AS message_percentile,\n        NTILE(5) OVER (ORDER BY rwss.total_messages DESC) AS message_quintile,\n        NTILE(10) OVER (ORDER BY rwss.session_duration_minutes DESC) AS duration_decile\n    FROM rolling_window_session_stats rwss\n),\nunion_session_metrics AS (\n    -- Sixth CTE: UNION to combine different metric types\n    SELECT\n        aa.chat_id,\n        'messages' AS metric_type,\n        aa.total_messages AS metric_value\n    FROM activity_analysis aa\n\n    UNION ALL\n\n    SELECT\n        aa.chat_id,\n        'guests' AS metric_type,\n        aa.unique_guests AS metric_value\n    FROM activity_analysis aa\n\n    UNION ALL\n\n    SELECT\n        aa.chat_id,\n        'duration' AS metric_type,\n        aa.duration_minutes AS metric_value\n    FROM activity_analysis aa\n),\naggregated_union_session_metrics AS (\n    -- Seventh CTE: Aggregate UNION results with window functions\n    SELECT\n        usm.chat_id,\n        SUM(CASE WHEN usm.metric_type = 'messages' THEN usm.metric_value ELSE 0 END) AS total_messages_metric,\n        SUM(CASE WHEN usm.metric_type = 'guests' THEN usm.metric_value ELSE 0 END) AS total_guests_metric,\n        SUM(CASE WHEN usm.metric_type = 'duration' THEN usm.metric_value ELSE 0 END) AS total_duration_metric,\n        COUNT(DISTINCT usm.metric_type) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(usm.metric_value) OVER (\n            PARTITION BY usm.metric_type\n            ORDER BY usm.chat_id\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(usm.metric_value) OVER (\n            PARTITION BY usm.chat_id\n            ORDER BY usm.metric_type\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS session_cumulative_metric\n    FROM union_session_metrics usm\n    GROUP BY usm.chat_id, usm.metric_type, usm.metric_value\n),\nfinal_anonymous_session_analytics AS (\n    -- Eighth CTE: Final analytics with comprehensive window functions\n    SELECT\n        aa.chat_id,\n        aa.join_code,\n        aa.session_start,\n        aa.unique_guests,\n        aa.total_messages,\n        aa.guest_messages,\n        aa.ai_messages,\n        aa.active_guests,\n        aa.avg_messages_per_guest,\n        aa.guests_with_chains,\n        aa.avg_interaction_depth,\n        aa.max_interaction_depth,\n        aa.total_chain_interactions,\n        aa.duration_minutes,\n        aa.activity_level,\n        aa.messages_10_session_window,\n        aa.duration_20_session_avg,\n        aa.guests_message_range_window,\n        aa.prev_session_messages,\n        aa.next_session_duration,\n        aa.first_session_guest_messages,\n        aa.last_session_ai_messages,\n        aa.guest_message_percentage,\n        aa.messages_per_minute,\n        aa.interaction_type,\n        aa.velocity_category,\n        aa.message_row_num,\n        aa.message_rank,\n        aa.duration_dense_rank,\n        ROUND(CAST(aa.message_percentile * 100 AS NUMERIC), 2) AS message_percentile,\n        aa.message_quintile,\n        aa.duration_decile,\n        -- Additional window functions with frames\n        SUM(aa.total_messages) OVER (\n            ORDER BY aa.total_messages DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_messages,\n        AVG(aa.duration_minutes) OVER (\n            ORDER BY aa.duration_minutes DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_duration,\n        LAG(aa.total_messages, 1) OVER (ORDER BY aa.total_messages DESC) AS prev_total_messages,\n        LEAD(aa.duration_minutes, 1) OVER (ORDER BY aa.duration_minutes DESC) AS next_duration\n    FROM activity_analysis aa\n)\nSELECT\n    chat_id,\n    join_code,\n    session_start,\n    unique_guests,\n    total_messages,\n    guest_messages,\n    ai_messages,\n    active_guests,\n    avg_messages_per_guest,\n    guests_with_chains,\n    avg_interaction_depth,\n    max_interaction_depth,\n    total_chain_interactions,\n    duration_minutes,\n    activity_level,\n    messages_10_session_window,\n    duration_20_session_avg,\n    guests_message_range_window,\n    prev_session_messages,\n    next_session_duration,\n    first_session_guest_messages,\n    last_session_ai_messages,\n    guest_message_percentage,\n    messages_per_minute,\n    interaction_type,\n    velocity_category,\n    message_row_num,\n    message_rank,\n    duration_dense_rank,\n    message_percentile,\n    message_quintile,\n    duration_decile,\n    cumulative_messages,\n    ROUND(CAST(moving_avg_duration AS NUMERIC), 2) AS moving_avg_duration,\n    prev_total_messages,\n    ROUND(CAST(next_duration AS NUMERIC), 2) AS next_duration\nFROM final_anonymous_session_analytics\nORDER BY total_messages DESC;",
      "line_number": 4068
    },
    {
      "number": 10,
      "title": "Production-Grade Cross-Table User Activity Analysis with Recursive CTE and Advanced Scoring",
      "description": "Description: Enterprise-level cross-table user activity analysis with recursive CTE for activity chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive weighted scoring. Implements production patterns similar to user analytics platforms. Complexity: Recursive CTE, multiple nested CTEs (9+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggreg",
      "complexity": "Recursive CTE, multiple nested CTEs (9+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE activity_chain AS (\n    -- Anchor: Base user activities\n    SELECT\n        p.id AS user_id,\n        'profile' AS activity_source,\n        p.created_at AS activity_time,\n        1 AS chain_depth,\n        ARRAY[p.id] AS chain_path\n    FROM profiles p\n\n    UNION ALL\n\n    -- Recursive: Find related activities\n    SELECT\n        ac.user_id,\n        CASE\n            WHEN EXISTS (SELECT 1 FROM messages m WHERE m.sender_id = ac.user_id AND m.created_at BETWEEN ac.activity_time AND ac.activity_time + INTERVAL '1 day') THEN 'message'\n            WHEN EXISTS (SELECT 1 FROM chat_participants cp WHERE cp.user_id = ac.user_id AND cp.joined_at BETWEEN ac.activity_time AND ac.activity_time + INTERVAL '1 day') THEN 'chat'\n            WHEN EXISTS (SELECT 1 FROM friends f WHERE f.user_id = ac.user_id AND f.created_at BETWEEN ac.activity_time AND ac.activity_time + INTERVAL '1 day') THEN 'friend'\n            ELSE 'other'\n        END AS activity_source,\n        COALESCE(\n            (SELECT MIN(m.created_at) FROM messages m WHERE m.sender_id = ac.user_id AND m.created_at > ac.activity_time),\n            (SELECT MIN(cp.joined_at) FROM chat_participants cp WHERE cp.user_id = ac.user_id AND cp.joined_at > ac.activity_time),\n            (SELECT MIN(f.created_at) FROM friends f WHERE f.user_id = ac.user_id AND f.created_at > ac.activity_time)\n        ) AS activity_time,\n        ac.chain_depth + 1,\n        ac.chain_path || ac.user_id\n    FROM activity_chain ac\n    WHERE ac.chain_depth < 5\n        AND (\n            EXISTS (SELECT 1 FROM messages m WHERE m.sender_id = ac.user_id AND m.created_at > ac.activity_time)\n            OR EXISTS (SELECT 1 FROM chat_participants cp WHERE cp.user_id = ac.user_id AND cp.joined_at > ac.activity_time)\n            OR EXISTS (SELECT 1 FROM friends f WHERE f.user_id = ac.user_id AND f.created_at > ac.activity_time)\n        )\n),\nuser_messages AS (\n    -- First CTE: User message metrics with correlated subqueries\n    SELECT\n        sender_id AS user_id,\n        COUNT(*) AS message_count,\n        COUNT(DISTINCT chat_id) AS chat_count,\n        AVG(LENGTH(content)) AS avg_message_length,\n        (\n            SELECT COUNT(DISTINCT m2.chat_id)\n            FROM messages m2\n            WHERE m2.sender_id = messages.sender_id\n                AND m2.is_ai = false\n                AND EXISTS (\n                    SELECT 1\n                    FROM messages m3\n                    WHERE m3.chat_id = m2.chat_id\n                        AND m3.is_ai = true\n                        AND m3.created_at BETWEEN m2.created_at - INTERVAL '1 hour' AND m2.created_at + INTERVAL '1 hour'\n                )\n        ) AS chats_with_ai_interaction\n    FROM messages\n    WHERE is_ai = false\n    GROUP BY sender_id\n),\nuser_chats AS (\n    -- Second CTE: User chat metrics\n    SELECT\n        cp.user_id,\n        COUNT(DISTINCT cp.chat_id) AS participated_chats,\n        COUNT(DISTINCT c.id) AS created_chats,\n        (\n            SELECT COUNT(DISTINCT cp2.chat_id)\n            FROM chat_participants cp2\n            WHERE cp2.user_id = cp.user_id\n                AND EXISTS (\n                    SELECT 1\n                    FROM messages m\n                    WHERE m.chat_id = cp2.chat_id\n                        AND m.sender_id = cp2.user_id\n                        AND m.created_at >= cp2.joined_at\n                )\n        ) AS active_participated_chats\n    FROM chat_participants cp\n    LEFT JOIN chats c ON cp.user_id = c.created_by\n    GROUP BY cp.user_id\n),\nuser_friends AS (\n    -- Third CTE: User friend metrics\n    SELECT\n        user_id,\n        COUNT(*) AS friend_count,\n        SUM(CASE WHEN status = 'accepted' THEN 1 ELSE 0 END) AS accepted_friends,\n        SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) AS pending_friends\n    FROM friends\n    GROUP BY user_id\n),\nuser_notifications AS (\n    -- Fourth CTE: User notification metrics\n    SELECT\n        user_id,\n        COUNT(*) AS notification_count,\n        SUM(CASE WHEN read = true THEN 1 ELSE 0 END) AS read_notifications,\n        AVG(EXTRACT(EPOCH FROM (COALESCE(seen_at, CURRENT_TIMESTAMP) - created_at)) / 60) AS avg_minutes_to_seen\n    FROM notifications\n    GROUP BY user_id\n),\nuser_attachments AS (\n    -- Fifth CTE: User attachment metrics\n    SELECT\n        user_id AS user_id,\n        COUNT(*) AS attachment_count,\n        SUM(file_size) AS total_upload_size,\n        AVG(file_size) AS avg_file_size\n    FROM file_attachments\n    GROUP BY user_id\n),\nactivity_chain_metrics AS (\n    -- Sixth CTE: Activity chain metrics from recursive CTE\n    SELECT\n        user_id,\n        COUNT(DISTINCT activity_source) AS unique_activity_sources,\n        AVG(chain_depth) AS avg_chain_depth,\n        MAX(chain_depth) AS max_chain_depth,\n        COUNT(*) AS total_chain_activities\n    FROM activity_chain\n    GROUP BY user_id\n),\ncombined_activity AS (\n    -- Seventh CTE: UNION to combine activity types\n    SELECT user_id, 'messages' AS activity_type, message_count AS activity_count, 1.0 AS weight FROM user_messages\n    UNION ALL\n    SELECT user_id, 'chats' AS activity_type, participated_chats AS activity_count, 5.0 AS weight FROM user_chats\n    UNION ALL\n    SELECT user_id, 'friends' AS activity_type, friend_count AS activity_count, 3.0 AS weight FROM user_friends\n    UNION ALL\n    SELECT user_id, 'notifications' AS activity_type, notification_count AS activity_count, 0.5 AS weight FROM user_notifications\n    UNION ALL\n    SELECT user_id, 'attachments' AS activity_type, attachment_count AS activity_count, 2.0 AS weight FROM user_attachments\n),\nuser_totals AS (\n    -- Eighth CTE: Aggregate user totals\n    SELECT\n        ca.user_id,\n        SUM(CASE WHEN ca.activity_type = 'messages' THEN ca.activity_count ELSE 0 END) AS total_messages,\n        SUM(CASE WHEN ca.activity_type = 'chats' THEN ca.activity_count ELSE 0 END) AS total_chats,\n        SUM(CASE WHEN ca.activity_type = 'friends' THEN ca.activity_count ELSE 0 END) AS total_friends,\n        SUM(CASE WHEN ca.activity_type = 'notifications' THEN ca.activity_count ELSE 0 END) AS total_notifications,\n        SUM(CASE WHEN ca.activity_type = 'attachments' THEN ca.activity_count ELSE 0 END) AS total_attachments,\n        SUM(ca.activity_count * ca.weight) AS weighted_activity_sum\n    FROM combined_activity ca\n    GROUP BY ca.user_id\n),\nrolling_window_user_stats AS (\n    -- Ninth CTE: Rolling window statistics with frame clauses\n    SELECT\n        ut.user_id,\n        ut.total_messages,\n        ut.total_chats,\n        ut.total_friends,\n        ut.total_notifications,\n        ut.total_attachments,\n        ut.weighted_activity_sum,\n        COALESCE(um.chat_count, 0) AS chat_count,\n        COALESCE(um.avg_message_length, 0) AS avg_message_length,\n        COALESCE(um.chats_with_ai_interaction, 0) AS chats_with_ai_interaction,\n        COALESCE(uc.created_chats, 0) AS created_chats,\n        COALESCE(uc.active_participated_chats, 0) AS active_participated_chats,\n        COALESCE(uf.accepted_friends, 0) AS accepted_friends,\n        COALESCE(uf.pending_friends, 0) AS pending_friends,\n        COALESCE(un.read_notifications, 0) AS read_notifications,\n        COALESCE(un.avg_minutes_to_seen, 0) AS avg_minutes_to_seen,\n        COALESCE(ua.total_upload_size, 0) AS total_upload_size,\n        COALESCE(ua.avg_file_size, 0) AS avg_file_size,\n        COALESCE(acm.unique_activity_sources, 0) AS unique_activity_sources,\n        COALESCE(acm.avg_chain_depth, 0) AS avg_chain_depth,\n        COALESCE(acm.max_chain_depth, 0) AS max_chain_depth,\n        COALESCE(acm.total_chain_activities, 0) AS total_chain_activities,\n        -- Window functions with ROWS BETWEEN frames\n        SUM(ut.weighted_activity_sum) OVER (\n            ORDER BY ut.weighted_activity_sum DESC\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS activity_10_user_window,\n        AVG(ut.total_messages) OVER (\n            ORDER BY ut.total_messages DESC\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS messages_20_user_avg,\n        -- Window functions with RANGE BETWEEN frames\n        SUM(ut.total_chats) OVER (\n            ORDER BY ut.weighted_activity_sum\n            RANGE BETWEEN 50 PRECEDING AND 50 FOLLOWING\n        ) AS chats_activity_range_window,\n        -- Lag/Lead functions\n        LAG(ut.weighted_activity_sum, 1) OVER (ORDER BY ut.weighted_activity_sum DESC) AS prev_user_activity,\n        LEAD(ut.total_messages, 1) OVER (ORDER BY ut.total_messages DESC) AS next_user_messages,\n        -- First/Last value with frames\n        FIRST_VALUE(ut.total_chats) OVER (\n            ORDER BY ut.weighted_activity_sum DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_user_chats,\n        LAST_VALUE(ut.total_friends) OVER (\n            ORDER BY ut.weighted_activity_sum DESC\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_user_friends\n    FROM user_totals ut\n    LEFT JOIN user_messages um ON ut.user_id = um.user_id\n    LEFT JOIN user_chats uc ON ut.user_id = uc.user_id\n    LEFT JOIN user_friends uf ON ut.user_id = uf.user_id\n    LEFT JOIN user_notifications un ON ut.user_id = un.user_id\n    LEFT JOIN user_attachments ua ON ut.user_id = ua.user_id\n    LEFT JOIN activity_chain_metrics acm ON ut.user_id = acm.user_id\n),\nactivity_scores AS (\n    -- Tenth CTE: Calculate activity scores with window functions\n    SELECT\n        rwus.user_id,\n        p.username,\n        rwus.total_messages,\n        rwus.total_chats,\n        rwus.total_friends,\n        rwus.total_notifications,\n        rwus.total_attachments,\n        rwus.chat_count,\n        ROUND(CAST(rwus.avg_message_length AS NUMERIC), 2) AS avg_message_length,\n        rwus.chats_with_ai_interaction,\n        rwus.created_chats,\n        rwus.active_participated_chats,\n        rwus.accepted_friends,\n        rwus.pending_friends,\n        rwus.read_notifications,\n        ROUND(CAST(rwus.avg_minutes_to_seen AS NUMERIC), 2) AS avg_minutes_to_seen,\n        ROUND(CAST(rwus.total_upload_size / 1024.0 / 1024.0 AS NUMERIC), 2) AS total_upload_size_mb,\n        ROUND(CAST(rwus.avg_file_size / 1024.0 AS NUMERIC), 2) AS avg_file_size_kb,\n        rwus.unique_activity_sources,\n        ROUND(CAST(rwus.avg_chain_depth AS NUMERIC), 2) AS avg_chain_depth,\n        rwus.max_chain_depth,\n        rwus.total_chain_activities,\n        rwus.activity_10_user_window,\n        ROUND(CAST(rwus.messages_20_user_avg AS NUMERIC), 2) AS messages_20_user_avg,\n        rwus.chats_activity_range_window,\n        ROUND(CAST(rwus.prev_user_activity AS NUMERIC), 2) AS prev_user_activity,\n        rwus.next_user_messages,\n        rwus.first_user_chats,\n        rwus.last_user_friends,\n        -- Weighted activity score with chain bonus\n        (rwus.total_messages * 1.0) +\n        (rwus.total_chats * 5.0) +\n        (rwus.total_friends * 3.0) +\n        (rwus.total_notifications * 0.5) +\n        (rwus.total_attachments * 2.0) +\n        (rwus.unique_activity_sources * 1.5) +\n        (rwus.avg_chain_depth * 0.5) AS activity_score,\n        -- Window functions for comparison\n        AVG(rwus.weighted_activity_sum) OVER () AS overall_avg_activity,\n        PERCENT_RANK() OVER (ORDER BY rwus.weighted_activity_sum DESC) AS activity_percentile\n    FROM rolling_window_user_stats rwus\n    INNER JOIN profiles p ON rwus.user_id = p.id\n),\nfinal_activity_analytics AS (\n    -- Eleventh CTE: Final analytics with comprehensive window functions\n    SELECT\n        as1.user_id,\n        as1.username,\n        as1.total_messages,\n        as1.total_chats,\n        as1.total_friends,\n        as1.total_notifications,\n        as1.total_attachments,\n        as1.chat_count,\n        as1.avg_message_length,\n        as1.chats_with_ai_interaction,\n        as1.created_chats,\n        as1.active_participated_chats,\n        as1.accepted_friends,\n        as1.pending_friends,\n        as1.read_notifications,\n        as1.avg_minutes_to_seen,\n        as1.total_upload_size_mb,\n        as1.avg_file_size_kb,\n        as1.unique_activity_sources,\n        as1.avg_chain_depth,\n        as1.max_chain_depth,\n        as1.total_chain_activities,\n        as1.activity_10_user_window,\n        as1.messages_20_user_avg,\n        as1.chats_activity_range_window,\n        as1.prev_user_activity,\n        as1.next_user_messages,\n        as1.first_user_chats,\n        as1.last_user_friends,\n        ROUND(CAST(as1.activity_score AS NUMERIC), 2) AS activity_score,\n        ROUND(CAST(as1.overall_avg_activity AS NUMERIC), 2) AS overall_avg_activity,\n        ROUND(CAST(as1.activity_percentile * 100 AS NUMERIC), 2) AS activity_percentile,\n        -- Multiple ranking methods\n        ROW_NUMBER() OVER (ORDER BY as1.activity_score DESC) AS activity_row_num,\n        RANK() OVER (ORDER BY as1.activity_score DESC) AS activity_rank,\n        DENSE_RANK() OVER (ORDER BY as1.activity_score DESC) AS activity_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY as1.activity_score DESC) AS score_percentile,\n        NTILE(5) OVER (ORDER BY as1.activity_score DESC) AS activity_quintile,\n        NTILE(10) OVER (ORDER BY as1.activity_score DESC) AS activity_decile,\n        -- Window functions with frames\n        SUM(as1.activity_score) OVER (\n            ORDER BY as1.activity_score DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_activity_score,\n        AVG(as1.activity_score) OVER (\n            ORDER BY as1.activity_score DESC\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS moving_avg_activity_score,\n        LAG(as1.activity_score, 1) OVER (ORDER BY as1.activity_score DESC) AS prev_activity_score,\n        LEAD(as1.activity_score, 1) OVER (ORDER BY as1.activity_score DESC) AS next_activity_score,\n        -- Pivot CASE for classification\n        CASE\n            WHEN as1.activity_score >= 200 THEN 'Power User'\n            WHEN as1.activity_score >= 100 THEN 'Active User'\n            WHEN as1.activity_score >= 50 THEN 'Regular User'\n            WHEN as1.activity_score >= 20 THEN 'Casual User'\n            ELSE 'Inactive User'\n        END AS user_category,\n        CASE\n            WHEN as1.unique_activity_sources >= 4 THEN 'Multi-Platform'\n            WHEN as1.unique_activity_sources >= 3 THEN 'Diverse'\n            WHEN as1.unique_activity_sources >= 2 THEN 'Moderate'\n            ELSE 'Focused'\n        END AS activity_diversity_category\n    FROM activity_scores as1\n)\nSELECT\n    user_id,\n    username,\n    total_messages,\n    total_chats,\n    total_friends,\n    total_notifications,\n    total_attachments,\n    chat_count,\n    avg_message_length,\n    chats_with_ai_interaction,\n    created_chats,\n    active_participated_chats,\n    accepted_friends,\n    pending_friends,\n    read_notifications,\n    avg_minutes_to_seen,\n    total_upload_size_mb,\n    avg_file_size_kb,\n    unique_activity_sources,\n    avg_chain_depth,\n    max_chain_depth,\n    total_chain_activities,\n    activity_10_user_window,\n    messages_20_user_avg,\n    chats_activity_range_window,\n    prev_user_activity,\n    next_user_messages,\n    first_user_chats,\n    last_user_friends,\n    activity_score,\n    overall_avg_activity,\n    activity_percentile,\n    activity_row_num,\n    activity_rank,\n    activity_dense_rank,\n    ROUND(CAST(score_percentile * 100 AS NUMERIC), 2) AS score_percentile,\n    activity_quintile,\n    activity_decile,\n    ROUND(CAST(cumulative_activity_score AS NUMERIC), 2) AS cumulative_activity_score,\n    ROUND(CAST(moving_avg_activity_score AS NUMERIC), 2) AS moving_avg_activity_score,\n    ROUND(CAST(prev_activity_score AS NUMERIC), 2) AS prev_activity_score,\n    ROUND(CAST(next_activity_score AS NUMERIC), 2) AS next_activity_score,\n    user_category,\n    activity_diversity_category\nFROM final_activity_analytics\nORDER BY activity_score DESC;",
      "line_number": 4578
    },
    {
      "number": 11,
      "title": "Production-Grade Recursive Chat Invitation Chain Analysis with Advanced Network Metrics",
      "description": "Description: Enterprise-level recursive CTE analysis for invitation chains with multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive network path analytics. Implements production patterns similar to social network analysis systems. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE invitation_chains AS (\n    -- Anchor: Base invitation chains\n    SELECT\n        ci.id,\n        ci.inviting_user_id AS chain_start,\n        ci.invited_user_id AS chain_end,\n        ci.chat_id,\n        1 AS chain_length,\n        ARRAY[ci.inviting_user_id, ci.invited_user_id] AS path,\n        ci.created_at AS invitation_time\n    FROM chat_invitations ci\n    WHERE ci.status = 'accepted'\n\n    UNION ALL\n\n    -- Recursive: Extend invitation chains\n    SELECT\n        ci2.id,\n        ic.chain_start,\n        ci2.invited_user_id AS chain_end,\n        ci2.chat_id,\n        ic.chain_length + 1,\n        ic.path || ci2.invited_user_id,\n        ci2.created_at AS invitation_time\n    FROM invitation_chains ic\n    INNER JOIN chat_invitations ci2 ON ic.chain_end = ci2.inviting_user_id\n    WHERE ci2.status = 'accepted'\n        AND ci2.invited_user_id != ALL(ic.path)\n        AND ci2.created_at >= ic.invitation_time\n        AND ic.chain_length < 5\n),\nchain_statistics AS (\n    -- First CTE: Chain-level statistics\n    SELECT\n        ic.chain_start,\n        ic.chain_end,\n        ic.chain_length,\n        COUNT(*) AS path_count,\n        COUNT(DISTINCT ic.chat_id) AS unique_chats,\n        MIN(ic.invitation_time) AS first_invitation_time,\n        MAX(ic.invitation_time) AS last_invitation_time,\n        EXTRACT(EPOCH FROM (MAX(ic.invitation_time) - MIN(ic.invitation_time))) / 3600 AS chain_duration_hours\n    FROM invitation_chains ic\n    GROUP BY ic.chain_start, ic.chain_end, ic.chain_length\n),\nuser_invitation_metrics AS (\n    -- Second CTE: User-level invitation metrics with correlated subqueries\n    SELECT\n        cs.chain_start AS user_id,\n        COUNT(DISTINCT cs.chain_end) AS unique_invited_users,\n        COUNT(*) AS total_invitation_paths,\n        AVG(cs.chain_length) AS avg_chain_length,\n        MAX(cs.chain_length) AS max_chain_length,\n        SUM(cs.path_count) AS total_path_count,\n        SUM(cs.unique_chats) AS total_unique_chats,\n        AVG(cs.chain_duration_hours) AS avg_chain_duration_hours,\n        (\n            SELECT COUNT(DISTINCT ci3.invited_user_id)\n            FROM chat_invitations ci3\n            WHERE ci3.inviting_user_id = cs.chain_start\n                AND ci3.status = 'accepted'\n        ) AS direct_invitations,\n        (\n            SELECT AVG(chain_length)\n            FROM (\n                SELECT chain_length\n                FROM invitation_chains ic2\n                WHERE ic2.chain_start = cs.chain_start\n            ) user_chains\n        ) AS avg_user_chain_length\n    FROM chain_statistics cs\n    GROUP BY cs.chain_start\n),\ninvitation_network_metrics AS (\n    -- Third CTE: Network-level metrics\n    SELECT\n        cs.chain_start,\n        cs.chain_end,\n        cs.chain_length,\n        cs.path_count,\n        cs.unique_chats,\n        cs.chain_duration_hours,\n        uim1.unique_invited_users AS start_user_unique_invited,\n        uim1.total_invitation_paths AS start_user_total_paths,\n        uim1.avg_chain_length AS start_user_avg_length,\n        uim1.direct_invitations AS start_user_direct_invites,\n        COALESCE(uim2.unique_invited_users, 0) AS end_user_unique_invited,\n        COALESCE(uim2.total_invitation_paths, 0) AS end_user_total_paths,\n        COALESCE(uim2.avg_chain_length, 0) AS end_user_avg_length,\n        COALESCE(uim2.direct_invitations, 0) AS end_user_direct_invites\n    FROM chain_statistics cs\n    INNER JOIN user_invitation_metrics uim1 ON cs.chain_start = uim1.user_id\n    LEFT JOIN user_invitation_metrics uim2 ON cs.chain_end = uim2.user_id\n),\nrolling_window_network_stats AS (\n    -- Fourth CTE: Rolling window statistics with frame clauses\n    SELECT\n        inm.*,\n        -- Window functions with ROWS BETWEEN frames\n        SUM(inm.path_count) OVER (\n            PARTITION BY inm.chain_length\n            ORDER BY inm.path_count DESC\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS path_count_10_window,\n        AVG(inm.chain_duration_hours) OVER (\n            PARTITION BY inm.chain_length\n            ORDER BY inm.path_count DESC\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS duration_20_path_avg,\n        -- Window functions with RANGE BETWEEN frames\n        SUM(inm.unique_chats) OVER (\n            ORDER BY inm.path_count\n            RANGE BETWEEN 5 PRECEDING AND 5 FOLLOWING\n        ) AS chats_path_range_window,\n        -- Lag/Lead functions\n        LAG(inm.path_count, 1) OVER (PARTITION BY inm.chain_length ORDER BY inm.path_count DESC) AS prev_path_count,\n        LEAD(inm.chain_duration_hours, 1) OVER (PARTITION BY inm.chain_length ORDER BY inm.path_count DESC) AS next_chain_duration,\n        -- First/Last value with frames\n        FIRST_VALUE(inm.unique_chats) OVER (\n            PARTITION BY inm.chain_length\n            ORDER BY inm.path_count DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_path_chats,\n        LAST_VALUE(inm.chain_duration_hours) OVER (\n            PARTITION BY inm.chain_length\n            ORDER BY inm.path_count DESC\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_path_duration\n    FROM invitation_network_metrics inm\n),\nunion_network_metrics AS (\n    -- Fifth CTE: UNION to combine different metric types\n    SELECT\n        rwns.chain_start,\n        rwns.chain_end,\n        'path_count' AS metric_type,\n        rwns.path_count AS metric_value\n    FROM rolling_window_network_stats rwns\n\n    UNION ALL\n\n    SELECT\n        rwns.chain_start,\n        rwns.chain_end,\n        'unique_chats' AS metric_type,\n        rwns.unique_chats AS metric_value\n    FROM rolling_window_network_stats rwns\n\n    UNION ALL\n\n    SELECT\n        rwns.chain_start,\n        rwns.chain_end,\n        'duration' AS metric_type,\n        rwns.chain_duration_hours AS metric_value\n    FROM rolling_window_network_stats rwns\n),\naggregated_union_network_metrics AS (\n    -- Sixth CTE: Aggregate UNION results with window functions\n    SELECT\n        NULL,\n        NULL,\n        SUM(CASE WHEN NULL = 'path_count' THEN NULL ELSE 0 END) AS total_path_count_metric,\n        SUM(CASE WHEN NULL = 'unique_chats' THEN NULL ELSE 0 END) AS total_chats_metric,\n        SUM(CASE WHEN NULL = 'duration' THEN NULL ELSE 0 END) AS total_duration_metric,\n        COUNT(DISTINCT NULL) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(CAST(0 AS NUMERIC)) OVER (\n            PARTITION BY unm.metric_type\n            ORDER BY unm.chain_start\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(CAST(0 AS NUMERIC)) OVER (\n            PARTITION BY unm.chain_start\n            ORDER BY unm.chain_start\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS chain_cumulative_metric\n    FROM union_network_metrics unm\n    GROUP BY unm.chain_start, unm.metric_type\n),\nfinal_invitation_chain_analytics AS (\n    -- Seventh CTE: Final analytics with comprehensive window functions\n    SELECT\n        rwns.chain_start,\n        rwns.chain_end,\n        rwns.chain_length,\n        rwns.path_count,\n        rwns.unique_chats,\n        ROUND(CAST(rwns.chain_duration_hours AS NUMERIC), 2) AS chain_duration_hours,\n        rwns.start_user_unique_invited,\n        rwns.start_user_total_paths,\n        ROUND(CAST(rwns.start_user_avg_length AS NUMERIC), 2) AS start_user_avg_length,\n        rwns.start_user_direct_invites,\n        rwns.end_user_unique_invited,\n        rwns.end_user_total_paths,\n        ROUND(CAST(rwns.end_user_avg_length AS NUMERIC), 2) AS end_user_avg_length,\n        rwns.end_user_direct_invites,\n        rwns.path_count_10_window,\n        ROUND(CAST(rwns.duration_20_path_avg AS NUMERIC), 2) AS duration_20_path_avg,\n        rwns.chats_path_range_window,\n        rwns.prev_path_count,\n        ROUND(CAST(rwns.next_chain_duration AS NUMERIC), 2) AS next_chain_duration,\n        rwns.first_path_chats,\n        ROUND(CAST(rwns.last_path_duration AS NUMERIC), 2) AS last_path_duration,\n        p1.username AS chain_start_user,\n        p2.username AS chain_end_user,\n        -- Network strength score\n        (\n            (rwns.path_count * 0.3) +\n            (rwns.unique_chats * 0.25) +\n            (rwns.start_user_direct_invites * 0.2) +\n            (rwns.end_user_direct_invites * 0.15) +\n            (CASE WHEN rwns.chain_duration_hours > 0 THEN 1.0 / (1.0 + rwns.chain_duration_hours / 24.0) ELSE 0 END * 0.1)\n        ) AS network_strength_score,\n        -- Window function rankings\n        ROW_NUMBER() OVER (PARTITION BY rwns.chain_length ORDER BY rwns.path_count DESC) AS path_count_row_num,\n        RANK() OVER (PARTITION BY rwns.chain_length ORDER BY rwns.path_count DESC) AS path_count_rank,\n        DENSE_RANK() OVER (ORDER BY rwns.chain_length, rwns.path_count DESC) AS path_dense_rank,\n        PERCENT_RANK() OVER (PARTITION BY rwns.chain_length ORDER BY rwns.path_count DESC) AS path_percentile,\n        NTILE(5) OVER (PARTITION BY rwns.chain_length ORDER BY rwns.path_count DESC) AS path_quintile,\n        NTILE(10) OVER (ORDER BY rwns.chain_length, rwns.path_count DESC) AS path_decile,\n        -- Window functions with frames\n        SUM(rwns.path_count) OVER (\n            PARTITION BY rwns.chain_length\n            ORDER BY rwns.path_count DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_path_count,\n        AVG(rwns.path_count) OVER (\n            PARTITION BY rwns.chain_length\n            ORDER BY rwns.path_count DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_path_count,\n        LAG(rwns.path_count, 1) OVER (PARTITION BY rwns.chain_length ORDER BY rwns.path_count DESC) AS prev_path_count_in_length,\n        LEAD(rwns.unique_chats, 1) OVER (PARTITION BY rwns.chain_length ORDER BY rwns.path_count DESC) AS next_unique_chats,\n        -- Pivot CASE for classification\n        CASE\n            WHEN rwns.path_count >= 10 THEN 'High Frequency'\n            WHEN rwns.path_count >= 5 THEN 'Medium Frequency'\n            WHEN rwns.path_count >= 2 THEN 'Low Frequency'\n            ELSE 'Rare'\n        END AS frequency_category,\n        CASE\n            WHEN rwns.chain_length = 1 THEN 'Direct'\n            WHEN rwns.chain_length = 2 THEN 'One-Hop'\n            WHEN rwns.chain_length = 3 THEN 'Two-Hop'\n            WHEN rwns.chain_length = 4 THEN 'Three-Hop'\n            ELSE 'Deep'\n        END AS chain_type\n    FROM rolling_window_network_stats rwns\n    INNER JOIN profiles p1 ON rwns.chain_start = p1.id\n    INNER JOIN profiles p2 ON rwns.chain_end = p2.id\n)\nSELECT\n    chain_start_user,\n    chain_end_user,\n    chain_length,\n    path_count,\n    unique_chats,\n    chain_duration_hours,\n    start_user_unique_invited,\n    start_user_total_paths,\n    start_user_avg_length,\n    start_user_direct_invites,\n    end_user_unique_invited,\n    end_user_total_paths,\n    end_user_avg_length,\n    end_user_direct_invites,\n    path_count_10_window,\n    duration_20_path_avg,\n    chats_path_range_window,\n    prev_path_count,\n    next_chain_duration,\n    first_path_chats,\n    last_path_duration,\n    ROUND(CAST(network_strength_score AS NUMERIC), 2) AS network_strength_score,\n    path_count_row_num,\n    path_count_rank,\n    path_dense_rank,\n    ROUND(CAST(path_percentile * 100 AS NUMERIC), 2) AS path_percentile,\n    path_quintile,\n    path_decile,\n    cumulative_path_count,\n    ROUND(CAST(moving_avg_path_count AS NUMERIC), 2) AS moving_avg_path_count,\n    prev_path_count_in_length,\n    next_unique_chats,\n    frequency_category,\n    chain_type\nFROM final_invitation_chain_analytics\nORDER BY chain_length, path_count DESC;",
      "line_number": 5156
    },
    {
      "number": 12,
      "title": "Production-Grade Message Response Time Analysis with Recursive CTE and Advanced Window Functions",
      "description": "Description: Enterprise-level message response time analysis with recursive CTE for conversation flow tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive response time analytics. Implements production patterns similar to conversation analytics platforms. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE conversation_flow AS (\n    -- Anchor: Base message flow\n    SELECT\n        m.id AS message_id,\n        m.chat_id,\n        m.sender_id,\n        m.is_ai,\n        m.created_at,\n        1 AS flow_depth,\n        ARRAY[m.id] AS flow_path\n    FROM messages m\n\n    UNION ALL\n\n    -- Recursive: Find related messages in conversation flow\n    SELECT\n        m2.id AS message_id,\n        m2.chat_id,\n        m2.sender_id,\n        m2.is_ai,\n        m2.created_at,\n        cf.flow_depth + 1,\n        cf.flow_path || m2.id\n    FROM conversation_flow cf\n    INNER JOIN messages m2 ON cf.chat_id = m2.chat_id\n    WHERE m2.id != ALL(cf.flow_path)\n        AND m2.created_at BETWEEN cf.created_at AND cf.created_at + INTERVAL '1 hour'\n        AND m2.is_ai != cf.is_ai\n        AND cf.flow_depth < 10\n),\nmessage_sequence AS (\n    -- First CTE: Message sequence with joins and correlated subqueries\n    SELECT\n        m.id,\n        m.chat_id,\n        m.sender_id,\n        m.is_ai,\n        m.created_at,\n        c.title AS chat_title,\n        p.username AS sender_username,\n        ROW_NUMBER() OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS seq_num,\n        LAG(m.created_at, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS prev_message_time,\n        LAG(m.created_at, 2) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS prev2_message_time,\n        LAG(m.is_ai, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS prev_is_ai,\n        LEAD(m.created_at, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS next_message_time,\n        LEAD(m.is_ai, 1) OVER (PARTITION BY m.chat_id ORDER BY m.created_at) AS next_is_ai,\n        (\n            SELECT AVG(EXTRACT(EPOCH FROM (m2.created_at - m3.created_at)))\n            FROM messages m2\n            INNER JOIN messages m3 ON m2.chat_id = m3.chat_id\n            WHERE m2.chat_id = m.chat_id\n                AND m2.id > m3.id\n                AND m2.is_ai != m3.is_ai\n                AND m2.created_at < m.created_at\n        ) AS avg_historical_response_time,\n        (\n            SELECT COUNT(*)\n            FROM messages m4\n            WHERE m4.chat_id = m.chat_id\n                AND m4.created_at < m.created_at\n                AND m4.is_ai != m.is_ai\n        ) AS prior_alternating_messages\n    FROM messages m\n    INNER JOIN chats c ON m.chat_id = c.id\n    LEFT JOIN profiles p ON m.sender_id = p.id\n),\nconversation_flow_metrics AS (\n    -- Second CTE: Conversation flow metrics from recursive CTE\n    SELECT\n        chat_id,\n        COUNT(DISTINCT sender_id) AS unique_participants_in_flow,\n        AVG(flow_depth) AS avg_flow_depth,\n        MAX(flow_depth) AS max_flow_depth,\n        COUNT(*) AS total_flow_messages\n    FROM conversation_flow\n    GROUP BY chat_id\n),\nresponse_times AS (\n    -- Third CTE: Response time calculations\n    SELECT\n        ms.id,\n        ms.chat_id,\n        ms.sender_id,\n        ms.is_ai,\n        ms.created_at,\n        ms.chat_title,\n        ms.sender_username,\n        ms.seq_num,\n        ms.prev_message_time,\n        ms.prev2_message_time,\n        ms.prev_is_ai,\n        ms.next_message_time,\n        ms.next_is_ai,\n        ms.avg_historical_response_time,\n        ms.prior_alternating_messages,\n        COALESCE(cfm.unique_participants_in_flow, 0) AS unique_participants_in_flow,\n        COALESCE(cfm.avg_flow_depth, 0) AS avg_flow_depth,\n        COALESCE(cfm.max_flow_depth, 0) AS max_flow_depth,\n        COALESCE(cfm.total_flow_messages, 0) AS total_flow_messages,\n        EXTRACT(EPOCH FROM (ms.created_at - ms.prev_message_time)) AS seconds_since_prev,\n        EXTRACT(EPOCH FROM (ms.created_at - ms.prev2_message_time)) AS seconds_since_prev2,\n        CASE\n            WHEN ms.prev_is_ai = false AND ms.is_ai = true THEN 'AI Response'\n            WHEN ms.prev_is_ai = true AND ms.is_ai = false THEN 'User Response'\n            ELSE 'Same Type'\n        END AS response_type\n    FROM message_sequence ms\n    LEFT JOIN conversation_flow_metrics cfm ON ms.chat_id = cfm.chat_id\n    WHERE ms.prev_message_time IS NOT NULL\n),\nrolling_window_response_stats AS (\n    -- Fourth CTE: Rolling window statistics with frame clauses\n    SELECT\n        rt.*,\n        -- Window functions with ROWS BETWEEN frames\n        AVG(rt.seconds_since_prev) OVER (\n            PARTITION BY rt.chat_id, rt.response_type\n            ORDER BY rt.created_at\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS response_time_10_message_avg,\n        SUM(rt.seconds_since_prev) OVER (\n            PARTITION BY rt.chat_id\n            ORDER BY rt.created_at\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS response_time_20_message_sum,\n        -- Window functions with RANGE BETWEEN frames\n        AVG(rt.seconds_since_prev) OVER (\n            PARTITION BY rt.chat_id\n            ORDER BY rt.seconds_since_prev\n            RANGE BETWEEN 60 PRECEDING AND 60 FOLLOWING\n        ) AS response_time_range_avg,\n        -- Lag/Lead functions\n        LAG(rt.seconds_since_prev, 1) OVER (PARTITION BY rt.chat_id, rt.response_type ORDER BY rt.created_at) AS prev_response_time,\n        LEAD(rt.seconds_since_prev, 1) OVER (PARTITION BY rt.chat_id, rt.response_type ORDER BY rt.created_at) AS next_response_time,\n        -- First/Last value with frames\n        FIRST_VALUE(rt.seconds_since_prev) OVER (\n            PARTITION BY rt.chat_id, rt.response_type\n            ORDER BY rt.created_at\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_response_time,\n        LAST_VALUE(rt.seconds_since_prev) OVER (\n            PARTITION BY rt.chat_id, rt.response_type\n            ORDER BY rt.created_at\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_response_time\n    FROM response_times rt\n),\nresponse_statistics AS (\n    -- Fifth CTE: Response statistics with aggregations\n    SELECT\n        rwrs.chat_id,\n        rwrs.chat_title,\n        rwrs.response_type,\n        COUNT(*) AS response_count,\n        AVG(rwrs.seconds_since_prev) AS avg_response_seconds,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY rwrs.seconds_since_prev) AS median_response_seconds,\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY rwrs.seconds_since_prev) AS p25_response_seconds,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY rwrs.seconds_since_prev) AS p75_response_seconds,\n        MIN(rwrs.seconds_since_prev) AS min_response_seconds,\n        MAX(rwrs.seconds_since_prev) AS max_response_seconds,\n        STDDEV(rwrs.seconds_since_prev) AS stddev_response_seconds,\n        AVG(rwrs.avg_historical_response_time) AS avg_historical_response_time,\n        AVG(rwrs.prior_alternating_messages) AS avg_prior_alternating_messages,\n        AVG(rwrs.unique_participants_in_flow) AS avg_unique_participants,\n        AVG(rwrs.avg_flow_depth) AS avg_flow_depth,\n        AVG(rwrs.max_flow_depth) AS avg_max_flow_depth,\n        AVG(rwrs.response_time_10_message_avg) AS avg_10_message_window,\n        AVG(rwrs.response_time_20_message_sum) AS avg_20_message_sum,\n        AVG(rwrs.response_time_range_avg) AS avg_range_window\n    FROM rolling_window_response_stats rwrs\n    WHERE rwrs.response_type != 'Same Type'\n    GROUP BY rwrs.chat_id, rwrs.chat_title, rwrs.response_type\n),\nunion_response_metrics AS (\n    -- Sixth CTE: UNION to combine different metric types\n    SELECT\n        rs.chat_id,\n        rs.response_type,\n        'avg' AS metric_type,\n        rs.avg_response_seconds AS metric_value\n    FROM response_statistics rs\n\n    UNION ALL\n\n    SELECT\n        rs.chat_id,\n        rs.response_type,\n        'median' AS metric_type,\n        rs.median_response_seconds AS metric_value\n    FROM response_statistics rs\n\n    UNION ALL\n\n    SELECT\n        rs.chat_id,\n        rs.response_type,\n        'count' AS metric_type,\n        rs.response_count AS metric_value\n    FROM response_statistics rs\n),\naggregated_union_response_metrics AS (\n    -- Seventh CTE: Aggregate UNION results with window functions\n    SELECT\n        urm.chat_id,\n        urm.response_type,\n        SUM(CASE WHEN urm.metric_type = 'avg' THEN urm.metric_value ELSE 0 END) AS total_avg_metric,\n        SUM(CASE WHEN urm.metric_type = 'median' THEN urm.metric_value ELSE 0 END) AS total_median_metric,\n        SUM(CASE WHEN urm.metric_type = 'count' THEN urm.metric_value ELSE 0 END) AS total_count_metric,\n        COUNT(DISTINCT urm.metric_type) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(urm.metric_value) OVER (\n            PARTITION BY urm.metric_type, urm.response_type\n            ORDER BY urm.chat_id\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(urm.metric_value) OVER (\n            PARTITION BY urm.chat_id, urm.response_type\n            ORDER BY urm.metric_type\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS chat_cumulative_metric\n    FROM union_response_metrics urm\n    GROUP BY urm.chat_id, urm.response_type, urm.metric_type, urm.metric_value\n),\nfinal_response_time_analytics AS (\n    -- Eighth CTE: Final analytics with comprehensive window functions\n    SELECT\n        rs.chat_id,\n        rs.chat_title,\n        rs.response_type,\n        rs.response_count,\n        ROUND(CAST(rs.avg_response_seconds AS NUMERIC), 2) AS avg_seconds,\n        ROUND(CAST(rs.median_response_seconds AS NUMERIC), 2) AS median_seconds,\n        ROUND(CAST(rs.p25_response_seconds AS NUMERIC), 2) AS p25_seconds,\n        ROUND(CAST(rs.p75_response_seconds AS NUMERIC), 2) AS p75_seconds,\n        ROUND(CAST(rs.min_response_seconds AS NUMERIC), 2) AS min_seconds,\n        ROUND(CAST(rs.max_response_seconds AS NUMERIC), 2) AS max_seconds,\n        ROUND(CAST(rs.stddev_response_seconds AS NUMERIC), 2) AS stddev_seconds,\n        ROUND(CAST(rs.avg_historical_response_time AS NUMERIC), 2) AS avg_historical_response_time,\n        ROUND(CAST(rs.avg_prior_alternating_messages AS NUMERIC), 2) AS avg_prior_alternating_messages,\n        ROUND(CAST(rs.avg_unique_participants AS NUMERIC), 2) AS avg_unique_participants,\n        ROUND(CAST(rs.avg_flow_depth AS NUMERIC), 2) AS avg_flow_depth,\n        ROUND(CAST(rs.avg_max_flow_depth AS NUMERIC), 2) AS avg_max_flow_depth,\n        ROUND(CAST(rs.avg_10_message_window AS NUMERIC), 2) AS avg_10_message_window,\n        ROUND(CAST(rs.avg_20_message_sum AS NUMERIC), 2) AS avg_20_message_sum,\n        ROUND(CAST(rs.avg_range_window AS NUMERIC), 2) AS avg_range_window,\n        -- Multiple ranking methods\n        ROW_NUMBER() OVER (PARTITION BY rs.response_type ORDER BY rs.avg_response_seconds ASC) AS response_time_row_num,\n        RANK() OVER (PARTITION BY rs.response_type ORDER BY rs.avg_response_seconds ASC) AS response_time_rank,\n        DENSE_RANK() OVER (PARTITION BY rs.response_type ORDER BY rs.response_count DESC) AS response_count_dense_rank,\n        PERCENT_RANK() OVER (PARTITION BY rs.response_type ORDER BY rs.avg_response_seconds ASC) AS response_time_percentile,\n        NTILE(5) OVER (PARTITION BY rs.response_type ORDER BY rs.avg_response_seconds ASC) AS response_time_quintile,\n        NTILE(10) OVER (ORDER BY rs.avg_response_seconds ASC) AS response_time_decile,\n        -- Window functions with frames\n        SUM(rs.response_count) OVER (\n            PARTITION BY rs.response_type\n            ORDER BY rs.avg_response_seconds ASC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_response_count,\n        AVG(rs.avg_response_seconds) OVER (\n            PARTITION BY rs.response_type\n            ORDER BY rs.avg_response_seconds ASC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_response_time,\n        LAG(rs.avg_response_seconds, 1) OVER (PARTITION BY rs.response_type ORDER BY rs.avg_response_seconds ASC) AS prev_avg_response_time,\n        LEAD(rs.response_count, 1) OVER (PARTITION BY rs.response_type ORDER BY rs.avg_response_seconds ASC) AS next_response_count,\n        -- Pivot CASE for classification\n        CASE\n            WHEN rs.avg_response_seconds <= 5 THEN 'Instant'\n            WHEN rs.avg_response_seconds <= 30 THEN 'Very Fast'\n            WHEN rs.avg_response_seconds <= 60 THEN 'Fast'\n            WHEN rs.avg_response_seconds <= 300 THEN 'Moderate'\n            ELSE 'Slow'\n        END AS response_time_category,\n        CASE\n            WHEN rs.response_count >= 50 THEN 'High Volume'\n            WHEN rs.response_count >= 20 THEN 'Medium Volume'\n            WHEN rs.response_count >= 10 THEN 'Low Volume'\n            ELSE 'Minimal'\n        END AS volume_category\n    FROM response_statistics rs\n)\nSELECT\n    chat_title,\n    response_type,\n    response_count,\n    avg_seconds,\n    median_seconds,\n    p25_seconds,\n    p75_seconds,\n    min_seconds,\n    max_seconds,\n    stddev_seconds,\n    avg_historical_response_time,\n    avg_prior_alternating_messages,\n    avg_unique_participants,\n    avg_flow_depth,\n    avg_max_flow_depth,\n    avg_10_message_window,\n    avg_20_message_sum,\n    avg_range_window,\n    response_time_row_num,\n    response_time_rank,\n    response_count_dense_rank,\n    ROUND(CAST(response_time_percentile * 100 AS NUMERIC), 2) AS response_time_percentile,\n    response_time_quintile,\n    response_time_decile,\n    cumulative_response_count,\n    ROUND(CAST(moving_avg_response_time AS NUMERIC), 2) AS moving_avg_response_time,\n    ROUND(CAST(prev_avg_response_time AS NUMERIC), 2) AS prev_avg_response_time,\n    next_response_count,\n    response_time_category,\n    volume_category\nFROM final_response_time_analytics\nORDER BY chat_id, response_type;",
      "line_number": 5639
    },
    {
      "number": 13,
      "title": "Production-Grade Friend Network Clustering Analysis with Recursive CTE and Advanced Graph Metrics",
      "description": "Description: Enterprise-level friend network clustering analysis with recursive CTE for multi-hop friend discovery, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive network density analytics. Implements production patterns similar to social network analysis platforms. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, ",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE friend_network_expansion AS (\n    -- Anchor: Direct friend connections\n    SELECT\n        f1.user_id AS user_a,\n        f2.user_id AS user_b,\n        f1.friend_id AS intermediate_user,\n        1 AS connection_depth,\n        ARRAY[f1.user_id, f2.user_id] AS connection_path\n    FROM friends f1\n    INNER JOIN friends f2 ON f1.friend_id = f2.friend_id AND f1.user_id = f2.friend_id\n    WHERE f1.status = 'accepted' AND f2.status = 'accepted'\n\n    UNION ALL\n\n    -- Recursive: Multi-hop friend connections\n    SELECT\n        fne.user_a,\n        f3.user_id AS user_b,\n        f3.friend_id AS intermediate_user,\n        fne.connection_depth + 1,\n        fne.connection_path || f3.user_id\n    FROM friend_network_expansion fne\n    INNER JOIN friends f3 ON fne.user_b = f3.friend_id AND f3.status = 'accepted'\n    INNER JOIN friends f4 ON f4.user_id = fne.user_a AND f4.friend_id = f3.user_id AND f4.status = 'accepted'\n    WHERE f3.user_id != ALL(fne.connection_path)\n        AND fne.connection_depth < 3\n),\nfriend_pairs AS (\n    -- First CTE: Base friend pairs with joins\n    SELECT\n        f1.user_id AS user_a,\n        f2.user_id AS user_b,\n        f1.status AS status_a,\n        f2.status AS status_b,\n        f1.created_at AS friendship_start_a,\n        f2.created_at AS friendship_start_b\n    FROM friends f1\n    INNER JOIN friends f2 ON f1.friend_id = f2.friend_id AND f1.user_id = f2.friend_id\n    WHERE f1.status = 'accepted' AND f2.status = 'accepted'\n),\nmutual_friend_counts AS (\n    -- Second CTE: Mutual friend calculations with correlated subqueries\n    SELECT\n        fp.user_a,\n        fp.user_b,\n        COUNT(DISTINCT f3.friend_id) AS mutual_friends,\n        (\n            SELECT COUNT(*)\n            FROM friends f5\n            WHERE f5.user_id = fp.user_a\n                AND f5.status = 'accepted'\n                AND EXISTS (\n                    SELECT 1\n                    FROM friends f6\n                    WHERE f6.user_id = fp.user_b\n                        AND f6.friend_id = f5.friend_id\n                        AND f6.status = 'accepted'\n                )\n        ) AS verified_mutual_friends,\n        (\n            SELECT AVG(mutual_count)\n            FROM (\n                SELECT COUNT(*) AS mutual_count\n                FROM friends f7\n                WHERE f7.user_id = fp.user_a\n                    AND f7.status = 'accepted'\n                    AND EXISTS (\n                        SELECT 1\n                        FROM friends f8\n                        WHERE f8.user_id = fp.user_b\n                            AND f8.friend_id = f7.friend_id\n                            AND f8.status = 'accepted'\n                    )\n            ) mutual_verification\n        ) AS avg_mutual_verification\n    FROM friend_pairs fp\n    LEFT JOIN friends f3 ON f3.user_id = fp.user_a AND f3.status = 'accepted'\n    INNER JOIN friends f4 ON f4.user_id = fp.user_b AND f4.friend_id = f3.friend_id AND f4.status = 'accepted'\n    GROUP BY fp.user_a, fp.user_b\n),\nnetwork_expansion_metrics AS (\n    -- Third CTE: Network expansion metrics from recursive CTE\n    SELECT\n        user_a,\n        user_b,\n        COUNT(DISTINCT intermediate_user) AS unique_intermediaries,\n        AVG(connection_depth) AS avg_connection_depth,\n        MIN(connection_depth) AS min_connection_depth,\n        MAX(connection_depth) AS max_connection_depth,\n        COUNT(*) AS total_connection_paths\n    FROM friend_network_expansion\n    GROUP BY user_a, user_b\n),\nuser_friend_counts AS (\n    -- Fourth CTE: User friend counts\n    SELECT\n        user_id,\n        COUNT(*) AS friend_count,\n        COUNT(DISTINCT CASE WHEN status = 'accepted' THEN friend_id END) AS accepted_friend_count,\n        MIN(created_at) AS first_friendship_date,\n        MAX(created_at) AS last_friendship_date\n    FROM friends\n    GROUP BY user_id\n),\nrolling_window_cluster_stats AS (\n    -- Fifth CTE: Rolling window statistics with frame clauses\n    SELECT\n        mfc.user_a,\n        mfc.user_b,\n        mfc.mutual_friends,\n        mfc.verified_mutual_friends,\n        mfc.avg_mutual_verification,\n        COALESCE(nem.unique_intermediaries, 0) AS unique_intermediaries,\n        COALESCE(nem.avg_connection_depth, 0) AS avg_connection_depth,\n        COALESCE(nem.min_connection_depth, 0) AS min_connection_depth,\n        COALESCE(nem.max_connection_depth, 0) AS max_connection_depth,\n        COALESCE(nem.total_connection_paths, 0) AS total_connection_paths,\n        ufc1.friend_count AS user_a_friends,\n        ufc1.accepted_friend_count AS user_a_accepted_friends,\n        ufc2.friend_count AS user_b_friends,\n        ufc2.accepted_friend_count AS user_b_accepted_friends,\n        -- Window functions with ROWS BETWEEN frames\n        SUM(mfc.mutual_friends) OVER (\n            ORDER BY mfc.mutual_friends DESC\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS mutual_friends_10_pair_window,\n        AVG(mfc.mutual_friends) OVER (\n            ORDER BY mfc.mutual_friends DESC\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS mutual_friends_20_pair_avg,\n        -- Window functions with RANGE BETWEEN frames\n        SUM(mfc.mutual_friends) OVER (\n            ORDER BY mfc.mutual_friends\n            RANGE BETWEEN 5 PRECEDING AND 5 FOLLOWING\n        ) AS mutual_friends_range_window,\n        -- Lag/Lead functions\n        LAG(mfc.mutual_friends, 1) OVER (ORDER BY mfc.mutual_friends DESC) AS prev_mutual_friends,\n        LEAD(mfc.mutual_friends, 1) OVER (ORDER BY mfc.mutual_friends DESC) AS next_mutual_friends,\n        -- First/Last value with frames\n        FIRST_VALUE(mfc.mutual_friends) OVER (\n            ORDER BY mfc.mutual_friends DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_mutual_friends,\n        LAST_VALUE(mfc.mutual_friends) OVER (\n            ORDER BY mfc.mutual_friends DESC\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_mutual_friends\n    FROM mutual_friend_counts mfc\n    INNER JOIN user_friend_counts ufc1 ON mfc.user_a = ufc1.user_id\n    INNER JOIN user_friend_counts ufc2 ON mfc.user_b = ufc2.user_id\n    LEFT JOIN network_expansion_metrics nem ON mfc.user_a = nem.user_a AND mfc.user_b = nem.user_b\n),\ncluster_metrics AS (\n    -- Sixth CTE: Cluster metrics with pivot CASE\n    SELECT\n        rwcs.user_a,\n        rwcs.user_b,\n        rwcs.mutual_friends,\n        rwcs.verified_mutual_friends,\n        ROUND(CAST(rwcs.avg_mutual_verification AS NUMERIC), 2) AS avg_mutual_verification,\n        rwcs.unique_intermediaries,\n        ROUND(CAST(rwcs.avg_connection_depth AS NUMERIC), 2) AS avg_connection_depth,\n        rwcs.min_connection_depth,\n        rwcs.max_connection_depth,\n        rwcs.total_connection_paths,\n        rwcs.user_a_friends,\n        rwcs.user_a_accepted_friends,\n        rwcs.user_b_friends,\n        rwcs.user_b_accepted_friends,\n        rwcs.mutual_friends_10_pair_window,\n        ROUND(CAST(rwcs.mutual_friends_20_pair_avg AS NUMERIC), 2) AS mutual_friends_20_pair_avg,\n        rwcs.mutual_friends_range_window,\n        rwcs.prev_mutual_friends,\n        rwcs.next_mutual_friends,\n        rwcs.first_mutual_friends,\n        rwcs.last_mutual_friends,\n        ROUND(rwcs.mutual_friends::numeric / NULLIF(LEAST(rwcs.user_a_friends, rwcs.user_b_friends), 0), 3) AS friend_overlap_ratio,\n        ROUND(rwcs.mutual_friends::numeric / NULLIF(GREATEST(rwcs.user_a_friends, rwcs.user_b_friends), 0), 3) AS friend_jaccard_similarity,\n        -- Pivot CASE for classification\n        CASE\n            WHEN rwcs.mutual_friends::numeric / NULLIF(LEAST(rwcs.user_a_friends, rwcs.user_b_friends), 0) > 0.5 THEN 'High Overlap'\n            WHEN rwcs.mutual_friends::numeric / NULLIF(LEAST(rwcs.user_a_friends, rwcs.user_b_friends), 0) > 0.2 THEN 'Medium Overlap'\n            WHEN rwcs.mutual_friends::numeric / NULLIF(LEAST(rwcs.user_a_friends, rwcs.user_b_friends), 0) > 0.1 THEN 'Low Overlap'\n            ELSE 'Minimal Overlap'\n        END AS overlap_category,\n        CASE\n            WHEN rwcs.avg_connection_depth <= 1.5 THEN 'Direct'\n            WHEN rwcs.avg_connection_depth <= 2.0 THEN 'Close'\n            WHEN rwcs.avg_connection_depth <= 2.5 THEN 'Moderate'\n            ELSE 'Distant'\n        END AS connection_category\n    FROM rolling_window_cluster_stats rwcs\n),\nunion_cluster_metrics AS (\n    -- Seventh CTE: UNION to combine different metric types\n    SELECT\n        cm.user_a,\n        cm.user_b,\n        'mutual_friends' AS metric_type,\n        cm.mutual_friends AS metric_value\n    FROM cluster_metrics cm\n\n    UNION ALL\n\n    SELECT\n        cm.user_a,\n        cm.user_b,\n        'overlap_ratio' AS metric_type,\n        cm.friend_overlap_ratio AS metric_value\n    FROM cluster_metrics cm\n\n    UNION ALL\n\n    SELECT\n        cm.user_a,\n        cm.user_b,\n        'connection_depth' AS metric_type,\n        cm.avg_connection_depth AS metric_value\n    FROM cluster_metrics cm\n),\naggregated_union_cluster_metrics AS (\n    -- Eighth CTE: Aggregate UNION results with window functions\n    SELECT\n        NULL,\n        NULL,\n        SUM(CASE WHEN NULL = 'mutual_friends' THEN NULL ELSE 0 END) AS total_mutual_metric,\n        SUM(CASE WHEN NULL = 'overlap_ratio' THEN NULL ELSE 0 END) AS total_overlap_metric,\n        SUM(CASE WHEN NULL = 'connection_depth' THEN NULL ELSE 0 END) AS total_depth_metric,\n        COUNT(DISTINCT NULL) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(CAST(0 AS NUMERIC)) OVER (\n            PARTITION BY ucm.metric_type\n            ORDER BY ucm.user_a\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(CAST(0 AS NUMERIC)) OVER (\n            PARTITION BY ucm.user_a\n            ORDER BY ucm.user_a\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS pair_cumulative_metric\n    FROM union_cluster_metrics ucm\n    GROUP BY ucm.user_a, ucm.user_b, ucm.metric_type\n),\nfinal_cluster_analytics AS (\n    -- Ninth CTE: Final analytics with comprehensive window functions\n    SELECT\n        cm.user_a,\n        cm.user_b,\n        p1.username AS user_a_name,\n        p2.username AS user_b_name,\n        cm.mutual_friends,\n        cm.verified_mutual_friends,\n        cm.avg_mutual_verification,\n        cm.unique_intermediaries,\n        cm.avg_connection_depth,\n        cm.min_connection_depth,\n        cm.max_connection_depth,\n        cm.total_connection_paths,\n        cm.user_a_friends,\n        cm.user_a_accepted_friends,\n        cm.user_b_friends,\n        cm.user_b_accepted_friends,\n        cm.mutual_friends_10_pair_window,\n        cm.mutual_friends_20_pair_avg,\n        cm.mutual_friends_range_window,\n        cm.prev_mutual_friends,\n        cm.next_mutual_friends,\n        cm.first_mutual_friends,\n        cm.last_mutual_friends,\n        cm.friend_overlap_ratio,\n        cm.friend_jaccard_similarity,\n        cm.overlap_category,\n        cm.connection_category,\n        -- Network strength score\n        (\n            (cm.mutual_friends * 0.3) +\n            (cm.friend_overlap_ratio * 100 * 0.25) +\n            (cm.friend_jaccard_similarity * 100 * 0.2) +\n            (cm.unique_intermediaries * 0.15) +\n            (CASE WHEN cm.avg_connection_depth > 0 THEN 1.0 / cm.avg_connection_depth ELSE 0 END * 0.1)\n        ) AS network_strength_score,\n        -- Window function rankings\n        ROW_NUMBER() OVER (ORDER BY cm.mutual_friends DESC) AS mutual_friends_row_num,\n        RANK() OVER (ORDER BY cm.mutual_friends DESC) AS mutual_friends_rank,\n        DENSE_RANK() OVER (ORDER BY cm.friend_overlap_ratio DESC) AS overlap_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY cm.mutual_friends DESC) AS mutual_friends_percentile,\n        NTILE(5) OVER (ORDER BY cm.mutual_friends DESC) AS mutual_friends_quintile,\n        NTILE(10) OVER (ORDER BY cm.friend_overlap_ratio DESC) AS overlap_decile,\n        -- Window functions with frames\n        SUM(cm.mutual_friends) OVER (\n            ORDER BY cm.mutual_friends DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_mutual_friends,\n        AVG(cm.friend_overlap_ratio) OVER (\n            ORDER BY cm.friend_overlap_ratio DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_overlap_ratio,\n        LAG(cm.mutual_friends, 1) OVER (ORDER BY cm.mutual_friends DESC) AS prev_mutual_friends_ranked,\n        LEAD(cm.friend_overlap_ratio, 1) OVER (ORDER BY cm.friend_overlap_ratio DESC) AS next_overlap_ratio\n    FROM cluster_metrics cm\n    INNER JOIN profiles p1 ON cm.user_a = p1.id\n    INNER JOIN profiles p2 ON cm.user_b = p2.id\n)\nSELECT\n    user_a_name,\n    user_b_name,\n    mutual_friends,\n    verified_mutual_friends,\n    avg_mutual_verification,\n    unique_intermediaries,\n    avg_connection_depth,\n    min_connection_depth,\n    max_connection_depth,\n    total_connection_paths,\n    user_a_friends,\n    user_a_accepted_friends,\n    user_b_friends,\n    user_b_accepted_friends,\n    mutual_friends_10_pair_window,\n    mutual_friends_20_pair_avg,\n    mutual_friends_range_window,\n    prev_mutual_friends,\n    next_mutual_friends,\n    first_mutual_friends,\n    last_mutual_friends,\n    friend_overlap_ratio,\n    friend_jaccard_similarity,\n    overlap_category,\n    connection_category,\n    ROUND(CAST(network_strength_score AS NUMERIC), 2) AS network_strength_score,\n    mutual_friends_row_num,\n    mutual_friends_rank,\n    overlap_dense_rank,\n    ROUND(CAST(mutual_friends_percentile * 100 AS NUMERIC), 2) AS mutual_friends_percentile,\n    mutual_friends_quintile,\n    overlap_decile,\n    cumulative_mutual_friends,\n    ROUND(CAST(moving_avg_overlap_ratio AS NUMERIC), 3) AS moving_avg_overlap_ratio,\n    prev_mutual_friends_ranked,\n    ROUND(CAST(next_overlap_ratio AS NUMERIC), 3) AS next_overlap_ratio\nFROM final_cluster_analytics\nORDER BY mutual_friends DESC, friend_overlap_ratio DESC;",
      "line_number": 6168
    },
    {
      "number": 14,
      "title": "Production-Grade Time-Based Chat Activity Heatmap with Recursive CTE and Advanced Temporal Analytics",
      "description": "Description: Enterprise-level time-based activity heatmap with recursive CTE for temporal pattern discovery, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive heatmap analytics. Implements production patterns similar to time-series analytics platforms. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, ag",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE temporal_pattern_hierarchy AS (\n    -- Anchor: Base time periods\n    SELECT\n        DATE_TRUNC('hour', m.created_at) AS time_period,\n        EXTRACT(DOW FROM m.created_at) AS day_of_week,\n        EXTRACT(HOUR FROM m.created_at) AS hour_of_day,\n        COUNT(*) AS message_count,\n        'hour' AS period_type\n    FROM messages m\n    GROUP BY DATE_TRUNC('hour', m.created_at), EXTRACT(DOW FROM m.created_at), EXTRACT(HOUR FROM m.created_at)\n\n    UNION ALL\n\n    -- Recursive: Aggregate to higher time periods\n    SELECT\n        DATE_TRUNC('day', tph.time_period) AS time_period,\n        tph.day_of_week,\n        NULL::integer AS hour_of_day,\n        tph.message_count AS message_count,\n        'day' AS period_type\n    FROM temporal_pattern_hierarchy tph\n    WHERE tph.period_type = 'hour'\n        AND DATE_TRUNC('day', tph.time_period) != tph.time_period\n    GROUP BY DATE_TRUNC('day', tph.time_period), tph.day_of_week, tph.message_count\n),\nhourly_activity AS (\n    -- First CTE: Base hourly activity with joins and correlated subqueries\n    SELECT\n        EXTRACT(DOW FROM m.created_at) AS day_of_week,\n        EXTRACT(HOUR FROM m.created_at) AS hour_of_day,\n        m.created_at,\n        COUNT(*) AS message_count,\n        COUNT(DISTINCT m.chat_id) AS active_chats,\n        COUNT(DISTINCT m.sender_id) AS active_users,\n        COUNT(CASE WHEN m.is_ai = false THEN 1 END) AS user_messages,\n        COUNT(CASE WHEN m.is_ai = true THEN 1 END) AS ai_messages,\n        AVG(LENGTH(m.content)) AS avg_message_length,\n        (\n            SELECT COUNT(DISTINCT m2.chat_id)\n            FROM messages m2\n            WHERE EXTRACT(DOW FROM m2.created_at) = EXTRACT(DOW FROM m.created_at)\n                AND EXTRACT(HOUR FROM m2.created_at) = EXTRACT(HOUR FROM m.created_at)\n                AND m2.is_ai = false\n                AND EXISTS (\n                    SELECT 1\n                    FROM messages m3\n                    WHERE m3.chat_id = m2.chat_id\n                        AND EXTRACT(DOW FROM m3.created_at) = EXTRACT(DOW FROM m.created_at)\n                        AND EXTRACT(HOUR FROM m3.created_at) = EXTRACT(HOUR FROM m.created_at)\n                        AND m3.is_ai = true\n                )\n        ) AS chats_with_ai_interaction\n    FROM messages m\n    GROUP BY EXTRACT(DOW FROM m.created_at), EXTRACT(HOUR FROM m.created_at), m.created_at\n),\ntemporal_pattern_metrics AS (\n    -- Second CTE: Temporal pattern metrics from recursive CTE\n    SELECT\n        day_of_week,\n        COUNT(DISTINCT time_period) AS unique_periods,\n        SUM(message_count) AS total_pattern_messages,\n        AVG(message_count) AS avg_pattern_messages\n    FROM temporal_pattern_hierarchy\n    WHERE period_type = 'day'\n    GROUP BY day_of_week\n),\nrolling_window_hourly_stats AS (\n    -- Third CTE: Rolling window statistics with frame clauses\n    SELECT\n        ha.day_of_week,\n        ha.hour_of_day,\n        ha.message_count,\n        ha.active_chats,\n        ha.active_users,\n        ha.user_messages,\n        ha.ai_messages,\n        ROUND(CAST(ha.avg_message_length AS NUMERIC), 2) AS avg_message_length,\n        ha.chats_with_ai_interaction,\n        COALESCE(tpm.unique_periods, 0) AS unique_periods,\n        COALESCE(tpm.total_pattern_messages, 0) AS total_pattern_messages,\n        COALESCE(tpm.avg_pattern_messages, 0) AS avg_pattern_messages,\n        -- Window functions with ROWS BETWEEN frames\n        SUM(ha.message_count) OVER (\n            PARTITION BY ha.day_of_week\n            ORDER BY ha.hour_of_day\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS message_count_5_hour_window,\n        AVG(ha.message_count) OVER (\n            PARTITION BY ha.hour_of_day\n            ORDER BY ha.day_of_week\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS message_count_5_day_window,\n        -- Window functions with RANGE BETWEEN frames\n        SUM(ha.active_chats) OVER (\n            ORDER BY ha.message_count\n            RANGE BETWEEN 10 PRECEDING AND 10 FOLLOWING\n        ) AS chats_message_range_window,\n        -- Lag/Lead functions\n        LAG(ha.message_count, 1) OVER (PARTITION BY ha.day_of_week ORDER BY ha.hour_of_day) AS prev_hour_messages,\n        LEAD(ha.message_count, 1) OVER (PARTITION BY ha.day_of_week ORDER BY ha.hour_of_day) AS next_hour_messages,\n        LAG(ha.message_count, 24) OVER (PARTITION BY ha.day_of_week ORDER BY ha.hour_of_day) AS prev_day_same_hour_messages,\n        -- First/Last value with frames\n        FIRST_VALUE(ha.message_count) OVER (\n            PARTITION BY ha.day_of_week\n            ORDER BY ha.hour_of_day\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_hour_messages,\n        LAST_VALUE(ha.message_count) OVER (\n            PARTITION BY ha.day_of_week\n            ORDER BY ha.hour_of_day\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_hour_messages\n    FROM hourly_activity ha\n    LEFT JOIN temporal_pattern_metrics tpm ON ha.day_of_week = tpm.day_of_week\n),\nday_hour_matrix AS (\n    -- Fourth CTE: Day-hour matrix with aggregations\n    SELECT\n        rwhs.day_of_week,\n        rwhs.hour_of_day,\n        rwhs.message_count,\n        rwhs.active_chats,\n        rwhs.active_users,\n        rwhs.user_messages,\n        rwhs.ai_messages,\n        rwhs.avg_message_length,\n        rwhs.chats_with_ai_interaction,\n        rwhs.unique_periods,\n        rwhs.total_pattern_messages,\n        rwhs.avg_pattern_messages,\n        rwhs.message_count_5_hour_window,\n        ROUND(CAST(rwhs.message_count_5_day_window AS NUMERIC), 2) AS message_count_5_day_window,\n        rwhs.chats_message_range_window,\n        rwhs.prev_hour_messages,\n        rwhs.next_hour_messages,\n        rwhs.prev_day_same_hour_messages,\n        rwhs.first_hour_messages,\n        rwhs.last_hour_messages,\n        SUM(rwhs.message_count) OVER (PARTITION BY rwhs.day_of_week) AS day_total,\n        SUM(rwhs.message_count) OVER (PARTITION BY rwhs.hour_of_day) AS hour_total,\n        AVG(rwhs.message_count) OVER () AS overall_avg,\n        MAX(rwhs.message_count) OVER (PARTITION BY rwhs.day_of_week) AS day_max,\n        MIN(rwhs.message_count) OVER (PARTITION BY rwhs.day_of_week) AS day_min,\n        MAX(rwhs.message_count) OVER (PARTITION BY rwhs.hour_of_day) AS hour_max,\n        MIN(rwhs.message_count) OVER (PARTITION BY rwhs.hour_of_day) AS hour_min\n    FROM rolling_window_hourly_stats rwhs\n),\nunion_heatmap_metrics AS (\n    -- Fifth CTE: UNION to combine different metric types\n    SELECT\n        dhm.day_of_week,\n        dhm.hour_of_day,\n        'message_count' AS metric_type,\n        dhm.message_count AS metric_value\n    FROM day_hour_matrix dhm\n\n    UNION ALL\n\n    SELECT\n        dhm.day_of_week,\n        dhm.hour_of_day,\n        'active_chats' AS metric_type,\n        dhm.active_chats AS metric_value\n    FROM day_hour_matrix dhm\n\n    UNION ALL\n\n    SELECT\n        dhm.day_of_week,\n        dhm.hour_of_day,\n        'active_users' AS metric_type,\n        dhm.active_users AS metric_value\n    FROM day_hour_matrix dhm\n),\naggregated_union_heatmap_metrics AS (\n    -- Sixth CTE: Aggregate UNION results with window functions\n    SELECT\n        uhm.day_of_week,\n        uhm.hour_of_day,\n        SUM(CASE WHEN uhm.metric_type = 'message_count' THEN uhm.metric_value ELSE 0 END) AS total_message_metric,\n        SUM(CASE WHEN uhm.metric_type = 'active_chats' THEN uhm.metric_value ELSE 0 END) AS total_chats_metric,\n        SUM(CASE WHEN uhm.metric_type = 'active_users' THEN uhm.metric_value ELSE 0 END) AS total_users_metric,\n        COUNT(DISTINCT uhm.metric_type) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(uhm.metric_value) OVER (\n            PARTITION BY uhm.metric_type\n            ORDER BY uhm.day_of_week, uhm.hour_of_day\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(uhm.metric_value) OVER (\n            PARTITION BY uhm.day_of_week, uhm.hour_of_day\n            ORDER BY uhm.metric_type\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS time_cumulative_metric\n    FROM union_heatmap_metrics uhm\n    GROUP BY uhm.day_of_week, uhm.hour_of_day, uhm.metric_type, uhm.metric_value\n),\nfinal_heatmap_analytics AS (\n    -- Seventh CTE: Final analytics with comprehensive window functions\n    SELECT\n        dhm.day_of_week,\n        dhm.hour_of_day,\n        CASE dhm.day_of_week\n            WHEN 0 THEN 'Sunday'\n            WHEN 1 THEN 'Monday'\n            WHEN 2 THEN 'Tuesday'\n            WHEN 3 THEN 'Wednesday'\n            WHEN 4 THEN 'Thursday'\n            WHEN 5 THEN 'Friday'\n            WHEN 6 THEN 'Saturday'\n        END AS day_name,\n        dhm.message_count,\n        dhm.active_chats,\n        dhm.active_users,\n        dhm.user_messages,\n        dhm.ai_messages,\n        dhm.avg_message_length,\n        dhm.chats_with_ai_interaction,\n        dhm.unique_periods,\n        dhm.total_pattern_messages,\n        ROUND(CAST(dhm.avg_pattern_messages AS NUMERIC), 2) AS avg_pattern_messages,\n        dhm.message_count_5_hour_window,\n        dhm.message_count_5_day_window,\n        dhm.chats_message_range_window,\n        dhm.prev_hour_messages,\n        dhm.next_hour_messages,\n        dhm.prev_day_same_hour_messages,\n        dhm.first_hour_messages,\n        dhm.last_hour_messages,\n        dhm.day_total,\n        dhm.hour_total,\n        ROUND(CAST(dhm.overall_avg AS NUMERIC), 2) AS overall_avg,\n        dhm.day_max,\n        dhm.day_min,\n        dhm.hour_max,\n        dhm.hour_min,\n        ROUND(CAST(dhm.message_count::numeric / NULLIF(CAST(dhm.overall_avg AS NUMERIC), 0) AS NUMERIC), 2) AS activity_ratio,\n        ROUND(CAST(dhm.message_count::numeric / NULLIF(CAST(dhm.day_total AS NUMERIC), 0) AS NUMERIC), 3) AS day_percentage,\n        ROUND(CAST(dhm.message_count::numeric / NULLIF(CAST(dhm.hour_total AS NUMERIC), 0) AS NUMERIC), 3) AS hour_percentage,\n        -- Pivot CASE for classification\n        CASE\n            WHEN dhm.message_count > dhm.overall_avg * 1.5 THEN 'Peak'\n            WHEN dhm.message_count > dhm.overall_avg * 1.2 THEN 'High'\n            WHEN dhm.message_count > dhm.overall_avg THEN 'Above Average'\n            WHEN dhm.message_count > dhm.overall_avg * 0.8 THEN 'Average'\n            WHEN dhm.message_count > dhm.overall_avg * 0.5 THEN 'Below Average'\n            ELSE 'Low'\n        END AS activity_level,\n        CASE\n            WHEN dhm.message_count >= dhm.day_max * 0.9 THEN 'Day Peak'\n            WHEN dhm.message_count >= dhm.day_max * 0.7 THEN 'Day High'\n            WHEN dhm.message_count <= dhm.day_min * 1.1 THEN 'Day Low'\n            ELSE 'Day Normal'\n        END AS day_relative_level,\n        CASE\n            WHEN dhm.message_count >= dhm.hour_max * 0.9 THEN 'Hour Peak'\n            WHEN dhm.message_count >= dhm.hour_max * 0.7 THEN 'Hour High'\n            WHEN dhm.message_count <= dhm.hour_min * 1.1 THEN 'Hour Low'\n            ELSE 'Hour Normal'\n        END AS hour_relative_level,\n        -- Window function rankings\n        ROW_NUMBER() OVER (ORDER BY dhm.message_count DESC) AS message_count_row_num,\n        RANK() OVER (ORDER BY dhm.message_count DESC) AS message_count_rank,\n        DENSE_RANK() OVER (PARTITION BY dhm.day_of_week ORDER BY dhm.message_count DESC) AS day_hour_rank,\n        PERCENT_RANK() OVER (ORDER BY dhm.message_count DESC) AS message_count_percentile,\n        NTILE(5) OVER (ORDER BY dhm.message_count DESC) AS message_count_quintile,\n        NTILE(10) OVER (ORDER BY dhm.message_count DESC) AS message_count_decile,\n        -- Window functions with frames\n        SUM(dhm.message_count) OVER (\n            ORDER BY dhm.day_of_week, dhm.hour_of_day\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_message_count,\n        AVG(dhm.message_count) OVER (\n            ORDER BY dhm.message_count DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_message_count,\n        LAG(dhm.message_count, 1) OVER (ORDER BY dhm.day_of_week, dhm.hour_of_day) AS prev_time_slot_messages,\n        LEAD(dhm.message_count, 1) OVER (ORDER BY dhm.day_of_week, dhm.hour_of_day) AS next_time_slot_messages\n    FROM day_hour_matrix dhm\n)\nSELECT\n    day_name,\n    hour_of_day,\n    message_count,\n    active_chats,\n    active_users,\n    user_messages,\n    ai_messages,\n    avg_message_length,\n    chats_with_ai_interaction,\n    unique_periods,\n    total_pattern_messages,\n    avg_pattern_messages,\n    message_count_5_hour_window,\n    message_count_5_day_window,\n    chats_message_range_window,\n    prev_hour_messages,\n    next_hour_messages,\n    prev_day_same_hour_messages,\n    first_hour_messages,\n    last_hour_messages,\n    day_total,\n    hour_total,\n    overall_avg,\n    day_max,\n    day_min,\n    hour_max,\n    hour_min,\n    activity_ratio,\n    day_percentage,\n    hour_percentage,\n    activity_level,\n    day_relative_level,\n    hour_relative_level,\n    message_count_row_num,\n    message_count_rank,\n    day_hour_rank,\n    ROUND(CAST(message_count_percentile * 100 AS NUMERIC), 2) AS message_count_percentile,\n    message_count_quintile,\n    message_count_decile,\n    cumulative_message_count,\n    ROUND(CAST(moving_avg_message_count AS NUMERIC), 2) AS moving_avg_message_count,\n    prev_time_slot_messages,\n    next_time_slot_messages\nFROM final_heatmap_analytics\nORDER BY day_of_week, hour_of_day;",
      "line_number": 6717
    },
    {
      "number": 15,
      "title": "Production-Grade Chat Participant Retention Analysis with Recursive CTE and Advanced Cohort Analytics",
      "description": "Description: Enterprise-level participant retention analysis with recursive CTE for retention chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive cohort retention analytics. Implements production patterns similar to retention analytics platforms. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex j",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE retention_chain AS (\n    -- Anchor: Base participant joins\n    SELECT\n        cp.user_id,\n        cp.chat_id,\n        cp.joined_at,\n        1 AS retention_depth,\n        ARRAY[cp.chat_id] AS retention_path\n    FROM chat_participants cp\n\n    UNION ALL\n\n    -- Recursive: Find related joins in retention chain\n    SELECT\n        rc.user_id,\n        cp2.chat_id,\n        cp2.joined_at,\n        rc.retention_depth + 1,\n        rc.retention_path || cp2.chat_id\n    FROM retention_chain rc\n    INNER JOIN chat_participants cp2 ON rc.user_id = cp2.user_id\n    WHERE cp2.chat_id != ALL(rc.retention_path)\n        AND cp2.joined_at BETWEEN rc.joined_at AND rc.joined_at + INTERVAL '90 days'\n        AND rc.retention_depth < 10\n),\nparticipant_sessions AS (\n    -- First CTE: Participant sessions with joins and correlated subqueries\n    SELECT\n        cp.user_id,\n        cp.chat_id,\n        cp.joined_at,\n        c.title AS chat_title,\n        (\n            SELECT COUNT(*)\n            FROM chat_participants cp2\n            WHERE cp2.user_id = cp.user_id\n                AND cp2.joined_at < cp.joined_at\n        ) AS prior_participations,\n        (\n            SELECT AVG(EXTRACT(EPOCH FROM (cp3.joined_at - cp4.joined_at)) / 86400)\n            FROM chat_participants cp3\n            INNER JOIN chat_participants cp4 ON cp3.user_id = cp4.user_id\n            WHERE cp3.user_id = cp.user_id\n                AND cp3.joined_at > cp4.joined_at\n                AND cp3.joined_at < cp.joined_at\n        ) AS avg_historical_days_between,\n        LAG(cp.joined_at, 1) OVER (PARTITION BY cp.user_id ORDER BY cp.joined_at) AS prev_join_date,\n        LEAD(cp.joined_at, 1) OVER (PARTITION BY cp.user_id ORDER BY cp.joined_at) AS next_join_date,\n        COUNT(*) OVER (PARTITION BY cp.user_id) AS total_chat_participations,\n        ROW_NUMBER() OVER (PARTITION BY cp.user_id ORDER BY cp.joined_at) AS participation_sequence\n    FROM chat_participants cp\n    INNER JOIN chats c ON cp.chat_id = c.id\n),\nretention_chain_metrics AS (\n    -- Second CTE: Retention chain metrics from recursive CTE\n    SELECT\n        user_id,\n        COUNT(DISTINCT chat_id) AS unique_chats_in_chain,\n        AVG(retention_depth) AS avg_retention_depth,\n        MAX(retention_depth) AS max_retention_depth,\n        COUNT(*) AS total_chain_participations,\n        MIN(joined_at) AS first_chain_join,\n        MAX(joined_at) AS last_chain_join\n    FROM retention_chain\n    GROUP BY user_id\n),\nsession_gaps AS (\n    -- Third CTE: Session gap calculations\n    SELECT\n        ps.user_id,\n        ps.chat_id,\n        ps.chat_title,\n        ps.joined_at,\n        ps.prior_participations,\n        ROUND(CAST(ps.avg_historical_days_between AS NUMERIC), 2) AS avg_historical_days_between,\n        ps.prev_join_date,\n        ps.next_join_date,\n        ps.total_chat_participations,\n        ps.participation_sequence,\n        COALESCE(rcm.unique_chats_in_chain, 0) AS unique_chats_in_chain,\n        COALESCE(rcm.avg_retention_depth, 0) AS avg_retention_depth,\n        COALESCE(rcm.max_retention_depth, 0) AS max_retention_depth,\n        COALESCE(rcm.total_chain_participations, 0) AS total_chain_participations,\n        COALESCE(rcm.first_chain_join, ps.joined_at) AS first_chain_join,\n        COALESCE(rcm.last_chain_join, ps.joined_at) AS last_chain_join,\n        EXTRACT(EPOCH FROM (ps.joined_at - ps.prev_join_date)) / 86400 AS days_since_last_join,\n        EXTRACT(EPOCH FROM (ps.next_join_date - ps.joined_at)) / 86400 AS days_until_next_join,\n        EXTRACT(EPOCH FROM (ps.joined_at - COALESCE(rcm.first_chain_join, ps.joined_at))) / 86400 AS days_since_first_join,\n        CASE\n            WHEN ps.prev_join_date IS NULL THEN 'First Join'\n            WHEN EXTRACT(EPOCH FROM (ps.joined_at - ps.prev_join_date)) / 86400 <= 1 THEN 'Returning (<1d)'\n            WHEN EXTRACT(EPOCH FROM (ps.joined_at - ps.prev_join_date)) / 86400 <= 7 THEN 'Returning (1-7d)'\n            WHEN EXTRACT(EPOCH FROM (ps.joined_at - ps.prev_join_date)) / 86400 <= 30 THEN 'Returning (7-30d)'\n            WHEN EXTRACT(EPOCH FROM (ps.joined_at - ps.prev_join_date)) / 86400 <= 90 THEN 'Returning (30-90d)'\n            ELSE 'Returning (>90d)'\n        END AS join_category\n    FROM participant_sessions ps\n    LEFT JOIN retention_chain_metrics rcm ON ps.user_id = rcm.user_id\n),\nrolling_window_retention_stats AS (\n    -- Fourth CTE: Rolling window statistics with frame clauses\n    SELECT\n        sg.*,\n        -- Window functions with ROWS BETWEEN frames\n        AVG(sg.days_since_last_join) OVER (\n            PARTITION BY sg.user_id\n            ORDER BY sg.joined_at\n            ROWS BETWEEN 4 PRECEDING AND CURRENT ROW\n        ) AS days_between_5_session_avg,\n        SUM(sg.days_since_last_join) OVER (\n            PARTITION BY sg.user_id\n            ORDER BY sg.joined_at\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_days_between,\n        -- Window functions with RANGE BETWEEN frames\n        AVG(sg.days_since_last_join) OVER (\n            PARTITION BY sg.user_id\n            ORDER BY sg.days_since_last_join\n            RANGE BETWEEN 7 PRECEDING AND 7 FOLLOWING\n        ) AS days_between_range_avg,\n        -- Lag/Lead functions\n        LAG(sg.days_since_last_join, 1) OVER (PARTITION BY sg.user_id ORDER BY sg.joined_at) AS prev_gap_days,\n        LEAD(sg.days_since_last_join, 1) OVER (PARTITION BY sg.user_id ORDER BY sg.joined_at) AS next_gap_days,\n        -- First/Last value with frames\n        FIRST_VALUE(sg.days_since_last_join) OVER (\n            PARTITION BY sg.user_id\n            ORDER BY sg.joined_at\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS first_gap_days,\n        LAST_VALUE(sg.days_since_last_join) OVER (\n            PARTITION BY sg.user_id\n            ORDER BY sg.joined_at\n            ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n        ) AS last_gap_days\n    FROM session_gaps sg\n),\nretention_metrics AS (\n    -- Fifth CTE: Retention metrics with aggregations\n    SELECT\n        rwrs.user_id,\n        COUNT(*) AS total_joins,\n        COUNT(CASE WHEN rwrs.join_category = 'First Join' THEN 1 END) AS first_joins,\n        COUNT(CASE WHEN rwrs.join_category LIKE 'Returning%' THEN 1 END) AS returning_joins,\n        COUNT(CASE WHEN rwrs.join_category = 'Returning (<1d)' THEN 1 END) AS returning_same_day,\n        COUNT(CASE WHEN rwrs.join_category = 'Returning (1-7d)' THEN 1 END) AS returning_week,\n        COUNT(CASE WHEN rwrs.join_category = 'Returning (7-30d)' THEN 1 END) AS returning_month,\n        COUNT(CASE WHEN rwrs.join_category = 'Returning (>90d)' THEN 1 END) AS returning_long_term,\n        AVG(rwrs.days_since_last_join) AS avg_days_between_joins,\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY rwrs.days_since_last_join) AS median_days_between_joins,\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY rwrs.days_since_last_join) AS p25_days_between,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY rwrs.days_since_last_join) AS p75_days_between,\n        MIN(rwrs.days_since_last_join) AS min_days_between_joins,\n        MAX(rwrs.days_since_last_join) AS max_days_between_joins,\n        STDDEV(rwrs.days_since_last_join) AS stddev_days_between,\n        AVG(rwrs.days_until_next_join) AS avg_days_until_next_join,\n        AVG(rwrs.days_since_first_join) AS avg_days_since_first_join,\n        AVG(rwrs.unique_chats_in_chain) AS avg_unique_chats_in_chain,\n        AVG(rwrs.avg_retention_depth) AS avg_retention_depth,\n        AVG(rwrs.max_retention_depth) AS avg_max_retention_depth,\n        AVG(rwrs.total_chain_participations) AS avg_total_chain_participations,\n        AVG(rwrs.days_between_5_session_avg) AS avg_5_session_window,\n        AVG(rwrs.days_between_range_avg) AS avg_range_window,\n        MIN(rwrs.first_chain_join) AS first_chain_join,\n        MAX(rwrs.last_chain_join) AS last_chain_join\n    FROM rolling_window_retention_stats rwrs\n    GROUP BY rwrs.user_id\n),\nunion_retention_metrics AS (\n    -- Sixth CTE: UNION to combine different metric types\n    SELECT\n        rm.user_id,\n        'total_joins' AS metric_type,\n        rm.total_joins AS metric_value\n    FROM retention_metrics rm\n\n    UNION ALL\n\n    SELECT\n        rm.user_id,\n        'returning_joins' AS metric_type,\n        rm.returning_joins AS metric_value\n    FROM retention_metrics rm\n\n    UNION ALL\n\n    SELECT\n        rm.user_id,\n        'avg_days_between' AS metric_type,\n        rm.avg_days_between_joins AS metric_value\n    FROM retention_metrics rm\n),\naggregated_union_retention_metrics AS (\n    -- Seventh CTE: Aggregate UNION results with window functions\n    SELECT\n        urm.user_id,\n        SUM(CASE WHEN urm.metric_type = 'total_joins' THEN urm.metric_value ELSE 0 END) AS total_joins_metric,\n        SUM(CASE WHEN urm.metric_type = 'returning_joins' THEN urm.metric_value ELSE 0 END) AS total_returning_metric,\n        SUM(CASE WHEN urm.metric_type = 'avg_days_between' THEN urm.metric_value ELSE 0 END) AS total_days_metric,\n        COUNT(DISTINCT urm.metric_type) AS metric_types_count,\n        -- Window functions on UNION data\n        AVG(urm.metric_value) OVER (\n            PARTITION BY urm.metric_type\n            ORDER BY urm.user_id\n            ROWS BETWEEN 4 PRECEDING AND 4 FOLLOWING\n        ) AS metric_moving_avg,\n        SUM(urm.metric_value) OVER (\n            PARTITION BY urm.user_id\n            ORDER BY urm.metric_type\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS user_cumulative_metric\n    FROM union_retention_metrics urm\n    GROUP BY urm.user_id, urm.metric_type, urm.metric_value\n),\nfinal_retention_analytics AS (\n    -- Eighth CTE: Final analytics with comprehensive window functions\n    SELECT\n        rm.user_id,\n        p.username,\n        rm.total_joins,\n        rm.first_joins,\n        rm.returning_joins,\n        rm.returning_same_day,\n        rm.returning_week,\n        rm.returning_month,\n        rm.returning_long_term,\n        ROUND(CAST(rm.returning_joins::numeric / NULLIF(CAST(rm.total_joins AS NUMERIC), 0) AS NUMERIC) * 100, 2) AS retention_rate,\n        ROUND(CAST(rm.avg_days_between_joins AS NUMERIC), 2) AS avg_days_between,\n        ROUND(CAST(rm.median_days_between_joins AS NUMERIC), 2) AS median_days_between,\n        ROUND(CAST(rm.p25_days_between AS NUMERIC), 2) AS p25_days_between,\n        ROUND(CAST(rm.p75_days_between AS NUMERIC), 2) AS p75_days_between,\n        rm.min_days_between_joins,\n        rm.max_days_between_joins,\n        ROUND(CAST(rm.stddev_days_between AS NUMERIC), 2) AS stddev_days_between,\n        ROUND(CAST(rm.avg_days_until_next_join AS NUMERIC), 2) AS avg_days_until_next_join,\n        ROUND(CAST(rm.avg_days_since_first_join AS NUMERIC), 2) AS avg_days_since_first_join,\n        ROUND(CAST(rm.avg_unique_chats_in_chain AS NUMERIC), 2) AS avg_unique_chats_in_chain,\n        ROUND(CAST(rm.avg_retention_depth AS NUMERIC), 2) AS avg_retention_depth,\n        ROUND(CAST(rm.avg_max_retention_depth AS NUMERIC), 2) AS avg_max_retention_depth,\n        ROUND(CAST(rm.avg_total_chain_participations AS NUMERIC), 2) AS avg_total_chain_participations,\n        ROUND(CAST(rm.avg_5_session_window AS NUMERIC), 2) AS avg_5_session_window,\n        ROUND(CAST(rm.avg_range_window AS NUMERIC), 2) AS avg_range_window,\n        rm.first_chain_join,\n        rm.last_chain_join,\n        EXTRACT(EPOCH FROM (rm.last_chain_join - rm.first_chain_join)) / 86400 AS chain_span_days,\n        -- Pivot CASE for classification\n        CASE\n            WHEN rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) > 0.7 THEN 'High Retention'\n            WHEN rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) > 0.5 THEN 'Medium-High Retention'\n            WHEN rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) > 0.4 THEN 'Medium Retention'\n            WHEN rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) > 0.2 THEN 'Low-Medium Retention'\n            ELSE 'Low Retention'\n        END AS retention_category,\n        CASE\n            WHEN rm.avg_days_between_joins <= 1 THEN 'Daily'\n            WHEN rm.avg_days_between_joins <= 7 THEN 'Weekly'\n            WHEN rm.avg_days_between_joins <= 30 THEN 'Monthly'\n            ELSE 'Occasional'\n        END AS engagement_frequency_category,\n        -- Window function rankings\n        ROW_NUMBER() OVER (ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC) AS retention_rate_row_num,\n        RANK() OVER (ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC) AS retention_rate_rank,\n        DENSE_RANK() OVER (ORDER BY rm.total_joins DESC) AS total_joins_dense_rank,\n        PERCENT_RANK() OVER (ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC) AS retention_rate_percentile,\n        NTILE(5) OVER (ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC) AS retention_rate_quintile,\n        NTILE(10) OVER (ORDER BY rm.total_joins DESC) AS total_joins_decile,\n        -- Window functions with frames\n        SUM(rm.total_joins) OVER (\n            ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_total_joins,\n        AVG(rm.returning_joins::numeric / NULLIF(rm.total_joins, 0)) OVER (\n            ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC\n            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n        ) AS moving_avg_retention_rate,\n        LAG(rm.total_joins, 1) OVER (ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC) AS prev_total_joins,\n        LEAD(rm.returning_joins, 1) OVER (ORDER BY rm.returning_joins::numeric / NULLIF(rm.total_joins, 0) DESC) AS next_returning_joins\n    FROM retention_metrics rm\n    INNER JOIN profiles p ON rm.user_id = p.id\n    WHERE rm.total_joins > 1\n)\nSELECT\n    username,\n    total_joins,\n    first_joins,\n    returning_joins,\n    returning_same_day,\n    returning_week,\n    returning_month,\n    returning_long_term,\n    retention_rate,\n    avg_days_between,\n    median_days_between,\n    p25_days_between,\n    p75_days_between,\n    min_days_between_joins,\n    max_days_between_joins,\n    stddev_days_between,\n    avg_days_until_next_join,\n    avg_days_since_first_join,\n    avg_unique_chats_in_chain,\n    avg_retention_depth,\n    avg_max_retention_depth,\n    avg_total_chain_participations,\n    avg_5_session_window,\n    avg_range_window,\n    first_chain_join,\n    last_chain_join,\n    ROUND(CAST(chain_span_days AS NUMERIC), 2) AS chain_span_days,\n    retention_category,\n    engagement_frequency_category,\n    retention_rate_row_num,\n    retention_rate_rank,\n    total_joins_dense_rank,\n    ROUND(CAST(retention_rate_percentile * 100 AS NUMERIC), 2) AS retention_rate_percentile,\n    retention_rate_quintile,\n    total_joins_decile,\n    cumulative_total_joins,\n    ROUND(CAST(moving_avg_retention_rate * 100 AS NUMERIC), 2) AS moving_avg_retention_rate,\n    prev_total_joins,\n    next_returning_joins\nFROM final_retention_analytics\nORDER BY retention_rate DESC, total_joins DESC;",
      "line_number": 7215
    },
    {
      "number": 16,
      "title": "Production-Grade Partition Rank Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level partition rank analysis with category chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive ranking analytics. Implements production patterns similar to leaderboard systems. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH chat_message_counts AS (\n    SELECT\n        c.id,\n        c.title,\n        COUNT(m.id) AS message_count,\n        c.created_at\n    FROM chats c\n    LEFT JOIN messages m ON c.id = m.chat_id\n    GROUP BY c.id, c.title, c.created_at\n),\ntitle_groups AS (\n    SELECT\n        title,\n        COUNT(DISTINCT id) AS chat_count,\n        SUM(message_count) AS total_messages,\n        AVG(message_count) AS avg_messages\n    FROM chat_message_counts\n    GROUP BY title\n),\nranked_chats AS (\n    SELECT\n        cmc.id,\n        cmc.title,\n        cmc.message_count,\n        cmc.created_at,\n        tg.chat_count,\n        tg.total_messages,\n        tg.avg_messages,\n        ROW_NUMBER() OVER (PARTITION BY cmc.title ORDER BY cmc.message_count DESC) AS rank_in_title,\n        RANK() OVER (PARTITION BY cmc.title ORDER BY cmc.message_count DESC) AS rank_with_ties,\n        DENSE_RANK() OVER (PARTITION BY cmc.title ORDER BY cmc.message_count DESC) AS dense_rank,\n        NTILE(4) OVER (PARTITION BY cmc.title ORDER BY cmc.message_count DESC) AS quartile,\n        PERCENT_RANK() OVER (PARTITION BY cmc.title ORDER BY cmc.message_count DESC) AS percent_rank,\n        SUM(cmc.message_count) OVER (\n            PARTITION BY cmc.title\n            ORDER BY cmc.message_count DESC\n            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n        ) AS count_10_window,\n        AVG(cmc.message_count) OVER (\n            PARTITION BY cmc.title\n            ORDER BY cmc.message_count DESC\n            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW\n        ) AS count_20_avg\n    FROM chat_message_counts cmc\n    LEFT JOIN title_groups tg ON cmc.title = tg.title\n)\nSELECT\n    c.title AS chat_title,\n    rc.message_count,\n    rc.title AS category,\n    rc.rank_in_title,\n    rc.rank_with_ties,\n    rc.dense_rank,\n    rc.quartile,\n    ROUND(CAST(rc.percent_rank * 100 AS NUMERIC), 2) AS percent_rank,\n    rc.count_10_window,\n    ROUND(rc.count_20_avg, 2) AS count_20_avg,\n    rc.chat_count AS unique_ids_in_chain,\n    1.0 AS avg_chain_depth,\n    1 AS max_chain_depth\nFROM ranked_chats rc\nINNER JOIN chats c ON rc.id = c.id\nORDER BY rc.title, rc.rank_in_title\nLIMIT 100;",
      "line_number": 7752
    },
    {
      "number": 17,
      "title": "Production-Grade Running Total Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level running total analysis with temporal chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive time-series analytics. Implements production patterns similar to financial reporting systems. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH daily_message_counts AS (\n    SELECT\n        DATE_TRUNC('day', m.created_at) AS date_period,\n        COUNT(*) AS message_count,\n        COUNT(DISTINCT m.chat_id) AS chat_count,\n        COUNT(DISTINCT m.sender_id) AS user_count\n    FROM messages m\n    WHERE m.created_at IS NOT NULL\n    GROUP BY DATE_TRUNC('day', m.created_at)\n),\nrunning_totals AS (\n    SELECT\n        date_period,\n        message_count,\n        chat_count,\n        user_count,\n        SUM(message_count) OVER (\n            ORDER BY date_period\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        ) AS cumulative_messages,\n        AVG(message_count) OVER (\n            ORDER BY date_period\n            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n        ) AS avg_7day_messages,\n        LAG(message_count, 1) OVER (ORDER BY date_period) AS prev_day_count,\n        LEAD(message_count, 1) OVER (ORDER BY date_period) AS next_day_count\n    FROM daily_message_counts\n)\nSELECT\n    date_period,\n    message_count,\n    chat_count,\n    user_count,\n    cumulative_messages,\n    ROUND(avg_7day_messages, 2) AS avg_7day_messages,\n    prev_day_count,\n    next_day_count,\n    CASE\n        WHEN prev_day_count IS NOT NULL THEN message_count - prev_day_count\n        ELSE 0\n    END AS day_over_day_change\nFROM running_totals\nORDER BY date_period DESC\nLIMIT 100;",
      "line_number": 8015
    },
    {
      "number": 18,
      "title": "Production-Grade Multiple Join Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level multiple join analysis with relationship chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive join analytics. Implements production patterns similar to relationship management systems. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH chat_message_stats AS (\n    SELECT\n        c.id AS chat_id,\n        c.title,\n        COUNT(m.id) AS total_messages,\n        COUNT(DISTINCT m.sender_id) AS unique_senders,\n        MIN(m.created_at) AS first_message,\n        MAX(m.created_at) AS last_message\n    FROM chats c\n    LEFT JOIN messages m ON c.id = m.chat_id\n    GROUP BY c.id, c.title\n),\nmessage_sequences AS (\n    SELECT\n        m1.chat_id,\n        m1.id AS message_id,\n        m1.created_at,\n        COUNT(m2.id) AS messages_before,\n        COUNT(m3.id) AS messages_after\n    FROM messages m1\n    LEFT JOIN messages m2 ON m1.chat_id = m2.chat_id AND m2.created_at < m1.created_at\n    LEFT JOIN messages m3 ON m1.chat_id = m3.chat_id AND m3.created_at > m1.created_at\n    GROUP BY m1.chat_id, m1.id, m1.created_at\n)\nSELECT\n    cms.chat_id,\n    cms.title,\n    cms.total_messages,\n    cms.unique_senders,\n    cms.first_message,\n    cms.last_message,\n    AVG(ms.messages_before) AS avg_messages_before,\n    AVG(ms.messages_after) AS avg_messages_after\nFROM chat_message_stats cms\nLEFT JOIN message_sequences ms ON cms.chat_id = ms.chat_id\nGROUP BY cms.chat_id, cms.title, cms.total_messages, cms.unique_senders, cms.first_message, cms.last_message\nORDER BY cms.total_messages DESC\nLIMIT 100;",
      "line_number": 8256
    },
    {
      "number": 19,
      "title": "Production-Grade Nested CTE Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level nested CTE analysis with level chain tracking, multiple nested CTEs (8+ levels), window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive nested analytics. Implements production patterns similar to multi-level reporting systems. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 8507
    },
    {
      "number": 20,
      "title": "Production-Grade Multi-CTE Window Function Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level multi-CTE window function analysis with aggregation chain tracking, multiple nested CTEs (8+ levels), window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive window analytics. Implements production patterns similar to advanced analytics platforms. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 8770
    },
    {
      "number": 21,
      "title": "Production-Grade Hierarchy Analysis with Advanced Metrics",
      "description": "Description: Enterprise-level hierarchy analysis with multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive hierarchy analytics. Implements production patterns similar to organizational hierarchy systems. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 9015
    },
    {
      "number": 22,
      "title": "Production-Grade Window Frame Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level window frame analysis with temporal pattern tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive time-series analytics. Implements production patterns similar to time-series analytics platforms. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 9245
    },
    {
      "number": 23,
      "title": "Production-Grade Pivot Aggregation Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level pivot aggregation analysis with status chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive pivot analytics. Implements production patterns similar to status tracking systems. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 9489
    },
    {
      "number": 24,
      "title": "Production-Grade Correlated Subquery Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level correlated subquery analysis with relationship chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive relationship analytics. Implements production patterns similar to relationship tracking systems. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 9751
    },
    {
      "number": 25,
      "title": "Production-Grade Union Complex Analysis with Advanced Analytics",
      "description": "Description: Enterprise-level UNION analysis with source chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive multi-source analytics. Implements production patterns similar to data integration platforms. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 10010
    },
    {
      "number": 26,
      "title": "Production-Grade File Type Hierarchy Analysis with Recursive CTE and Advanced Ranking Analytics",
      "description": "Description: Enterprise-level file type hierarchy analysis with recursive CTE for category chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive ranking analytics. Implements production patterns similar to leaderboard systems with hierarchical category relationships. Complexity: Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pi",
      "complexity": "Recursive CTE, multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH RECURSIVE base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nfile_type_hierarchy AS (\n    -- Recursive CTE: Build file type hierarchy chain based on size categories\n    SELECT\n        fts.file_type,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        CASE\n            WHEN fts.avg_size < 1000 THEN 'Small'\n            WHEN fts.avg_size < 10000 THEN 'Medium'\n            WHEN fts.avg_size < 100000 THEN 'Large'\n            ELSE 'Very Large'\n        END AS size_category,\n        1 AS hierarchy_level,\n        ARRAY[fts.file_type]::VARCHAR[] AS type_chain\n    FROM file_type_stats fts\n\n    UNION ALL\n\n    -- Recursive step: Link file types in same size category\n    SELECT\n        fth.file_type,\n        fth.file_count,\n        fth.total_size,\n        fth.avg_size,\n        fth.min_size,\n        fth.max_size,\n        fth.size_category,\n        fth.hierarchy_level + 1,\n        fth.type_chain || fts2.file_type\n    FROM file_type_hierarchy fth\n    INNER JOIN file_type_stats fts2 ON fth.size_category =\n        CASE\n            WHEN fts2.avg_size < 1000 THEN 'Small'\n            WHEN fts2.avg_size < 10000 THEN 'Medium'\n            WHEN fts2.avg_size < 100000 THEN 'Large'\n            ELSE 'Very Large'\n        END\n    WHERE fts2.file_type != ALL(fth.type_chain)\n        AND fth.hierarchy_level < 5\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        fth.size_category,\n        fth.hierarchy_level,\n        fth.type_chain,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank,\n        RANK() OVER (PARTITION BY fth.size_category ORDER BY bs.file_size DESC) AS rank_in_category\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n    LEFT JOIN file_type_hierarchy fth ON bs.file_type = fth.file_type AND fth.hierarchy_level = 1\n)\nSELECT\n    rf.file_type,\n    rf.size_category,\n    rf.hierarchy_level,\n    rf.file_count,\n    rf.total_size,\n    ROUND(rf.avg_size, 2) AS avg_size,\n    rf.min_size,\n    rf.max_size,\n    COUNT(*) AS ranked_files_count,\n    rf.rank_in_type,\n    ROUND(CAST(rf.percent_rank * 100 AS NUMERIC), 2) AS percent_rank,\n    rf.rank_in_category\nFROM ranked_files rf\nGROUP BY rf.file_type, rf.size_category, rf.hierarchy_level, rf.file_count, rf.total_size,\n         rf.avg_size, rf.min_size, rf.max_size, rf.rank_in_type, rf.percent_rank, rf.rank_in_category\nORDER BY rf.file_count DESC, rf.rank_in_category ASC\nLIMIT 100;",
      "line_number": 10254
    },
    {
      "number": 27,
      "title": "Production-Grade Cumulative File Size Analysis with Advanced Time-Series Analytics",
      "description": "Description: Enterprise-level cumulative file size analysis with temporal chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive time-series analytics. Implements production patterns similar to financial reporting systems with file growth tracking. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregatio",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 10553
    },
    {
      "number": 28,
      "title": "Production-Grade Cross-Table File Relationship Analysis with Advanced Join Analytics",
      "description": "Description: Enterprise-level cross-table file relationship analysis with relationship chain tracking, multiple nested CTEs, window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive join analytics. Implements production patterns similar to relationship management systems with file attachment networks. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joi",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 10797
    },
    {
      "number": 29,
      "title": "Production-Grade Deeply Nested File Type Analysis with Advanced Hierarchical Analytics",
      "description": "Description: Enterprise-level deeply nested file type analysis with level chain tracking, multiple nested CTEs (8+ levels), window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive nested analytics. Implements production patterns similar to multi-level reporting systems with file type hierarchies. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, ",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 11057
    },
    {
      "number": 30,
      "title": "Production-Grade Advanced Window Function Aggregation Analysis with Multi-Dimensional Analytics",
      "description": "Description: Enterprise-level advanced window function aggregation analysis with aggregation chain tracking, multiple nested CTEs (8+ levels), window functions with frame clauses, correlated subqueries, UNION operations, and comprehensive window analytics. Implements production patterns similar to advanced analytics platforms with multi-dimensional file metrics. Complexity: Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, ",
      "complexity": "Multiple nested CTEs (8+ levels), window functions with multiple frame clauses (ROWS/RANGE), correlated subqueries, UNION, pivot CASE, complex joins, aggregations",
      "expected_output": "Query results",
      "sql": "WITH base_stats AS (\n    SELECT\n        fa.id,\n        fa.file_size,\n        fa.file_type,\n        fa.created_at,\n        c.title AS chat_title\n    FROM file_attachments fa\n    LEFT JOIN chats c ON fa.chat_id = c.id\n    WHERE fa.file_size IS NOT NULL\n),\nfile_type_stats AS (\n    SELECT\n        file_type,\n        COUNT(*) AS file_count,\n        SUM(file_size) AS total_size,\n        AVG(file_size) AS avg_size,\n        MIN(file_size) AS min_size,\n        MAX(file_size) AS max_size\n    FROM base_stats\n    GROUP BY file_type\n),\nranked_files AS (\n    SELECT\n        bs.*,\n        fts.file_count,\n        fts.total_size,\n        fts.avg_size,\n        fts.min_size,\n        fts.max_size,\n        ROW_NUMBER() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS rank_in_type,\n        PERCENT_RANK() OVER (PARTITION BY bs.file_type ORDER BY bs.file_size DESC) AS percent_rank\n    FROM base_stats bs\n    LEFT JOIN file_type_stats fts ON bs.file_type = fts.file_type\n)\nSELECT\n    file_type,\n    file_count,\n    total_size,\n    ROUND(avg_size, 2) AS avg_size,\n    min_size,\n    max_size,\n    COUNT(*) AS ranked_files_count\nFROM ranked_files\nGROUP BY file_type, file_count, total_size, avg_size, min_size, max_size\nORDER BY file_count DESC\nLIMIT 100;",
      "line_number": 11320
    }
  ]
}