{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL/ELT Pipeline - DB-7 Maritime Shipping Intelligence\n",
    "\n",
    "This notebook provides a comprehensive ETL/ELT pipeline for maritime shipping intelligence database db-7.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Extract**: Load data from government sources (NOAA, USCG, MARAD, Data.gov)\n",
    "2. **Transform**: Clean, validate, and transform maritime data\n",
    "3. **Load**: Load transformed data into target database\n",
    "4. **Validate**: Verify data quality and completeness\n",
    "5. **Monitor**: Track pipeline performance and errors\n",
    "\n",
    "## Government Data Sources\n",
    "\n",
    "### NOAA (National Oceanic and Atmospheric Administration)\n",
    "- **AccessAIS Tool**: Interactive vessel traffic data download\n",
    "- **MarineCadastre.gov**: AIS vessel traffic data (2009-2024)\n",
    "- **Vessel Traffic Data**: CSV, GeoPackages, GeoTIFFs formats\n",
    "- **Base URL**: https://coast.noaa.gov/digitalcoast/data/vesseltraffic.html\n",
    "- **AccessAIS Tool**: https://coast.noaa.gov/digitalcoast/tools/ais.html\n",
    "\n",
    "### US Coast Guard (USCG)\n",
    "- **National Vessel Movement Center (NVMC)**: Notice of Arrival and Departure (NOAD) data\n",
    "- **Vessel Information Verification Service (VIVS)**: AIS static data (MMSI, call sign, vessel info)\n",
    "- **AIS Data Sharing**: Level A (real-time), Level B (filtered), Level C (historical)\n",
    "- **NVMC Base URL**: https://www.nvmc.uscg.gov/\n",
    "- **VIVS Base URL**: https://navcen.uscg.gov/ais-vivs-home\n",
    "\n",
    "### MARAD (Maritime Administration)\n",
    "- **U.S.-Flag Fleet Data**: Current fleet lists, vessel characteristics, capacities\n",
    "- **Port Statistics**: Cargo volumes, vessel calls, berth productivity\n",
    "- **Waterborne Commerce Statistics**: Port performance metrics\n",
    "- **Base URL**: https://www.maritime.dot.gov/data-reports\n",
    "- **Port Data**: https://www.maritime.dot.gov/data-reports/ports\n",
    "- **Contact**: data.marad@dot.gov\n",
    "\n",
    "### Data.gov\n",
    "- **Virginia International Gateway Vessel Schedules**: Port of Virginia vessel schedules\n",
    "- **Port Region Grain Ocean Vessel Activity**: USDA weekly vessel activity data\n",
    "- **AIS Vessel Tracks**: Commerce Data Hub AIS datasets\n",
    "- **Base URL**: https://catalog.data.gov\n",
    "- **Virginia Data**: https://data.virginia.gov/dataset/virginia-international-gateway-vig-vessel-schedules-the-port-of-virginia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "import requests\n",
    "from urllib.parse import urljoin, urlencode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connections\n",
    "try:\n",
    "    from sqlalchemy import create_engine, text\n",
    "    SQLALCHEMY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SQLALCHEMY_AVAILABLE = False\n",
    "    print(\"Warning: sqlalchemy not available\")\n",
    "\n",
    "# Geospatial libraries\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    GEOSPATIAL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GEOSPATIAL_AVAILABLE = False\n",
    "    print(\"Warning: geopandas/shapely not available\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DB_NAME = \"db-7\"\n",
    "DB_PATH = Path.cwd().parent\n",
    "\n",
    "# Database connection strings (configure as needed)\n",
    "# PostgreSQL\n",
    "POSTGRES_CONNECTION_STRING = None  # \"postgresql://user:password@localhost:5432/dbname\"\n",
    "\n",
    "# Databricks\n",
    "DATABRICKS_CONNECTION_STRING = None  # Configure Databricks connection\n",
    "\n",
    "# Databricks\n",
    "SNOWFLAKE_CONNECTION_STRING = None  # Configure Databricks connection\n",
    "\n",
    "# Source data paths\n",
    "DATA_DIR = DB_PATH / \"data\"\n",
    "SCHEMA_FILE = DATA_DIR / \"schema.sql\"\n",
    "DATA_FILE = DATA_DIR / \"data.sql\"\n",
    "\n",
    "# Government API endpoints\n",
    "NOAA_ACCESS_AIS_URL = \"https://coast.noaa.gov/digitalcoast/tools/ais.html\"\n",
    "MARINE_CADASTRE_AIS_URL = \"https://marinecadastre.gov/AIS/\"\n",
    "USCG_NVMC_URL = \"https://www.nvmc.uscg.gov/\"\n",
    "USCG_VIVS_URL = \"https://navcen.uscg.gov/ais-vivs-home\"\n",
    "MARAD_DATA_URL = \"https://www.maritime.dot.gov/data-reports\"\n",
    "DATA_GOV_CATALOG_URL = \"https://catalog.data.gov/api/3/action\"\n",
    "VIRGINIA_PORT_SCHEDULES_URL = \"https://data.virginia.gov/dataset/virginia-international-gateway-vig-vessel-schedules-the-port-of-virginia\"\n",
    "\n",
    "print(f\"Database: {DB_NAME}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Schema file exists: {SCHEMA_FILE.exists()}\")\n",
    "print(f\"Data file exists: {DATA_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Extract - Government Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_data_gov_datasets(query: str, limit: int = 10) -> Optional[List[Dict]]:\n",
    "    \"\"\"Search Data.gov catalog for maritime datasets.\"\"\"\n",
    "    try:\n",
    "        url = f\"{DATA_GOV_CATALOG_URL}/package_search\"\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'rows': limit\n",
    "        }\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if 'result' in data and 'results' in data['result']:\n",
    "            return data['result']['results']\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error searching Data.gov: {e}\")\n",
    "        return None\n",
    "\n",
    "# Search for maritime datasets\n",
    "maritime_datasets = search_data_gov_datasets(\"maritime shipping vessel port\", limit=20)\n",
    "if maritime_datasets:\n",
    "    print(f\"✓ Found {len(maritime_datasets)} maritime datasets on Data.gov\")\n",
    "    for dataset in maritime_datasets[:5]:\n",
    "        print(f\"  - {dataset.get('title', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noaa_ais_data(year: int, region: str = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extract NOAA AIS vessel traffic data.\n",
    "    Note: This is a placeholder - actual implementation requires\n",
    "    downloading from MarineCadastre.gov or using AccessAIS tool.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Extracting NOAA AIS data for year {year}\")\n",
    "    # Implementation would download from MarineCadastre.gov\n",
    "    # Data available in CSV, GeoPackage, GeoTIFF formats\n",
    "    # URL: https://marinecadastre.gov/AIS/\n",
    "    return None\n",
    "\n",
    "def extract_uscg_noad_data(start_date: datetime, end_date: datetime) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extract USCG Notice of Arrival and Departure (NOAD) data.\n",
    "    Note: Requires NVMC access and proper authentication.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Extracting USCG NOAD data from {start_date} to {end_date}\")\n",
    "    # Implementation would connect to NVMC system\n",
    "    # URL: https://www.nvmc.uscg.gov/\n",
    "    return None\n",
    "\n",
    "def extract_marad_fleet_data() -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extract MARAD U.S.-Flag Fleet data.\n",
    "    Note: Data available from maritime.dot.gov/data-reports\n",
    "    \"\"\"\n",
    "    logger.info(\"Extracting MARAD fleet data\")\n",
    "    # Implementation would download from MARAD website\n",
    "    # URL: https://www.maritime.dot.gov/data-reports/us-flag-fleet-dashboard\n",
    "    return None\n",
    "\n",
    "def extract_port_schedules_virginia() -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extract Virginia International Gateway vessel schedules.\n",
    "    \"\"\"\n",
    "    logger.info(\"Extracting Virginia port vessel schedules\")\n",
    "    # Implementation would download from data.virginia.gov\n",
    "    # URL: https://data.virginia.gov/dataset/virginia-international-gateway-vig-vessel-schedules-the-port-of-virginia\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Transform - Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ais_tracking_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Transform AIS tracking data to match vessel_tracking table schema.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Map columns to schema\n",
    "    transformed = pd.DataFrame()\n",
    "    \n",
    "    # Generate tracking_id\n",
    "    transformed['tracking_id'] = df.apply(\n",
    "        lambda row: f\"TRK_{row.get('mmsi', 'UNK')}_{row.get('timestamp', datetime.now()).strftime('%Y%m%d%H%M%S')}\",\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Map other fields\n",
    "    column_mapping = {\n",
    "        'mmsi': 'mmsi',\n",
    "        'timestamp': 'timestamp',\n",
    "        'latitude': 'latitude',\n",
    "        'longitude': 'longitude',\n",
    "        'speed': 'speed_knots',\n",
    "        'course': 'course_degrees',\n",
    "        'heading': 'heading_degrees',\n",
    "        'nav_status': 'navigation_status',\n",
    "        'destination': 'destination',\n",
    "        'eta': 'eta',\n",
    "        'draught': 'draught_meters'\n",
    "    }\n",
    "    \n",
    "    for source_col, target_col in column_mapping.items():\n",
    "        if source_col in df.columns:\n",
    "            transformed[target_col] = df[source_col]\n",
    "    \n",
    "    # Set defaults\n",
    "    transformed['data_source'] = 'AIS'\n",
    "    transformed['data_quality'] = 'High'\n",
    "    transformed['created_at'] = datetime.now()\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "def transform_port_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Transform port data to match ports table schema.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    transformed = pd.DataFrame()\n",
    "    \n",
    "    # Generate port_id\n",
    "    transformed['port_id'] = df.apply(\n",
    "        lambda row: f\"PORT_{row.get('locode', row.get('port_code', 'UNK'))}\",\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Map fields\n",
    "    column_mapping = {\n",
    "        'port_name': 'port_name',\n",
    "        'port_code': 'port_code',\n",
    "        'locode': 'locode',\n",
    "        'country': 'country',\n",
    "        'country_code': 'country_code',\n",
    "        'latitude': 'latitude',\n",
    "        'longitude': 'longitude',\n",
    "        'port_type': 'port_type',\n",
    "        'timezone': 'timezone'\n",
    "    }\n",
    "    \n",
    "    for source_col, target_col in column_mapping.items():\n",
    "        if source_col in df.columns:\n",
    "            transformed[target_col] = df[source_col]\n",
    "    \n",
    "    transformed['status'] = 'Active'\n",
    "    transformed['data_source'] = 'MARAD'\n",
    "    transformed['created_at'] = datetime.now()\n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Load - Database Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_database(df: pd.DataFrame, table_name: str, connection_string: str) -> bool:\n",
    "    \"\"\"Load DataFrame to database table.\"\"\"\n",
    "    if not SQLALCHEMY_AVAILABLE:\n",
    "        logger.error(\"SQLAlchemy not available\")\n",
    "        return False\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        logger.warning(f\"No data to load to {table_name}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        engine = create_engine(connection_string)\n",
    "        df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "        logger.info(f\"Loaded {len(df)} rows to {table_name}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading to {table_name}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Validate - Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data_quality(df: pd.DataFrame, table_name: str) -> Dict:\n",
    "    \"\"\"Perform data quality validation checks.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return {\"status\": \"empty\", \"issues\": []}\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    # Check for nulls in required fields\n",
    "    required_fields = {\n",
    "        'vessels': ['vessel_name', 'imo_number'],\n",
    "        'ports': ['port_name', 'latitude', 'longitude'],\n",
    "        'vessel_tracking': ['vessel_id', 'timestamp', 'latitude', 'longitude']\n",
    "    }\n",
    "    \n",
    "    if table_name in required_fields:\n",
    "        for field in required_fields[table_name]:\n",
    "            null_count = df[field].isna().sum() if field in df.columns else len(df)\n",
    "            if null_count > 0:\n",
    "                issues.append(f\"{null_count} null values in {field}\")\n",
    "    \n",
    "    # Check data ranges\n",
    "    if 'latitude' in df.columns:\n",
    "        invalid_lat = ((df['latitude'] < -90) | (df['latitude'] > 90)).sum()\n",
    "        if invalid_lat > 0:\n",
    "            issues.append(f\"{invalid_lat} invalid latitude values\")\n",
    "    \n",
    "    if 'longitude' in df.columns:\n",
    "        invalid_lon = ((df['longitude'] < -180) | (df['longitude'] > 180)).sum()\n",
    "        if invalid_lon > 0:\n",
    "            issues.append(f\"{invalid_lon} invalid longitude values\")\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"valid\" if len(issues) == 0 else \"issues_found\",\n",
    "        \"row_count\": len(df),\n",
    "        \"issues\": issues\n",
    "    }\n",
    "\n",
    "print(\"✓ Validation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Monitor - Pipeline Execution Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline execution metadata\n",
    "pipeline_metadata = {\n",
    "    \"pipeline_name\": \"db-7-maritime-intelligence\",\n",
    "    \"execution_date\": datetime.now().isoformat(),\n",
    "    \"data_sources\": [\n",
    "        \"NOAA AccessAIS\",\n",
    "        \"USCG NVMC\",\n",
    "        \"MARAD Fleet Data\",\n",
    "        \"Data.gov Maritime Datasets\"\n",
    "    ],\n",
    "    \"tables_loaded\": [],\n",
    "    \"records_processed\": 0,\n",
    "    \"errors\": []\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "metadata_file = DB_PATH / \"metadata\" / \"pipeline_metadata.json\"\n",
    "metadata_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(pipeline_metadata, f, indent=2)\n",
    "\n",
    "print(f\"✓ Pipeline metadata saved to {metadata_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
