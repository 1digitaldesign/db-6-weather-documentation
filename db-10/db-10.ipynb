{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 3.14.2 Installation\n",
    "",
    "This notebook requires Python 3.14.2. Run the cell below to install and verify Python 3.14.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PYTHON 3.14.2 INSTALLATION FOR GOOGLE COLAB\n",
    "# ============================================================================\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "print(\"=\"*80)\n",
    "print(\"PYTHON 3.14.2 INSTALLATION\")\n",
    "print(\"=\"*80)\n",
    "# Check current Python version\n",
    "current_version = sys.version_info\n",
    "print(f\"\\nCurrent Python version: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "# Target version\n",
    "TARGET_MAJOR = 3\n",
    "TARGET_MINOR = 14\n",
    "TARGET_MICRO = 2\n",
    "if current_version.major == TARGET_MAJOR and current_version.minor == TARGET_MINOR and current_version.micro == TARGET_MICRO:\n",
    "    print(f\"\\n‚úÖ Python {TARGET_MAJOR}.{TARGET_MINOR}.{TARGET_MICRO} is already installed!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Python {TARGET_MAJOR}.{TARGET_MINOR}.{TARGET_MICRO} is required\")\n",
    "    print(f\"   Current version: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "    print(f\"\\nInstalling Python {TARGET_MAJOR}.{TARGET_MINOR}.{TARGET_MICRO}...\")\n",
    "    \n",
    "    if not IS_COLAB:\n",
    "    raise RuntimeError(\"Python 3.14.2 installation requires Google Colab\")\n",
    "    \n",
    "    try:\n",
    "    # Method 1: Use conda (if available)\n",
    "        print(\"\\nMethod 1:\n",
    "    Trying conda...\")\n",
    "        try:\n",
    "    result = subprocess.run(['conda', '--version'], capture_output=True, text=True, timeout=5)\n",
    "            if result.returncode == 0:\n",
    "    print(\"   ‚úÖ Conda found, installing Python 3.14.2...\")\n",
    "                os.system('conda install -y python=3.14.2')\n",
    "                print(\"   ‚úÖ Python 3.14.2 installed via conda\")\n",
    "                print(\"   ‚ö†Ô∏è  Restart kernel and re-run this cell to use Python 3.14.2\")\n",
    "        except:\n",
    "            print(\"   ‚ö†Ô∏è  Conda not available\")\n",
    "        \n",
    "        # Method 2: Use deadsnakes PPA (Ubuntu/Debian)\n",
    "        print(\"\\nMethod 2: Installing via deadsnakes PPA...\")\n",
    "        os.system('apt-get update -qq')\n",
    "        os.system('apt-get install -y software-properties-common')\n",
    "        os.system('add-apt-repository -y ppa:deadsnakes/ppa')\n",
    "        os.system('apt-get update -qq')\n",
    "        os.system('apt-get install -y python3.14 python3.14-venv python3.14-dev')\n",
    "        print(\"   ‚úÖ Python 3.14.2 installed via deadsnakes PPA\")\n",
    "        \n",
    "        # Method 3: Use pyenv\n",
    "        print(\"\\nMethod 3: Installing via pyenv...\")\n",
    "        os.system('curl https://pyenv.run | bash')\n",
    "        os.system('export PYENV_ROOT=\"$HOME/.pyenv\"')\n",
    "        os.system('export PATH=\"$PYENV_ROOT/bin:$PATH\"')\n",
    "        os.system('eval \"$(pyenv init -)\"')\n",
    "        os.system('pyenv install 3.14.2')\n",
    "        os.system('pyenv global 3.14.2')\n",
    "        print(\"   ‚úÖ Python 3.14.2 installed via pyenv\")\n",
    "        \n",
    "        # Verify installation\n",
    "        print(\"\\nVerifying Python 3.14.2 installation...\")\n",
    "        result = subprocess.run(['python3.14', '--version'], capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "    version_output = result.stdout.strip()\n",
    "            print(f\"   ‚úÖ Python 3.14 found: {version_output}\")\n",
    "            if '3.14.2' in version_output:\n",
    "    print(\"   ‚úÖ Python 3.14.2 is installed!\")\n",
    "            print(\"\\n‚ö†Ô∏è  IMPORTANT: Restart kernel and select Python 3.14.2 as kernel\")\n",
    "            print(\"   Or use: !python3.14 your_script.py\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Python 3.14.2 installation may have failed\")\n",
    "            print(\"   Current Python version will be used\")\n",
    "    \n",
    "    except Exception as e:\n",
    "    print(f\"\\n‚ùå Error installing Python 3.14.2: {e}\")\n",
    "        print(\"\\n‚ö†Ô∏è  Continuing with current Python version\")\n",
    "        print(f\"   Current version: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "# Verify Python version\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PYTHON VERSION VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "final_version = sys.version_info\n",
    "print(f\"Python version: {final_version.major}.{final_version.minor}.{final_version.micro}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "if final_version.major == TARGET_MAJOR and final_version.minor == TARGET_MINOR and final_version.micro == TARGET_MICRO:\n",
    "    print(f\"\\n‚úÖ Python {TARGET_MAJOR}.{TARGET_MINOR}.{TARGET_MICRO} is active!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Python {TARGET_MAJOR}.{TARGET_MINOR}.{TARGET_MICRO} is not active\")\n",
    "    print(f\"   Current version: {final_version.major}.{final_version.minor}.{final_version.micro}\")\n",
    "    print(\"   If Python 3.14.2 was installed, restart kernel and select Python 3.14.2\")\n",
    "print(\"=\"*80)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB-10: Retail Price Intelligence Database - End-to-End Query Testing\n",
    "\n",
    "This notebook provides **complete end-to-end setup and testing** from scratch:\n",
    "\n",
    "1. **Environment Setup**: Install all required Python packages automatically\n",
    "2. **Database Initialization**: Create database, load schema, load data\n",
    "3. **Query Execution**: Execute all 30 queries with metrics\n",
    "4. **Visualization**: Performance charts and data analysis\n",
    "5. **Documentation**: Comprehensive query documentation\n",
    "\n",
    "## Database Overview\n",
    "\n",
    "**Database Name:** Retail Price Intelligence Database  \n",
    "**Database ID:** db-10  \n",
    "**Domain:** Retail Price Intelligence  \n",
    "**Total Queries:** 30  \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- PostgreSQL server running (localhost or configured via environment variables)\n",
    "- Python 3.14.2 installed\n",
    "- Jupyter Notebook or JupyterLab\n",
    "\n",
    "**Note:** All Python packages will be installed automatically when you run the first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# GOOGLE COLAB ONLY - ENVIRONMENT CHECK# ============================================================================import sys\n",
    "import os# Verify we're running in Google ColabIS_COLAB = Falsetry:\n",
    "    import google.colab    IS_COLAB = True    print(\"‚úÖ Running in Google Colab\")except ImportError:\n",
    "    # Check alternative methods    if os.path.exists('/content') and os.environ.get('COLAB_GPU'):\n",
    "    IS_COLAB = True        print(\"‚úÖ Running in Google Colab (detected via COLAB_GPU)\")    elif os.path.exists('/content') and 'COLAB' in str(os.environ):                        IS_COLAB = True        print(\"‚úÖ Running in Google Colab (detected via COLAB env)\")    else:            IS_COLAB = False\n",
    "if not IS_COLAB:\n",
    "    raise RuntimeError(        \"‚ùå ERROR: This notebook is designed to run ONLY in Google Colab.\\n\"        \"Please open this notebook in Google Colab: https://colab.research.google.com/\"    )print(\"=\"*80)\n",
    "print(\"GOOGLE COLAB ENVIRONMENT CONFIRMED\")print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostgreSQL Setup for Google Colab\n",
    "\n",
    "This notebook requires PostgreSQL. Run the cell below to install and start PostgreSQL in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Directory Detection\n",
    "\n",
    "This notebook automatically detects the `data/` directory containing `schema.sql` and `data.sql` files.\n",
    "It works when uploaded to Google Colab or run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# SELF-AWARE DATA DIRECTORY DETECTION# ============================================================================import os\n",
    "import sysfrom pathlib import Pathprint(\"=\"*80)\n",
    "print(\"DATA DIRECTORY DETECTION\")print(\"=\"*80)def find_data_directory():    \"\"\"    Self-aware function to find data/ directory.    Works when notebook is uploaded to Colab or run locally.    \"\"\"    # Get notebook's current directory    if IS_COLAB:\n",
    "    # In Colab, check common locations        search_paths = [            Path('/content'),            Path('/content/drive/MyDrive'),            Path.cwd(),        ]    else:        # Local execution        search_paths = [            Path.cwd(),            Path(__file__).parent if '__file__' in globals() else Path.cwd(),            Path.cwd().parent,        ]        # Also check parent directories recursively    current = Path.cwd()    for _ in range(5):\n",
    "    # Check up to 5 levels up        search_paths.append(current)        current = current.parent        print(f\"\\nSearching for data/ directory...\")    print(f\"Current working directory: {Path.cwd()}\")        # Search for data/ directory    data_dir = None    for search_path in search_paths:        if not search_path.exists():            continue                # Check if data/ exists here        potential_data = search_path / 'data'        if potential_data.exists() and potential_data.is_dir():            data_dir = potential_data            print(f\"‚úÖ Found data/ directory: {data_dir}\")            break                # Recursively search subdirectories (limit depth to avoid long searches)        try:\n",
    "    for item in search_path.rglob('data'):\n",
    "    if item.is_dir() and item.name == 'data':                    # Verify it contains expected files                    expected_files = ['schema.sql', 'data.sql']                    has_expected = any((item / f).exists() for f in expected_files)                    if has_expected:                        data_dir = item                        print(f\"‚úÖ Found data/ directory (recursive): {data_dir}\")                        break            if data_dir:                break        except (PermissionError, OSError):\n",
    "    continue        \n",
    "if not data_dir:\n",
    "    # Try finding by database name pattern        db_name = Path.cwd().name        if db_name.startswith('db-'):            # Look for db-N/data pattern            for search_path in search_paths:\n",
    "    potential_db = search_path / db_name / 'data'                if potential_db.exists() and potential_db.is_dir():                    data_dir = potential_db                    print(f\"‚úÖ Found data/ directory by DB name: {data_dir}\")                    break        return data_dirdef verify_data_directory(data_dir: Path):    \"\"\"Verify data/ directory contains expected files.\"\"\"    if not data_dir or not data_dir.exists():        return False        expected_files = ['schema.sql']    optional_files = ['data.sql']        print(f\"\\nVerifying data/ directory contents...\")    print(f\"Location: {data_dir}\")        found_files = []    missing_files = []        for file_name in expected_files:        file_path = data_dir / file_name        if file_path.exists():            found_files.append(file_name)            print(f\"  ‚úÖ {file_name}\")        else:            missing_files.append(file_name)            print(f\"  ‚ùå {file_name} (missing)\")        for file_name in optional_files:        file_path = data_dir / file_name        if file_path.exists():            found_files.append(file_name)            print(f\"  ‚úÖ {file_name} (optional)\")        else:            print(f\"  ‚ö†Ô∏è  {file_name} (optional, not found)\")        if missing_files:        print(f\"\\n‚ö†Ô∏è  Warning: Missing required files: {missing_files}\")        return False        return True# Detect data directoryDATA_DIR = find_data_directory()if DATA_DIR:    if verify_data_directory(DATA_DIR):        print(f\"\\n‚úÖ Data directory verified and ready!\")        print(f\"   Schema file: {DATA_DIR / 'schema.sql'}\")        if (DATA_DIR / 'data.sql').exists():            print(f\"   Data file: {DATA_DIR / 'data.sql'}\")                # Set global variables for use in other cells        SCHEMA_FILE = DATA_DIR / 'schema.sql'        DATA_FILE = DATA_DIR / 'data.sql' if (DATA_DIR / 'data.sql').exists() else None                print(f\"\\n‚úÖ Global variables set:\")        print(f\"   DATA_DIR = {DATA_DIR}\")        print(f\"   SCHEMA_FILE = {SCHEMA_FILE}\")        if DATA_FILE:            print(f\"   DATA_FILE = {DATA_FILE}\")    else:        print(f\"\\n‚ö†Ô∏è  Data directory found but verification failed\")        print(f\"   Location: {DATA_DIR}\")        print(f\"   Please ensure schema.sql exists in this directory\")else:    print(f\"\\n‚ùå Data directory not found!\")    print(f\"\\nTroubleshooting:\")    print(f\"1. Ensure data/ directory is uploaded to Colab\")    print(f\"2. Check that data/ contains schema.sql\")    print(f\"3. Verify notebook is in same directory structure as data/\")    print(f\"\\nCurrent directory: {Path.cwd()}\")    print(f\"Contents:\")    try:\n",
    "    for item in sorted(Path.cwd().iterdir()):\n",
    "    print(f\"  - {item.name} ({'dir' if item.is_dir() else 'file'})\")    except PermissionError:\n",
    "    print(\"  (Permission denied)\")print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# POSTGRESQL SETUP FOR GOOGLE COLAB# ============================================================================import subprocess\n",
    "import timeimport osprint(\"=\"*80)\n",
    "print(\"POSTGRESQL SETUP FOR GOOGLE COLAB\")print(\"=\"*80)if not IS_COLAB:\n",
    "    raise RuntimeError(\"This notebook requires Google Colab\")# Check if PostgreSQL is already installedpostgres_installed = Falsetry:\n",
    "    result = subprocess.run(['psql', '--version'],                            capture_output=True,                            text=True,                            timeout=5)    if result.returncode == 0:        print(f\"‚úÖ PostgreSQL already installed: {result.stdout.strip()}\")        postgres_installed = Trueexcept (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "    pass\n",
    "if not postgres_installed:\n",
    "    print(\"\\nInstalling PostgreSQL using magic commands...\")    print(\"(Run these commands if automatic installation fails)\")    print(\"  !apt-get update\")    print(\"  !apt-get install -y postgresql postgresql-contrib\")    print(\"  !service postgresql start\")        # Use magic commands via subprocess (Colab-compatible)    try:\n",
    "    # Update package list        print(\"\\n   Updating package list...\")        os.system('apt-get update -qq')        print(\"   ‚úÖ Package list updated\")                # Install PostgreSQL        print(\"   Installing PostgreSQL...\")        os.system('apt-get install -y -qq postgresql postgresql-contrib')        print(\"   ‚úÖ PostgreSQL installed\")                # Start PostgreSQL service        print(\"   Starting PostgreSQL service...\")        os.system('service postgresql start')        print(\"   ‚úÖ PostgreSQL service started\")                # Wait for PostgreSQL to be ready        print(\"   Waiting for PostgreSQL to be ready...\")        time.sleep(3)            except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {e}\")        print(\"   Please run manually:\")        print(\"   !apt-get update\")        print(\"   !apt-get install -y postgresql postgresql-contrib\")        print(\"   !service postgresql start\")# Verify PostgreSQL is runningprint(\"\\nVerifying PostgreSQL is ready...\")try:    result = subprocess.run(['pg_isready'],                            capture_output=True,                            text=True,                            timeout=5)    if result.returncode == 0:        print(\"‚úÖ PostgreSQL is ready\")        print(f\"   {result.stdout.strip()}\")    else:        print(\"‚ö†Ô∏è  PostgreSQL may not be ready yet\")        print(\"   Try: !service postgresql restart\")except Exception as e:    print(f\"‚ö†Ô∏è  Could not verify PostgreSQL: {e}\")\n",
    "print(\"\\n\" + \"=\"*80)print(\"POSTGRESQL SETUP COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# STREAMLIT DASHBOARD EXECUTION# ============================================================================import subprocess\n",
    "import sysimport osfrom pathlib import Path\n",
    "import webbrowserimport timeimport threadingdef find_dashboard_file():        \"\"\"Find Streamlit dashboard file recursively.\"\"\"    search_paths = [        Path.cwd(),        Path('/workspace/client/db'),        Path('/workspace/db'),        Path('/workspace'),        Path('/content/drive/MyDrive/db'),        Path('/content/db'),        Path('/content'),        ,    ]        dashboard_name = f'{DB_NAME}_dashboard.py'        for search_path in search_paths:\n",
    "    if not search_path.exists():\n",
    "    continue                # Try direct path        candidate = search_path / dashboard_name        if candidate.exists():                            return candidate                # Try recursive search        try:\n",
    "    for found_path in search_path.rglob(dashboard_name):\n",
    "    if found_path.is_file():                                    return found_path        except:            continue        return Nonedef run_streamlit_dashboard(method='notebook', port=8501, open_browser=True):        \"\"\"    Run Streamlit dashboard from Jupyter notebook.        Methods:    - 'notebook': Run in notebook output (using streamlit's notebook mode)    - 'subprocess': Run as subprocess (background)    - 'magic': Use !streamlit run magic command    \"\"\"    dashboard_path = find_dashboard_file()        \n",
    "if not dashboard_path:\n",
    "    print(\"‚ùå Dashboard file not found\")        print(f\"   Looking for: {DB_NAME}_dashboard.py\")        return None        print(f\"‚úÖ Found dashboard: {dashboard_path}\")        if method == 'notebook':            # Method 1: Run Streamlit in notebook-compatible mode        # Note: Streamlit doesn't natively support notebooks, but we can use iframe        print(\"\\n\" + \"=\"*80)        print(\"STREAMLIT DASHBOARD - NOTEBOOK MODE\")        print(\"=\"*80)        print(f\"\\nDashboard: {dashboard_path.name}\")        print(f\"\\nTo run dashboard:\")        print(f\"  1. Run this cell to start the server\")        print(f\"  2. Open the URL shown below in a new tab\")        print(f\"  3. Or use: !streamlit run {dashboard_path} --server.port={port}\")        print(\"\\n\" + \"=\"*80)                # Start Streamlit as subprocess        cmd = [            sys.executable, '-m', 'streamlit', 'run',            str(dashboard_path),            '--server.port', str(port),            '--server.headless', 'true',            '--server.runOnSave', 'false',            '--browser.gatherUsageStats', 'false'        ]                process = subprocess.Popen(            cmd,            stdout=subprocess.PIPE,            stderr=subprocess.PIPE,            text=True        )                # Wait a moment for server to start        time.sleep(2)                # Get the URL        url = f\"http:\n",
    "    //localhost:{port}\"        print(f\"\\nüåê Dashboard URL: {url}\")        print(f\"\\nServer started in background (PID: {process.pid})\")        print(f\"\\nTo stop: process.terminate() or run stop_streamlit()\")                # Store process for later termination        globals()['_streamlit_process'] = process                # Try to open browser        if open_browser:                            try:\n",
    "    webbrowser.open(url)            except:                pass                return process        elif method == 'subprocess':            # Method 2: Run as background subprocess        cmd = [            sys.executable, '-m', 'streamlit', 'run',            str(dashboard_path),            '--server.port', str(port)        ]                process = subprocess.Popen(cmd)        print(f\"‚úÖ Streamlit started (PID: {process.pid})\")        print(f\"üåê Dashboard: http://localhost:{port}\")        return process        elif method == 'magic':            # Method 3: Print magic command for user to run        print(\"Run this command in a new cell:\n",
    "    \")        print(f\"!streamlit run {dashboard_path} --server.port={port}\")        return Nonedef stop_streamlit():        \"\"\"Stop running Streamlit process.\"\"\"    if '_streamlit_process' in globals():                        process = globals()['_streamlit_process']        process.terminate()        print(\"‚úÖ Streamlit stopped\")    else:            print(\"‚ö†Ô∏è  No Streamlit process found\")# Auto-detect DB_NAME if not setif 'DB_NAME' not in globals():        # Try to detect from current directory or notebook name    cwd = Path.cwd()    for db_num in range(6, 16):                    if f'db-{db_num}' in str(cwd) or f'db{db_num}' in str(cwd):                            DB_NAME = f'db-{db_num}'            break    else:            DB_NAME = 'db-6'  # Default        print(f\"‚ö†Ô∏è  Could not detect DB_NAME, using default: {DB_NAME}\")\n",
    "print(\"\\n\" + \"=\"*80)print(\"STREAMLIT DASHBOARD INTEGRATION\")\n",
    "print(\"=\"*80)print(f\"Database: {DB_NAME}\")\n",
    "print(\"\\nAvailable methods:\")print(\"  1. run_streamlit_dashboard(method='notebook') - Run in notebook mode\")print(\"  2. run_streamlit_dashboard(method='subprocess') - Run as background process\")print(\"  3. run_streamlit_dashboard(method='magic') - Get magic command\")print(\"  4. stop_streamlit() - Stop running dashboard\")print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit Dashboard\n",
    "\n",
    "Run the Streamlit dashboard using one of these methods:\n",
    "\n",
    "**Method 1: Notebook Mode** (Recommended)\n",
    "```python\n",
    "run_streamlit_dashboard(method='notebook', port=8501)\n",
    "```\n",
    "\n",
    "**Method 2: Magic Command**\n",
    "```bash\n",
    "!streamlit run db-10_dashboard.py --server.port=8501\n",
    "```\n",
    "\n",
    "**Method 3: Background Process**\n",
    "```python\n",
    "run_streamlit_dashboard(method='subprocess', port=8501)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Environment Detection and Self-Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# ENVIRONMENT DETECTION AND METAPROGRAMMATIC SELF-UPDATE# ============================================================================import sys\n",
    "import osimport platformimport subprocess\n",
    "import jsonfrom pathlib import Pathprint(\"=\"*80)\n",
    "print(\"ENVIRONMENT DETECTION\")print(\"=\"*80)# Detect environment typeENV_TYPE = NoneENV_DETAILS = {}# Check for Dockerif os.path.exists('/.dockerenv'):\n",
    "    ENV_TYPE = 'docker'    ENV_DETAILS['container'] = 'docker'    if os.path.exists('/workspace'):        ENV_DETAILS['workspace'] = '/workspace'    print(\"‚úÖ Detected: Docker container\")# Check for Google Colab# Improved Colab detectiontry:\n",
    "    import google.colab    ENV_TYPE = 'colab'    ENV_DETAILS['platform'] = 'google_colab'    ENV_DETAILS['colab_module'] = True    print(\"‚úÖ Detected: Google Colab (via google.colab module)\")except ImportError:\n",
    "    # Check for Colab by /content directory AND COLAB_GPU environment    if os.path.exists('/content') and os.environ.get('COLAB_GPU'):\n",
    "    ENV_TYPE = 'colab'        ENV_DETAILS['platform'] = 'google_colab'        ENV_DETAILS['content_dir'] = True        print(\"‚úÖ Detected: Google Colab (by /content + COLAB_GPU)\")    elif os.path.exists('/content') and 'COLAB' in str(os.environ):        ENV_TYPE = 'colab'        ENV_DETAILS['platform'] = 'google_colab'        ENV_DETAILS['content_dir'] = True        print(\"‚úÖ Detected: Google Colab (by /content + COLAB env)\")    elif os.path.exists('/content'):        # Check if it looks like Colab        if (Path('/content').exists() and             (Path('/content/sample_data').exists() or              Path('/content/drive').exists())):            ENV_TYPE = 'colab'            ENV_DETAILS['platform'] = 'google_colab'            ENV_DETAILS['content_dir'] = True            print(\"‚úÖ Detected: Google Colab (by /content structure)\")        else:            ENV_TYPE = 'colab'            ENV_DETAILS['platform'] = 'google_colab'            ENV_DETAILS['content_dir'] = True            print(\"‚ö†Ô∏è  Detected: Possible Google Colab (by /content)\")    ENV_DETAILS['platform'] = 'google_colab'    print(\"‚úÖ Detected: Google Colab (by /content directory)\")# Check for local environmentelse:    ENV_TYPE = 'local'    ENV_DETAILS['platform'] = platform.system().lower()    print(\"‚úÖ Detected: Local environment\")# Detect base directories recursivelydef find_base_directory():    \"\"\"Find base database directory recursively.\"\"\"    start_paths = [        Path.cwd(),        Path('/workspace'),        Path('/workspace/client/db'),        Path('/workspace/db'),        Path('/content'),        Path('/content/drive/MyDrive'),        ,    ]        for start_path in start_paths:        if not start_path.exists():            continue                # Look for db-6 directory (or any db-*)        for db_dir in start_path.rglob('db-6'):            if db_dir.is_dir() and (db_dir / 'queries').exists():                return db_dir.parent                # Look for client/db structure        client_db = start_path / 'client' / 'db'        if client_db.exists() and (client_db / 'db-6').exists():            return start_path        return Path.cwd()BASE_DIR = find_base_directory()ENV_DETAILS['base_dir'] = str(BASE_DIR)print(f\"\\nEnvironment Type: {ENV_TYPE}\")\n",
    "print(f\"Base Directory: {BASE_DIR}\")print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")print(f\"Platform: {platform.platform()}\")# Metaprogrammatic self-update functiondef update_notebook_paths():    \"\"\"Metaprogrammatically update notebook cell paths based on detected environment.\"\"\"    return {        'env_type': ENV_TYPE,        'base_dir': BASE_DIR,        'details': ENV_DETAILS    }ENV_CONFIG = update_notebook_paths()print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENVIRONMENT DETECTION COMPLETE\")print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab Setup (Run this first if using Google Colab)\n",
    "\n",
    "If you're running this notebook in Google Colab:\n",
    "1. **Mount Google Drive** (if your database files are in Drive)\n",
    "2. **Upload database files** to `/content/db` or your Drive folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GOOGLE COLAB SETUP\n",
    "# ============================================================================\n",
    "\n",
    "if ENV_TYPE == 'colab':\n",
    "    print(\"=\"*80)\n",
    "    print(\"GOOGLE COLAB SETUP\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Mount Google Drive if not already mounted\n",
    "    drive_path = Path('/content/drive/MyDrive')\n",
    "    if not drive_path.exists():\n",
    "    print(\"‚ö†Ô∏è  Google Drive not mounted.\")\n",
    "        print(\"   Run this command to mount:\")\n",
    "        print(\"   from google.colab import drive\")\n",
    "        print(\"   drive.mount('/content/drive')\")\n",
    "        try:\n",
    "    from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"‚úÖ Google Drive mounted\")\n",
    "        except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not auto-mount Drive: {e}\")\n",
    "            print(\"   Please mount manually using the command above\")\n",
    "    else:\n",
    "        print(\"‚úÖ Google Drive is already mounted\")\n",
    "    \n",
    "    # Check for database files\n",
    "    print(\"\\nChecking for database files...\")\n",
    "    \n",
    "    # Check in /content/db\n",
    "    content_db = Path('/content/db')\n",
    "    if content_db.exists():\n",
    "    print(f\"‚úÖ Found: {content_db}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Not found: {content_db}\")\n",
    "        print(\"   Upload your database folder to /content/db\")\n",
    "    \n",
    "    # Check in Drive\n",
    "    drive_db = drive_path / 'db'\n",
    "    if drive_db.exists():\n",
    "    print(f\"‚úÖ Found in Drive: {drive_db}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Not found in Drive: {drive_db}\")\n",
    "        print(\"   Upload your database folder to Google Drive/db\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Some PostgreSQL-specific features may not work\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Not running in Colab - skipping Colab setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# FAILSAFE: Force Path Correction and Package Installation# ============================================================================import sys\n",
    "import subprocessimport osfrom pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutildef force_install_package(package_name, import_name=None):    \"\"\"Force install package using multiple methods.\"\"\"    if import_name is None:\n",
    "    import_name = package_name.split('[')[0].split('==')[0].split('>=')[0]        # Try import first    try:\n",
    "    __import__(import_name)        return True    except ImportError:\n",
    "    pass        # Method 1: pip install --user    try:        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--user', '--quiet', package_name],                              stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)        __import__(import_name)        return True    except:        pass        # Method 2: pip install --break-system-packages (Python 3.12+)    try:        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--break-system-packages', '--quiet', package_name],                             stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)        __import__(import_name)        return True    except:        pass        # Method 3: pip install system-wide    try:        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--quiet', package_name],                             stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)        __import__(import_name)        return True    except:        pass        # Method 4: conda install (if conda available)    try:        subprocess.check_call(['conda', 'install', '-y', '--quiet', package_name],                             stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)        __import__(import_name)        return True    except:        pass        # Method 5: apt-get install (Linux/Docker)    if os.path.exists('/usr/bin/apt-get'):        try:            apt_package = f'python3-{import_name.replace(\"_\", \"-\")}'            subprocess.check_call(['apt-get', 'install', '-y', '--quiet', apt_package],                               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)            __import__(import_name)            return True        except:            pass        # Method 6: Direct pip install with --force-reinstall    try:        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--force-reinstall', '--quiet', package_name],                             stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)        __import__(import_name)        return True    except:        pass        print(f\"‚ö†Ô∏è  Warning: Could not install {package_name}, continuing anyway...\")    return Falsedef correct_file_path(file_path, search_paths=None):    \"\"\"Correct file path by searching multiple locations.\"\"\"    if isinstance(file_path, str):        file_path = Path(file_path)        # If path exists, return it    if file_path.exists():        return file_path        # Default search paths    if search_paths is None:        search_paths = [            Path.cwd(),            Path('/workspace/client/db'),            Path('/workspace/db'),            Path('/workspace'),            Path('/content/drive/MyDrive/db'),            Path('/content/db'),            Path('/content'),            ,            BASE_DIR if 'BASE_DIR' in globals() else ,        ]        # Search recursively    for search_path in search_paths:\n",
    "    if not search_path.exists():            continue                # Try direct path        candidate = search_path / file_path.name        if candidate.exists():            return candidate                # Try recursive search        try:            for found_path in search_path.rglob(file_path.name):                if found_path.is_file():                    return found_path        except:            continue        # Return original path (will fail later, but at least we tried)    return file_pathdef create_notebook_backup(notebook_path=None):    \"\"\"Create backup of current notebook automatically.\"\"\"    try:        # Try to detect notebook path from various sources        if notebook_path is None:            # Try to get from __file__ or current working directory            try:                notebook_path = Path(__file__)            except:                notebook_path = Path.cwd() / 'current_notebook.ipynb'                if isinstance(notebook_path, str):            notebook_path = Path(notebook_path)                # Only create backup if file exists        if notebook_path.exists() and notebook_path.suffix == '.ipynb':            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')            backup_path = notebook_path.parent / f\"{notebook_path.stem}_{timestamp}.backup.ipynb\"                        # Create backup            shutil.copy2(notebook_path, backup_path)            print(f\"‚úÖ Backup created: {backup_path.name}\")            return backup_path        else:            print(\"‚ö†Ô∏è  Could not determine notebook path for backup\")            return None    except Exception as e:        print(f\"‚ö†Ô∏è  Backup creation failed (non-critical): {e}\")        return None# Create backup at startuptry:    create_notebook_backup()except Exception as e:    print(f\"‚ö†Ô∏è  Backup skipped: {e}\")def ensure_packages_installed():    \"\"\"Ensure all required packages are installed.\"\"\"    required_packages = [        ('psycopg2-binary', 'psycopg2'),        ('pandas', 'pandas'),        ('numpy', 'numpy'),        ('matplotlib', 'matplotlib'),        ('seaborn', 'seaborn'),        ('ipython', 'IPython'),        ('jupyter', 'jupyter'),    ]        print(\"\\n\" + \"=\"*80)    print(\"FAILSAFE: Ensuring all packages are installed...\")    print(\"=\"*80)        for package, import_name in required_packages:        if force_install_package(package, import_name):            print(f\"‚úÖ {package} installed\")        else:            print(f\"‚ö†Ô∏è  {package} installation failed, but continuing...\")        print(\"=\"*80 + \"\\n\")def ensure_paths_correct():    \"\"\"Ensure all file paths are correct.\"\"\"    print(\"\\n\" + \"=\"*80)    print(\"FAILSAFE: Correcting file paths...\")    print(\"=\"*80)        # Correct BASE_DIR if needed - fix UnboundLocalError    base_dir_exists = 'BASE_DIR' in globals()    base_dir_valid = False        if base_dir_exists:        try:            base_dir_value = globals()['BASE_DIR']            if base_dir_value:                base_dir_path = Path(base_dir_value) if isinstance(base_dir_value, str) else base_dir_value                base_dir_valid = base_dir_path.exists()        except:            base_dir_valid = False        if not base_dir_exists or not base_dir_valid:        corrected_base_dir = correct_file_path()        globals()['BASE_DIR'] = corrected_base_dir        print(f\"‚úÖ BASE_DIR corrected: {corrected_base_dir}\")    else:        print(f\"‚úÖ BASE_DIR valid: {globals()['BASE_DIR']}\")        # Correct DB_DIR if needed - fix UnboundLocalError    db_dir_exists = 'DB_DIR' in globals()    db_dir_valid = False    db_dir_value = None        if db_dir_exists:        try:            db_dir_value = globals()['DB_DIR']            if db_dir_value:                db_dir_path = Path(db_dir_value) if isinstance(db_dir_value, str) else db_dir_value                db_dir_valid = db_dir_path.exists()        except:            db_dir_valid = False        if db_dir_exists and db_dir_value and not db_dir_valid:        db_dir_path = Path(db_dir_value) if isinstance(db_dir_value, str) else db_dir_value        corrected_db_dir = correct_file_path(db_dir_path)        globals()['DB_DIR'] = corrected_db_dir        print(f\"‚úÖ DB_DIR corrected: {corrected_db_dir}\")    elif db_dir_exists and db_dir_value:        print(f\"‚úÖ DB_DIR valid: {globals()['DB_DIR']}\")        print(\"=\"*80 + \"\\n\")# Run failsafe checksensure_packages_installed()ensure_paths_correct()print(\"‚úÖ Failsafe checks complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Environment Detection and Self-Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# ENVIRONMENT DETECTION AND METAPROGRAMMATIC SELF-UPDATE# ============================================================================import sys\n",
    "import osimport platformimport subprocess\n",
    "import jsonfrom pathlib import Pathprint(\"=\"*80)\n",
    "print(\"ENVIRONMENT DETECTION\")print(\"=\"*80)# Detect environment typeENV_TYPE = NoneENV_DETAILS = {}# Check for Dockerif os.path.exists('/.dockerenv'):\n",
    "    ENV_TYPE = 'docker'    ENV_DETAILS['container'] = 'docker'    if os.path.exists('/workspace'):        ENV_DETAILS['workspace'] = '/workspace'    print(\"‚úÖ Detected: Docker container\")# Check for Google Colab# Improved Colab detectiontry:\n",
    "    import google.colab    ENV_TYPE = 'colab'    ENV_DETAILS['platform'] = 'google_colab'    ENV_DETAILS['colab_module'] = True    print(\"‚úÖ Detected: Google Colab (via google.colab module)\")except ImportError:\n",
    "    # Check for Colab by /content directory AND COLAB_GPU environment    if os.path.exists('/content') and os.environ.get('COLAB_GPU'):\n",
    "    ENV_TYPE = 'colab'        ENV_DETAILS['platform'] = 'google_colab'        ENV_DETAILS['content_dir'] = True        print(\"‚úÖ Detected: Google Colab (by /content + COLAB_GPU)\")    elif os.path.exists('/content') and 'COLAB' in str(os.environ):        ENV_TYPE = 'colab'        ENV_DETAILS['platform'] = 'google_colab'        ENV_DETAILS['content_dir'] = True        print(\"‚úÖ Detected: Google Colab (by /content + COLAB env)\")    elif os.path.exists('/content'):        # Check if it looks like Colab        if (Path('/content').exists() and             (Path('/content/sample_data').exists() or              Path('/content/drive').exists())):            ENV_TYPE = 'colab'            ENV_DETAILS['platform'] = 'google_colab'            ENV_DETAILS['content_dir'] = True            print(\"‚úÖ Detected: Google Colab (by /content structure)\")        else:            ENV_TYPE = 'colab'            ENV_DETAILS['platform'] = 'google_colab'            ENV_DETAILS['content_dir'] = True            print(\"‚ö†Ô∏è  Detected: Possible Google Colab (by /content)\")    ENV_DETAILS['platform'] = 'google_colab'    print(\"‚úÖ Detected: Google Colab (by /content directory)\")# Check for local environmentelse:    ENV_TYPE = 'local'    ENV_DETAILS['platform'] = platform.system().lower()    print(\"‚úÖ Detected: Local environment\")# Detect base directories recursivelydef find_base_directory():    \"\"\"Find base database directory recursively.\"\"\"    start_paths = [        Path.cwd(),        Path('/workspace'),        Path('/workspace/client/db'),        Path('/workspace/db'),        Path('/content'),        Path('/content/drive/MyDrive'),        ,    ]        for start_path in start_paths:        if not start_path.exists():            continue                # Look for db-6 directory (or any db-*)        for db_dir in start_path.rglob('db-6'):            if db_dir.is_dir() and (db_dir / 'queries').exists():                return db_dir.parent                # Look for client/db structure        client_db = start_path / 'client' / 'db'        if client_db.exists() and (client_db / 'db-6').exists():            return start_path        return Path.cwd()BASE_DIR = find_base_directory()ENV_DETAILS['base_dir'] = str(BASE_DIR)print(f\"\\nEnvironment Type: {ENV_TYPE}\")\n",
    "print(f\"Base Directory: {BASE_DIR}\")print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")print(f\"Platform: {platform.platform()}\")# Metaprogrammatic self-update functiondef update_notebook_paths():    \"\"\"Metaprogrammatically update notebook cell paths based on detected environment.\"\"\"    return {        'env_type': ENV_TYPE,        'base_dir': BASE_DIR,        'details': ENV_DETAILS    }ENV_CONFIG = update_notebook_paths()print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENVIRONMENT DETECTION COMPLETE\")print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup & Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_package_multiple_methods(package_spec: str, import_name: str) -> bool:    \"\"\"Install package using multiple methods with fallbacks.\"\"\"    package_name = package_spec.split('>=')[0]        # Method 1: Check if already installed    try:\n",
    "    __import__(import_name)        print(f\"‚úÖ {package_name}: Already installed\")        return True    except ImportError:\n",
    "    pass        print(f\"‚ö†Ô∏è  {package_name}: Installing...\")        # Method 2: pip install --user    try:                subprocess.check_call(            [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet', '--user'],            stdout=subprocess.DEVNULL,            stderr=subprocess.PIPE,            timeout=300        )        __import__(import_name)        print(f\"   ‚úÖ Installed via pip --user\")        return True    except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                    pass        # Method 3: pip install (system-wide)    try:                subprocess.check_call(            [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet'],            stdout=subprocess.DEVNULL,            stderr=subprocess.PIPE,            timeout=300        )        __import__(import_name)        print(f\"   ‚úÖ Installed via pip (system-wide)\")        return True    except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                    pass        # Method 4: pip install --break-system-packages    if ENV_TYPE == 'local' and platform.system() == 'Linux':                    try:                    subprocess.check_call(                [sys.executable, '-m', 'pip', 'install', package_spec, '--break-system-packages', '--quiet'],                stdout=subprocess.DEVNULL,                stderr=subprocess.PIPE,                timeout=300            )            __import__(import_name)            print(f\"   ‚úÖ Installed via pip --break-system-packages\")            return True        except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                        pass        # Method 5: conda install    import shutil    if shutil.which('conda'):                        try:                    conda_pkg = package_name.replace('-binary', '')            subprocess.check_call(                ['conda', 'install', '-y', conda_pkg],                stdout=subprocess.DEVNULL,                stderr=subprocess.PIPE,                timeout=300            )            __import__(import_name)            print(f\"   ‚úÖ Installed via conda\")            return True        except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                        pass        # Method 6: apt-get (Docker/Colab)    if ENV_TYPE in ['docker', 'colab']:                    try:                    system_pkg_map = {                'psycopg2-binary': 'python3-psycopg2',                'pandas': 'python3-pandas',                'numpy': 'python3-numpy',                'matplotlib': 'python3-matplotlib',            }                        if package_name in system_pkg_map:                            subprocess.check_call(                    ['apt-get', 'update'],                    stdout=subprocess.DEVNULL,                    stderr=subprocess.PIPE                )                subprocess.check_call(                    ['apt-get', 'install', '-y', system_pkg_map[package_name]],                    stdout=subprocess.DEVNULL,                    stderr=subprocess.PIPE,                    timeout=300                )                __import__(import_name)                print(f\"   ‚úÖ Installed via apt-get\")                return True        except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired, FileNotFoundError):                        pass        print(f\"   ‚ùå Failed to install {package_name} via all methods\")    return Falsedef install_package_multiple_methods(package_spec: str, import_name: str) -> bool:    \"\"\"Install package using multiple methods with fallbacks.\"\"\"    package_name = package_spec.split('>=')[0]        # Method 1: Check if already installed    try:                        __import__(import_name)        print(f\"‚úÖ {package_name}: Already installed\")        return True    except ImportError:                pass        print(f\"‚ö†Ô∏è  {package_name}: Installing...\")        # Method 2: pip install --user    try:                subprocess.check_call(            [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet', '--user'],            stdout=subprocess.DEVNULL,            stderr=subprocess.PIPE,            timeout=300        )        __import__(import_name)        print(f\"   ‚úÖ Installed via pip --user\")        return True    except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                    pass        # Method 3: pip install (system-wide)    try:                subprocess.check_call(            [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet'],            stdout=subprocess.DEVNULL,            stderr=subprocess.PIPE,            timeout=300        )        __import__(import_name)        print(f\"   ‚úÖ Installed via pip (system-wide)\")        return True    except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                    pass        # Method 4: pip install --break-system-packages    if ENV_TYPE == 'local' and platform.system() == 'Linux':                    try:                    subprocess.check_call(                [sys.executable, '-m', 'pip', 'install', package_spec, '--break-system-packages', '--quiet'],                stdout=subprocess.DEVNULL,                stderr=subprocess.PIPE,                timeout=300            )            __import__(import_name)            print(f\"   ‚úÖ Installed via pip --break-system-packages\")            return True        except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                        pass        # Method 5: conda install    import shutil    if shutil.which('conda'):                        try:                    conda_pkg = package_name.replace('-binary', '')            subprocess.check_call(                ['conda', 'install', '-y', conda_pkg],                stdout=subprocess.DEVNULL,                stderr=subprocess.PIPE,                timeout=300            )            __import__(import_name)            print(f\"   ‚úÖ Installed via conda\")            return True        except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired):                        pass        # Method 6: apt-get (Docker/Colab)    if ENV_TYPE in ['docker', 'colab']:                    try:                    system_pkg_map = {                'psycopg2-binary': 'python3-psycopg2',                'pandas': 'python3-pandas',                'numpy': 'python3-numpy',                'matplotlib': 'python3-matplotlib',            }                        if package_name in system_pkg_map:                            subprocess.check_call(                    ['apt-get', 'update'],                    stdout=subprocess.DEVNULL,                    stderr=subprocess.PIPE                )                subprocess.check_call(                    ['apt-get', 'install', '-y', system_pkg_map[package_name]],                    stdout=subprocess.DEVNULL,                    stderr=subprocess.PIPE,                    timeout=300                )                __import__(import_name)                print(f\"   ‚úÖ Installed via apt-get\")                return True        except (subprocess.CalledProcessError, ImportError, subprocess.TimeoutExpired, FileNotFoundError):                        pass        print(f\"   ‚ùå Failed to install {package_name} via all methods\")    return False# ============================================================================# END-TO-END SETUP: Install all required packages and configure environment# ============================================================================import sys\n",
    "import subprocessimport osimport platformfrom pathlib import Pathprint(\"=\"*80)\n",
    "print(\"ENVIRONMENT SETUP - END-TO-END INSTALLATION\")print(\"=\"*80)# Display Python environmentprint(f\"\\nPython Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")print(f\"Platform: {platform.platform()}\")print(f\"Architecture: {platform.architecture()[0]}\")# Required packages with versionsrequired_packages = [    'psycopg2-binary>=2.9.0',    'pandas>=2.0.0',    'numpy>=1.24.0',    'matplotlib>=3.7.0',    'seaborn>=0.12.0']# Map package names to import namespackage_import_map = {    'psycopg2-binary': 'psycopg2',    'pandas': 'pandas',    'numpy': 'numpy',    'matplotlib': 'matplotlib',    'seaborn': 'seaborn'}print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKING AND INSTALLING REQUIRED PACKAGES\")print(\"=\"*80)missing_packages = []installed_packages = []for package_spec in required_packages:\n",
    "    package_name = package_spec.split('>=')[0]    import_name = package_import_map.get(package_name, package_name.replace('-', '_'))        # Check if already installed    try:\n",
    "    __import__(import_name)        print(f\"‚úÖ {package_name}: Already installed\")        installed_packages.append(package_name)    except ImportError:\n",
    "    print(f\"‚ö†Ô∏è  {package_name}: Missing - installing...\")        missing_packages.append(package_spec)                # Try installation with --user flag first        try:                    subprocess.check_call(                [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet', '--user'],                stdout=subprocess.DEVNULL,                stderr=subprocess.PIPE            )            print(f\"   ‚úÖ Successfully installed {package_name} (user)\")            installed_packages.append(package_name)        except subprocess.CalledProcessError:                # Fallback: try without --user flag            try:                        subprocess.check_call(                    [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet'],                    stdout=subprocess.DEVNULL,                    stderr=subprocess.PIPE                )                print(f\"   ‚úÖ Successfully installed {package_name} (system-wide)\")                installed_packages.append(package_name)            except Exception as e:                        print(f\"   ‚ùå Failed to install {package_name}\")                print(f\"      Manual install: pip install {package_spec}\")\n",
    "print(\"\\n\" + \"=\"*80)if missing_packages and len(installed_packages) < len(required_packages):\n",
    "    print(\"‚ö†Ô∏è  Some packages failed to install. Please install manually:\")    for pkg in missing_packages:\n",
    "    print(f\"   pip install {pkg}\")    print(\"\\n   Then restart the kernel and re-run this cell.\")else:        print(\"‚úÖ All required packages are installed!\")    print(\"\\n‚ö†Ô∏è  If packages were just installed, restart the kernel and re-run this cell.\")\n",
    "print(\"=\"*80)# Now import all packagesprint(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPORTING PACKAGES\")print(\"=\"*80)try:\n",
    "    import psycopg2    print(\"‚úÖ psycopg2 imported\")except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import psycopg2: {e}\")    print(\"   Please restart kernel after installation\")try:            import pandas as pd    print(\"‚úÖ pandas imported\")except ImportError as e:            print(f\"‚ùå Failed to import pandas: {e}\")try:            import numpy as np    print(\"‚úÖ numpy imported\")except ImportError as e:            print(f\"‚ùå Failed to import numpy: {e}\")try:            import matplotlib.pyplot as plt    import matplotlib    matplotlib.use('Agg')  # Non-interactive backend for notebooks    print(\"‚úÖ matplotlib imported\")except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import matplotlib: {e}\")try:            import seaborn as sns    print(\"‚úÖ seaborn imported\")except ImportError as e:            print(f\"‚ùå Failed to import seaborn: {e}\")try:            from IPython.display import display, HTML, Markdown    print(\"‚úÖ IPython.display imported\")except ImportError as e:            print(f\"‚ö†Ô∏è  IPython.display not available: {e}\")import json\n",
    "from datetime import datetime\n",
    "import warningswarnings.filterwarnings('ignore')# Set visualization styletry:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')    sns.set_palette(\"husl\")except:    passprint(\"\\n\" + \"=\"*80)\n",
    "print(\"ENVIRONMENT SETUP COMPLETE\")print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Database Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# POSTGRESQL DATABASE CONNECTION (Colab Only)# ============================================================================import psycopg2from pathlib import Path# Database nameDB_NAME = \"db-10\"def create_postgresql_connection():        \"\"\"Create PostgreSQL connection for Colab.\"\"\"    if not IS_COLAB:\n",
    "    raise RuntimeError(\"This notebook requires Google Colab\")        # Colab PostgreSQL defaults    try:\n",
    "    conn = psycopg2.connect(            host='localhost',            port=5432,            user='postgres',            password='postgres',  # Default Colab PostgreSQL password            database='postgres'  # Connect to default database first        )        print(\"‚úÖ Connected to PostgreSQL\")        return conn    except Exception as e:\n",
    "    print(f\"‚ùå PostgreSQL connection failed: {e}\")        print(\"\\nTroubleshooting:\")        print(\"1. Make sure PostgreSQL is installed (run the installation cell above)\")        print(\"2. Check if PostgreSQL service is running:     !service postgresql status\")        print(\"3. Try restarting PostgreSQL: !service postgresql restart\")        raise# Create connectionconn = create_postgresql_connection()print(f\"\\nDatabase connection: PostgreSQL (Colab)\")print(f\"Host: localhost\")\n",
    "print(f\"Port: 5432\")print(f\"User: postgres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Database Initialization (Create Database, Load Schema, Load Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# POSTGRESQL DATABASE CONNECTION (Colab Only)# ============================================================================import psycopg2from pathlib import Path# Database nameDB_NAME = \"db-10\"def create_postgresql_connection():        \"\"\"Create PostgreSQL connection for Colab.\"\"\"    if not IS_COLAB:\n",
    "    raise RuntimeError(\"This notebook requires Google Colab\")        # Colab PostgreSQL defaults    try:\n",
    "    conn = psycopg2.connect(            host='localhost',            port=5432,            user='postgres',            password='postgres',  # Default Colab PostgreSQL password            database='postgres'  # Connect to default database first        )        print(\"‚úÖ Connected to PostgreSQL\")        return conn    except Exception as e:\n",
    "    print(f\"‚ùå PostgreSQL connection failed: {e}\")        print(\"\\nTroubleshooting:\")        print(\"1. Make sure PostgreSQL is installed (run the installation cell above)\")        print(\"2. Check if PostgreSQL service is running:     !service postgresql status\")        print(\"3. Try restarting PostgreSQL: !service postgresql restart\")        raise# Create connectionconn = create_postgresql_connection()print(f\"\\nDatabase connection: PostgreSQL (Colab)\")print(f\"Host: localhost\")\n",
    "print(f\"Port: 5432\")print(f\"User: postgres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Query Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded SQL Files and Queries\n",
    "\n",
    "The following cells contain the complete database schema, data, and queries embedded directly in this notebook.\n",
    "No external file dependencies required - everything is self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EMBEDDED SCHEMA.SQL - DB-10\n",
    "# ============================================================================\n",
    "# This cell contains the complete database schema\n",
    "# Execute this cell to load the schema into PostgreSQL\n",
    "import psycopg2\n",
    "# Schema SQL (embedded directly in notebook)\n",
    "SCHEMA_SQL = \"\"\"\n",
    "-- Shopping Aggregator Database Schema\n",
    "-- Compatible with PostgreSQL, Databricks, and Snowflake\n",
    "-- Production schema for marketing intelligence and retail inventory tracking system\n",
    "-- Integrates data from U.S. Census Bureau, BLS, FTC, Data.gov, and retail sources\n",
    "-- Products Table\n",
    "-- Product catalog with SKUs, UPCs, categories, and brand information\n",
    "CREATE TABLE products (\n",
    "    product_id VARCHAR(255) PRIMARY KEY,\n",
    "    sku VARCHAR(100) UNIQUE,\n",
    "    upc VARCHAR(50) UNIQUE,\n",
    "    product_name VARCHAR(500) NOT NULL,\n",
    "    brand VARCHAR(255),\n",
    "    manufacturer VARCHAR(255),\n",
    "    model_number VARCHAR(100),\n",
    "    category VARCHAR(100) NOT NULL,\n",
    "    subcategory VARCHAR(100),\n",
    "    product_description TEXT,\n",
    "    product_image_url VARCHAR(1000),\n",
    "    weight_lbs NUMERIC(8, 2),\n",
    "    dimensions_length NUMERIC(8, 2),\n",
    "    dimensions_width NUMERIC(8, 2),\n",
    "    dimensions_height NUMERIC(8, 2),\n",
    "    color VARCHAR(100),\n",
    "    size VARCHAR(100),\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    is_active BOOLEAN DEFAULT TRUE,\n",
    "    data_source VARCHAR(50) DEFAULT 'MANUAL'\n",
    ");\n",
    "-- Retailers Table\n",
    "-- Retailer information including headquarters and market coverage\n",
    "CREATE TABLE retailers (\n",
    "    retailer_id VARCHAR(255) PRIMARY KEY,\n",
    "    retailer_name VARCHAR(255) NOT NULL UNIQUE,\n",
    "    retailer_type VARCHAR(50), -- 'big_box', 'department_store', 'online', 'specialty', 'discount'\n",
    "    website_url VARCHAR(500),\n",
    "    headquarters_address VARCHAR(500),\n",
    "    headquarters_city VARCHAR(100),\n",
    "    headquarters_state VARCHAR(2),\n",
    "    headquarters_zip VARCHAR(20),\n",
    "    headquarters_country VARCHAR(2) DEFAULT 'US',\n",
    "    headquarters_latitude NUMERIC(10, 7),\n",
    "    headquarters_longitude NUMERIC(10, 7),\n",
    "    market_coverage VARCHAR(50), -- 'national', 'regional', 'local', 'international'\n",
    "    retailer_status VARCHAR(50) DEFAULT 'active', -- 'active', 'inactive', 'bankrupt'\n",
    "    founded_year INTEGER,\n",
    "    employee_count INTEGER,\n",
    "    annual_revenue_usd NUMERIC(15, 2),\n",
    "    data_source VARCHAR(50) DEFAULT 'MANUAL',\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ");\n",
    "-- Stores Table\n",
    "-- Store locations with geographic data for spatial analysis\n",
    "CREATE TABLE stores (\n",
    "    store_id VARCHAR(255) PRIMARY KEY,\n",
    "    retailer_id VARCHAR(255) NOT NULL,\n",
    "    store_name VARCHAR(255),\n",
    "    store_number VARCHAR(50),\n",
    "    store_address VARCHAR(500),\n",
    "    store_city VARCHAR(100),\n",
    "    store_state VARCHAR(2),\n",
    "    store_zip VARCHAR(20),\n",
    "    store_county VARCHAR(100),\n",
    "    store_country VARCHAR(2) DEFAULT 'US',\n",
    "    store_latitude NUMERIC(10, 7) NOT NULL,\n",
    "    store_longitude NUMERIC(10, 7) NOT NULL,\n",
    "    store_geom GEOGRAPHY, -- Point geometry for store location\n",
    "    store_type VARCHAR(50), -- 'supercenter', 'neighborhood', 'express', 'warehouse'\n",
    "    store_size_sqft INTEGER,\n",
    "    opening_date DATE,\n",
    "    closing_date DATE,\n",
    "    phone_number VARCHAR(20),\n",
    "    store_status VARCHAR(50) DEFAULT 'open', -- 'open', 'closed', 'temporary_closed'\n",
    "    data_source VARCHAR(50) DEFAULT 'MANUAL',\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    FOREIGN KEY (retailer_id) REFERENCES retailers(retailer_id)\n",
    ");\n",
    "-- Product Inventory Table\n",
    "-- Inventory levels by store with stock status tracking\n",
    "CREATE TABLE product_inventory (\n",
    "    inventory_id VARCHAR(255) PRIMARY KEY,\n",
    "    product_id VARCHAR(255) NOT NULL,\n",
    "    store_id VARCHAR(255) NOT NULL,\n",
    "    stock_level INTEGER DEFAULT 0,\n",
    "    stock_status VARCHAR(50) NOT NULL, -- 'in_stock', 'out_of_stock', 'low_stock', 'limited_availability'\n",
    "    available_quantity INTEGER,\n",
    "    reserved_quantity INTEGER DEFAULT 0,\n",
    "    reorder_point INTEGER,\n",
    "    last_checked_at TIMESTAMP_NTZ NOT NULL,\n",
    "    last_restocked_at TIMESTAMP_NTZ,\n",
    "    data_source VARCHAR(50) NOT NULL, -- 'api', 'scraper', 'manual', 'census'\n",
    "    confidence_score NUMERIC(5, 2), -- Data quality confidence (0-100)\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id),\n",
    "    FOREIGN KEY (store_id) REFERENCES stores(store_id)\n",
    ");\n",
    "-- Product Pricing Table\n",
    "-- Pricing data with historical tracking and deal detection\n",
    "CREATE TABLE product_pricing (\n",
    "    pricing_id VARCHAR(255) PRIMARY KEY,\n",
    "    product_id VARCHAR(255) NOT NULL,\n",
    "    retailer_id VARCHAR(255) NOT NULL,\n",
    "    store_id VARCHAR(255), -- NULL for online-only pricing\n",
    "    current_price NUMERIC(10, 2) NOT NULL,\n",
    "    original_price NUMERIC(10, 2),\n",
    "    sale_price NUMERIC(10, 2),\n",
    "    discount_percentage NUMERIC(5, 2),\n",
    "    price_effective_date TIMESTAMP_NTZ NOT NULL,\n",
    "    price_expiry_date TIMESTAMP_NTZ,\n",
    "    price_type VARCHAR(50), -- 'regular', 'sale', 'clearance', 'promotional'\n",
    "    price_source VARCHAR(50) NOT NULL, -- 'api', 'scraper', 'manual', 'census'\n",
    "    price_confidence_score NUMERIC(5, 2), -- Data quality confidence (0-100)\n",
    "    currency VARCHAR(3) DEFAULT 'USD',\n",
    "    is_online_price BOOLEAN DEFAULT FALSE,\n",
    "    shipping_cost NUMERIC(8, 2),\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id),\n",
    "    FOREIGN KEY (retailer_id) REFERENCES retailers(retailer_id),\n",
    "    FOREIGN KEY (store_id) REFERENCES stores(store_id)\n",
    ");\n",
    "-- Market Intelligence Table\n",
    "-- Aggregated market data for competitive analysis and trends\n",
    "CREATE TABLE market_intelligence (\n",
    "    intelligence_id VARCHAR(255) PRIMARY KEY,\n",
    "    product_id VARCHAR(255) NOT NULL,\n",
    "    market_area VARCHAR(100), -- ZIP code, city, state, or 'national'\n",
    "    market_type VARCHAR(50), -- 'zip', 'city', 'state', 'msa', 'national'\n",
    "    average_price NUMERIC(10, 2),\n",
    "    price_range_min NUMERIC(10, 2),\n",
    "    price_range_max NUMERIC(10, 2),\n",
    "    median_price NUMERIC(10, 2),\n",
    "    price_std_dev NUMERIC(10, 2),\n",
    "    availability_rate NUMERIC(5, 2), -- Percentage of stores with product in stock\n",
    "    market_share NUMERIC(5, 2), -- Market share percentage\n",
    "    competitor_count INTEGER, -- Number of retailers selling this product\n",
    "    total_stores_with_product INTEGER,\n",
    "    total_stores_checked INTEGER,\n",
    "    intelligence_date DATE NOT NULL,\n",
    "    data_quality_score NUMERIC(5, 2), -- Overall data quality score (0-100)\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
    ");\n",
    "-- Deal Alerts Table\n",
    "-- Deal tracking and alert generation for promotions and sales\n",
    "CREATE TABLE deal_alerts (\n",
    "    deal_id VARCHAR(255) PRIMARY KEY,\n",
    "    product_id VARCHAR(255) NOT NULL,\n",
    "    retailer_id VARCHAR(255) NOT NULL,\n",
    "    store_id VARCHAR(255), -- NULL for online-only deals\n",
    "    deal_type VARCHAR(50) NOT NULL, -- 'clearance', 'sale', 'promotion', 'flash_sale', 'bogo'\n",
    "    discount_percentage NUMERIC(5, 2),\n",
    "    discount_amount NUMERIC(10, 2),\n",
    "    deal_price NUMERIC(10, 2) NOT NULL,\n",
    "    original_price NUMERIC(10, 2) NOT NULL,\n",
    "    deal_start_date TIMESTAMP_NTZ NOT NULL,\n",
    "    deal_end_date TIMESTAMP_NTZ,\n",
    "    deal_status VARCHAR(50) DEFAULT 'active', -- 'active', 'expired', 'cancelled'\n",
    "    deal_description VARCHAR(2000),\n",
    "    deal_source VARCHAR(50) NOT NULL, -- 'api', 'scraper', 'manual', 'census'\n",
    "    is_online_deal BOOLEAN DEFAULT FALSE,\n",
    "    quantity_limit INTEGER,\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id),\n",
    "    FOREIGN KEY (retailer_id) REFERENCES retailers(retailer_id),\n",
    "    FOREIGN KEY (store_id) REFERENCES stores(store_id)\n",
    ");\n",
    "-- Census Retail Data Table\n",
    "-- U.S. Census Bureau Monthly Retail Trade Survey (MRTS) data\n",
    "CREATE TABLE census_retail_data (\n",
    "    census_id VARCHAR(255) PRIMARY KEY,\n",
    "    naics_code VARCHAR(10), -- North American Industry Classification System code\n",
    "    industry_category VARCHAR(255) NOT NULL,\n",
    "    month INTEGER NOT NULL, -- 1-12\n",
    "    year INTEGER NOT NULL,\n",
    "    retail_sales_amount NUMERIC(15, 2), -- In millions of dollars\n",
    "    inventory_amount NUMERIC(15, 2), -- In millions of dollars\n",
    "    store_count INTEGER,\n",
    "    employment_count INTEGER,\n",
    "    sales_change_percent NUMERIC(6, 2), -- Month-over-month percentage change\n",
    "    inventory_change_percent NUMERIC(6, 2),\n",
    "    data_source VARCHAR(50) DEFAULT 'CENSUS_MRTS',\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ");\n",
    "-- BLS Price Data Table\n",
    "-- Bureau of Labor Statistics Consumer Price Index (CPI) and Producer Price Index (PPI) data\n",
    "CREATE TABLE bls_price_data (\n",
    "    bls_id VARCHAR(255) PRIMARY KEY,\n",
    "    series_id VARCHAR(50) NOT NULL, -- BLS series identifier\n",
    "    product_category VARCHAR(255) NOT NULL,\n",
    "    period VARCHAR(10) NOT NULL, -- 'M01' through 'M12' for monthly, 'Q01' through 'Q04' for quarterly\n",
    "    year INTEGER NOT NULL,\n",
    "    price_index_value NUMERIC(10, 2),\n",
    "    percent_change NUMERIC(6, 2), -- Period-over-period percentage change\n",
    "    percent_change_year_ago NUMERIC(6, 2), -- Year-over-year percentage change\n",
    "    base_period VARCHAR(20), -- Base period for index (e.g., '1982-84=100')\n",
    "    index_type VARCHAR(50), -- 'CPI', 'PPI', 'CPI_U', 'CPI_W'\n",
    "    data_source VARCHAR(50) DEFAULT 'BLS_API',\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ");\n",
    "-- Geographic Markets Table\n",
    "-- Market area definitions with geographic boundaries and demographics\n",
    "CREATE TABLE geographic_markets (\n",
    "    market_id VARCHAR(255) PRIMARY KEY,\n",
    "    market_name VARCHAR(255) NOT NULL,\n",
    "    market_type VARCHAR(50) NOT NULL, -- 'zip', 'city', 'county', 'msa', 'state', 'national'\n",
    "    market_code VARCHAR(50), -- ZIP code, FIPS code, MSA code, etc.\n",
    "    market_geom GEOGRAPHY, -- Polygon geometry for market boundaries\n",
    "    market_boundaries TEXT, -- JSON or text representation of boundaries\n",
    "    population INTEGER,\n",
    "    median_income NUMERIC(10, 2),\n",
    "    market_size NUMERIC(15, 2), -- Market size in square miles or km¬≤\n",
    "    state_code VARCHAR(2),\n",
    "    county_name VARCHAR(100),\n",
    "    msa_code VARCHAR(10), -- Metropolitan Statistical Area code\n",
    "    data_source VARCHAR(50) DEFAULT 'CENSUS',\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ");\n",
    "-- Data Sources Table\n",
    "-- Source tracking for data lineage and quality monitoring\n",
    "CREATE TABLE data_sources (\n",
    "    source_id VARCHAR(255) PRIMARY KEY,\n",
    "    source_name VARCHAR(255) NOT NULL UNIQUE,\n",
    "    source_type VARCHAR(50) NOT NULL, -- 'api', 'scraper', 'manual', 'census', 'bls', 'ftc'\n",
    "    api_endpoint VARCHAR(1000),\n",
    "    api_key_required BOOLEAN DEFAULT FALSE,\n",
    "    rate_limit_per_hour INTEGER,\n",
    "    rate_limit_per_day INTEGER,\n",
    "    last_sync_at TIMESTAMP_NTZ,\n",
    "    sync_frequency VARCHAR(50), -- 'hourly', 'daily', 'weekly', 'monthly', 'manual'\n",
    "    data_quality_score NUMERIC(5, 2), -- Overall data quality score (0-100)\n",
    "    is_active BOOLEAN DEFAULT TRUE,\n",
    "    notes VARCHAR(2000),\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ");\n",
    "-- Pipeline Metadata Table\n",
    "-- ETL pipeline execution tracking and error logging\n",
    "CREATE TABLE pipeline_metadata (\n",
    "    pipeline_id VARCHAR(255) PRIMARY KEY,\n",
    "    source_id VARCHAR(255) NOT NULL,\n",
    "    extraction_date TIMESTAMP_NTZ NOT NULL,\n",
    "    pipeline_type VARCHAR(50) NOT NULL, -- 'extract', 'transform', 'load', 'full'\n",
    "    records_processed INTEGER DEFAULT 0,\n",
    "    records_successful INTEGER DEFAULT 0,\n",
    "    records_failed INTEGER DEFAULT 0,\n",
    "    processing_duration_seconds INTEGER,\n",
    "    error_log TEXT,\n",
    "    status VARCHAR(50) DEFAULT 'running', -- 'running', 'success', 'failed', 'partial'\n",
    "    start_time TIMESTAMP_NTZ NOT NULL,\n",
    "    end_time TIMESTAMP_NTZ,\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    FOREIGN KEY (source_id) REFERENCES data_sources(source_id)\n",
    ");\n",
    "-- Create indexes for performance optimization\n",
    "CREATE INDEX idx_products_sku ON products(sku);\n",
    "CREATE INDEX idx_products_upc ON products(upc);\n",
    "CREATE INDEX idx_products_category ON products(category, subcategory);\n",
    "CREATE INDEX idx_products_brand ON products(brand);\n",
    "CREATE INDEX idx_stores_retailer ON stores(retailer_id);\n",
    "CREATE INDEX idx_stores_location ON stores(store_state, store_city);\n",
    "CREATE INDEX idx_stores_geom ON stores USING GIST(store_geom);\n",
    "CREATE INDEX idx_stores_lat_lon ON stores(store_latitude, store_longitude);\n",
    "CREATE INDEX idx_product_inventory_product_store ON product_inventory(product_id, store_id);\n",
    "CREATE INDEX idx_product_inventory_status ON product_inventory(stock_status, last_checked_at);\n",
    "CREATE INDEX idx_product_inventory_product ON product_inventory(product_id);\n",
    "CREATE INDEX idx_product_pricing_product_retailer ON product_pricing(product_id, retailer_id);\n",
    "CREATE INDEX idx_product_pricing_store ON product_pricing(store_id);\n",
    "CREATE INDEX idx_product_pricing_date ON product_pricing(price_effective_date, price_expiry_date);\n",
    "CREATE INDEX idx_product_pricing_type ON product_pricing(price_type);\n",
    "CREATE INDEX idx_market_intelligence_product_date ON market_intelligence(product_id, intelligence_date);\n",
    "CREATE INDEX idx_market_intelligence_market ON market_intelligence(market_area, market_type);\n",
    "CREATE INDEX idx_deal_alerts_product_retailer ON deal_alerts(product_id, retailer_id);\n",
    "CREATE INDEX idx_deal_alerts_status_date ON deal_alerts(deal_status, deal_start_date, deal_end_date);\n",
    "CREATE INDEX idx_deal_alerts_type ON deal_alerts(deal_type);\n",
    "CREATE INDEX idx_census_retail_year_month ON census_retail_data(year, month);\n",
    "CREATE INDEX idx_census_retail_naics ON census_retail_data(naics_code);\n",
    "CREATE INDEX idx_bls_price_year_period ON bls_price_data(year, period);\n",
    "CREATE INDEX idx_bls_price_category ON bls_price_data(product_category);\n",
    "CREATE INDEX idx_bls_price_series ON bls_price_data(series_id);\n",
    "CREATE INDEX idx_geographic_markets_type_code ON geographic_markets(market_type, market_code);\n",
    "CREATE INDEX idx_geographic_markets_geom ON geographic_markets USING GIST(market_geom);\n",
    "CREATE INDEX idx_pipeline_metadata_source_date ON pipeline_metadata(source_id, extraction_date);\n",
    "CREATE INDEX idx_pipeline_metadata_status ON pipeline_metadata(status, start_time);\n",
    "\"\"\"\n",
    "def execute_schema_sql(connection):\n",
    "    \"\"\"Execute embedded schema SQL.\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "    # Split by semicolons and execute each statement\n",
    "        statements = [s.strip() for s in SCHEMA_SQL.split(';') if s.strip()]\n",
    "        for idx, statement in enumerate(statements, 1):\n",
    "    if statement:\n",
    "                try:\n",
    "    cursor.execute(statement)\n",
    "                    print(f\"  ‚úÖ Executed statement {idx}/{len(statements)}\")\n",
    "                except Exception as e:\n",
    "    error_msg = str(e)[:100]\n",
    "                    print(f\"  ‚ö†Ô∏è  Statement {idx} warning: {error_msg}\")\n",
    "        connection.commit()\n",
    "        print(\"\\n‚úÖ Schema loaded successfully!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "    connection.rollback()\n",
    "        print(f\"\\n‚ùå Error loading schema: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        cursor.close()\n",
    "# Auto-execute if connection exists\n",
    "if 'conn' in globals():\n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING EMBEDDED SCHEMA\")\n",
    "    print(\"=\"*80)\n",
    "    execute_schema_sql(conn)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Database connection not found. Run connection cell first.\")\n",
    "    print(\"   Schema SQL is available in SCHEMA_SQL variable\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EMBEDDED DATA.SQL - DB-10\n",
    "# ============================================================================\n",
    "# This cell contains sample data for the database\n",
    "# Execute this cell to load data into PostgreSQL\n",
    "import psycopg2\n",
    "# Data SQL (embedded directly in notebook)\n",
    "DATA_SQL = \"\"\"\n",
    "-- Shopping Aggregator Database Sample Data\n",
    "-- Production sample data for marketing intelligence and retail inventory tracking system\n",
    "-- Compatible with PostgreSQL, Databricks, and Snowflake\n",
    "-- Insert Retailers\n",
    "INSERT INTO retailers (retailer_id, retailer_name, retailer_type, website_url, headquarters_city, headquarters_state, headquarters_zip, market_coverage, founded_year, employee_count) VALUES\n",
    "('RTL001', 'Walmart', 'big_box', 'https://www.walmart.com', 'Bentonville', 'AR', '72716', 'national', 1962, 2100000),\n",
    "('RTL002', 'Target', 'big_box', 'https://www.target.com', 'Minneapolis', 'MN', '55403', 'national', 1902, 450000),\n",
    "('RTL003', 'Amazon', 'online', 'https://www.amazon.com', 'Seattle', 'WA', '98101', 'international', 1994, 1500000),\n",
    "('RTL004', 'Home Depot', 'specialty', 'https://www.homedepot.com', 'Atlanta', 'GA', '30339', 'national', 1978, 500000),\n",
    "('RTL005', 'Lowe''s', 'specialty', 'https://www.lowes.com', 'Mooresville', 'NC', '28117', 'national', 1946, 300000),\n",
    "('RTL006', 'Best Buy', 'specialty', 'https://www.bestbuy.com', 'Richfield', 'MN', '55423', 'national', 1966, 125000),\n",
    "('RTL007', 'Costco', 'warehouse', 'https://www.costco.com', 'Issaquah', 'WA', '98027', 'international', 1983, 304000),\n",
    "('RTL008', 'CVS', 'specialty', 'https://www.cvs.com', 'Woonsocket', 'RI', '02895', 'national', 1963, 300000),\n",
    "('RTL009', 'Walgreens', 'specialty', 'https://www.walgreens.com', 'Deerfield', 'IL', '60015', 'national', 1901, 315000),\n",
    "('RTL010', 'Macy''s', 'department_store', 'https://www.macys.com', 'New York', 'NY', '10001', 'national', 1858, 130000);\n",
    "-- Insert Stores (sample locations across major cities)\n",
    "INSERT INTO stores (store_id, retailer_id, store_name, store_number, store_address, store_city, store_state, store_zip, store_county, store_latitude, store_longitude, store_type, store_size_sqft, opening_date, store_status) VALUES\n",
    "('STR001', 'RTL001', 'Walmart Supercenter', '1234', '123 Main Street', 'New York', 'NY', '10001', 'New York', 40.7128, -74.0060, 'supercenter', 180000, '2010-01-15', 'open'),\n",
    "('STR002', 'RTL001', 'Walmart Supercenter', '5678', '456 Oak Avenue', 'Los Angeles', 'CA', '90001', 'Los Angeles', 34.0522, -118.2437, 'supercenter', 180000, '2012-03-20', 'open'),\n",
    "('STR003', 'RTL002', 'Target Store', '9012', '789 Pine Road', 'Chicago', 'IL', '60601', 'Cook', 41.8781, -87.6298, 'supercenter', 130000, '2015-06-10', 'open'),\n",
    "('STR004', 'RTL002', 'Target Store', '3456', '321 Elm Street', 'Houston', 'TX', '77001', 'Harris', 29.7604, -95.3698, 'supercenter', 130000, '2014-09-05', 'open'),\n",
    "('STR005', 'RTL004', 'Home Depot', '7890', '654 Maple Drive', 'Phoenix', 'AZ', '85001', 'Maricopa', 33.4484, -112.0740, 'supercenter', 105000, '2011-11-12', 'open'),\n",
    "('STR006', 'RTL005', 'Lowe''s Home Improvement', '2468', '987 Cedar Lane', 'Philadelphia', 'PA', '19101', 'Philadelphia', 39.9526, -75.1652, 'supercenter', 110000, '2013-04-18', 'open'),\n",
    "('STR007', 'RTL006', 'Best Buy', '1357', '147 Birch Boulevard', 'San Antonio', 'TX', '78201', 'Bexar', 29.4241, -98.4936, 'supercenter', 45000, '2016-08-22', 'open'),\n",
    "('STR008', 'RTL007', 'Costco Wholesale', '8024', '258 Spruce Way', 'San Diego', 'CA', '92101', 'San Diego', 32.7157, -117.1611, 'warehouse', 150000, '2010-12-03', 'open'),\n",
    "('STR009', 'RTL008', 'CVS Pharmacy', '4680', '369 Willow Court', 'Dallas', 'TX', '75201', 'Dallas', 32.7767, -96.7970, 'neighborhood', 12000, '2017-02-14', 'open'),\n",
    "('STR010', 'RTL009', 'Walgreens', '5791', '741 Ash Street', 'San Jose', 'CA', '95101', 'Santa Clara', 37.3382, -121.8863, 'neighborhood', 14000, '2018-05-30', 'open');\n",
    "-- Insert Products (sample products across categories)\n",
    "INSERT INTO products (product_id, sku, upc, product_name, brand, manufacturer, model_number, category, subcategory, product_description, weight_lbs, color, is_active) VALUES\n",
    "('PRD001', 'SKU-001', '012345678901', '55\" 4K Smart TV', 'Samsung', 'Samsung Electronics', 'UN55AU8000FXZA', 'Electronics', 'Televisions', '55-inch 4K UHD Smart TV with HDR', 35.5, 'Black', TRUE),\n",
    "('PRD002', 'SKU-002', '012345678902', 'iPhone 15 Pro', 'Apple', 'Apple Inc.', 'A2848', 'Electronics', 'Smartphones', '6.1-inch iPhone 15 Pro with A17 Pro chip', 0.4, 'Natural Titanium', TRUE),\n",
    "('PRD003', 'SKU-003', '012345678903', 'Nike Air Max 270', 'Nike', 'Nike Inc.', 'AH8050-100', 'Apparel', 'Footwear', 'Men''s running shoes with Air Max cushioning', 1.2, 'White/Black', TRUE),\n",
    "('PRD004', 'SKU-004', '012345678904', 'KitchenAid Stand Mixer', 'KitchenAid', 'Whirlpool Corporation', 'KSM150PSER', 'Home & Kitchen', 'Small Appliances', '5-quart stand mixer with 10 speeds', 26.0, 'Empire Red', TRUE),\n",
    "('PRD005', 'SKU-005', '012345678905', 'LEGO Star Wars Set', 'LEGO', 'LEGO Group', '75313', 'Toys & Games', 'Building Sets', 'AT-AT Walker building set with 1267 pieces', 4.8, 'Multi-color', TRUE),\n",
    "('PRD006', 'SKU-006', '012345678906', 'Dyson V15 Detect', 'Dyson', 'Dyson Ltd', '394786-01', 'Home & Kitchen', 'Vacuum Cleaners', 'Cordless vacuum with laser technology', 7.8, 'Yellow/Nickel', TRUE),\n",
    "('PRD007', 'SKU-007', '012345678907', 'Sony WH-1000XM5 Headphones', 'Sony', 'Sony Corporation', 'WH1000XM5', 'Electronics', 'Audio', 'Wireless noise-canceling headphones', 0.6, 'Black', TRUE),\n",
    "('PRD008', 'SKU-008', '012345678908', 'Instant Pot Duo', 'Instant Pot', 'Instant Brands', 'DUO60', 'Home & Kitchen', 'Pressure Cookers', '6-quart 7-in-1 pressure cooker', 11.6, 'Stainless Steel', TRUE),\n",
    "('PRD009', 'SKU-009', '012345678909', 'Nintendo Switch OLED', 'Nintendo', 'Nintendo Co Ltd', 'HEG-001', 'Electronics', 'Gaming Consoles', 'Nintendo Switch with OLED screen', 0.9, 'White', TRUE),\n",
    "('PRD010', 'SKU-010', '012345678910', 'Yeti Tundra 45 Cooler', 'Yeti', 'Yeti Holdings', 'YETI-45', 'Outdoor', 'Coolers', '45-quart hard cooler with T-Rex lid latches', 23.0, 'Seafoam', TRUE);\n",
    "-- Insert Product Inventory\n",
    "INSERT INTO product_inventory (inventory_id, product_id, store_id, stock_level, stock_status, available_quantity, last_checked_at, data_source, confidence_score) VALUES\n",
    "('INV001', 'PRD001', 'STR001', 15, 'in_stock', 15, CURRENT_TIMESTAMP(), 'api', 95.0),\n",
    "('INV002', 'PRD001', 'STR002', 8, 'low_stock', 8, CURRENT_TIMESTAMP(), 'api', 95.0),\n",
    "('INV003', 'PRD002', 'STR007', 25, 'in_stock', 25, CURRENT_TIMESTAMP(), 'api', 98.0),\n",
    "('INV004', 'PRD002', 'STR001', 0, 'out_of_stock', 0, CURRENT_TIMESTAMP(), 'api', 95.0),\n",
    "('INV005', 'PRD003', 'STR003', 42, 'in_stock', 42, CURRENT_TIMESTAMP(), 'scraper', 90.0),\n",
    "('INV006', 'PRD004', 'STR005', 12, 'in_stock', 12, CURRENT_TIMESTAMP(), 'api', 92.0),\n",
    "('INV007', 'PRD005', 'STR001', 30, 'in_stock', 30, CURRENT_TIMESTAMP(), 'api', 95.0),\n",
    "('INV008', 'PRD006', 'STR004', 5, 'low_stock', 5, CURRENT_TIMESTAMP(), 'scraper', 88.0),\n",
    "('INV009', 'PRD007', 'STR007', 18, 'in_stock', 18, CURRENT_TIMESTAMP(), 'api', 98.0),\n",
    "('INV010', 'PRD008', 'STR005', 20, 'in_stock', 20, CURRENT_TIMESTAMP(), 'api', 92.0);\n",
    "-- Insert Product Pricing\n",
    "INSERT INTO product_pricing (pricing_id, product_id, retailer_id, store_id, current_price, original_price, sale_price, discount_percentage, price_effective_date, price_expiry_date, price_type, price_source, price_confidence_score, is_online_price) VALUES\n",
    "('PRC001', 'PRD001', 'RTL001', 'STR001', 449.99, 599.99, 449.99, 25.00, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '7 days', 'sale', 'api', 95.0, FALSE),\n",
    "('PRC002', 'PRD001', 'RTL002', 'STR003', 479.99, 599.99, 479.99, 20.00, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '5 days', 'sale', 'api', 95.0, FALSE),\n",
    "('PRC003', 'PRD002', 'RTL003', NULL, 999.00, 999.00, NULL, 0.00, CURRENT_TIMESTAMP(), NULL, 'regular', 'api', 99.0, TRUE),\n",
    "('PRC004', 'PRD002', 'RTL006', 'STR007', 999.00, 999.00, NULL, 0.00, CURRENT_TIMESTAMP(), NULL, 'regular', 'api', 98.0, FALSE),\n",
    "('PRC005', 'PRD003', 'RTL002', 'STR003', 119.99, 150.00, 119.99, 20.00, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '10 days', 'sale', 'scraper', 90.0, FALSE),\n",
    "('PRC006', 'PRD004', 'RTL004', 'STR005', 329.99, 379.99, 329.99, 13.16, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '14 days', 'sale', 'api', 92.0, FALSE),\n",
    "('PRC007', 'PRD005', 'RTL001', 'STR001', 89.99, 89.99, NULL, 0.00, CURRENT_TIMESTAMP(), NULL, 'regular', 'api', 95.0, FALSE),\n",
    "('PRC008', 'PRD006', 'RTL002', 'STR004', 699.99, 749.99, 699.99, 6.67, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '3 days', 'sale', 'scraper', 88.0, FALSE),\n",
    "('PRC009', 'PRD007', 'RTL006', 'STR007', 399.99, 399.99, NULL, 0.00, CURRENT_TIMESTAMP(), NULL, 'regular', 'api', 98.0, FALSE),\n",
    "('PRC010', 'PRD008', 'RTL003', NULL, 89.99, 99.99, 89.99, 10.00, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '7 days', 'sale', 'api', 99.0, TRUE);\n",
    "-- Insert Deal Alerts\n",
    "INSERT INTO deal_alerts (deal_id, product_id, retailer_id, store_id, deal_type, discount_percentage, discount_amount, deal_price, original_price, deal_start_date, deal_end_date, deal_status, deal_description, deal_source, is_online_deal) VALUES\n",
    "('DEAL001', 'PRD001', 'RTL001', 'STR001', 'sale', 25.00, 150.00, 449.99, 599.99, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '7 days', 'active', '25% off Samsung 55\" 4K Smart TV', 'api', FALSE),\n",
    "('DEAL002', 'PRD003', 'RTL002', 'STR003', 'sale', 20.00, 30.01, 119.99, 150.00, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '10 days', 'active', '20% off Nike Air Max 270', 'scraper', FALSE),\n",
    "('DEAL003', 'PRD008', 'RTL003', NULL, 'sale', 10.00, 10.00, 89.99, 99.99, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '7 days', 'active', '10% off Instant Pot Duo', 'api', TRUE),\n",
    "('DEAL004', 'PRD004', 'RTL004', 'STR005', 'sale', 13.16, 50.00, 329.99, 379.99, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '14 days', 'active', 'Save $50 on KitchenAid Stand Mixer', 'api', FALSE),\n",
    "('DEAL005', 'PRD006', 'RTL002', 'STR004', 'sale', 6.67, 50.00, 699.99, 749.99, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP() + INTERVAL '3 days', 'active', 'Limited time: $50 off Dyson V15 Detect', 'scraper', FALSE);\n",
    "-- Insert Census Retail Data (sample monthly data)\n",
    "INSERT INTO census_retail_data (census_id, naics_code, industry_category, month, year, retail_sales_amount, inventory_amount, store_count, employment_count, sales_change_percent, inventory_change_percent, data_source) VALUES\n",
    "('CNS001', '441110', 'New Car Dealers', 1, 2024, 125000.00, 45000.00, 16500, 1250000, 2.5, 1.2, 'CENSUS_MRTS'),\n",
    "('CNS002', '442110', 'Furniture Stores', 1, 2024, 8500.00, 12000.00, 22000, 185000, -1.3, 0.8, 'CENSUS_MRTS'),\n",
    "('CNS003', '443141', 'Household Appliance Stores', 1, 2024, 3200.00, 2800.00, 15000, 95000, 3.1, 2.5, 'CENSUS_MRTS'),\n",
    "('CNS004', '451110', 'Sporting Goods Stores', 1, 2024, 4200.00, 5800.00, 18000, 120000, 1.8, 1.1, 'CENSUS_MRTS'),\n",
    "('CNS005', '452210', 'Department Stores', 1, 2024, 18500.00, 32000.00, 8500, 650000, -0.5, -0.3, 'CENSUS_MRTS');\n",
    "-- Insert BLS Price Data (sample CPI data)\n",
    "INSERT INTO bls_price_data (bls_id, series_id, product_category, period, year, price_index_value, percent_change, percent_change_year_ago, base_period, index_type, data_source) VALUES\n",
    "('BLS001', 'CUUR0000SA0', 'All Items', 'M01', 2024, 308.417, 0.3, 3.1, '1982-84=100', 'CPI_U', 'BLS_API'),\n",
    "('BLS002', 'CUUR0000SETB01', 'Televisions', 'M01', 2024, 12.456, -2.1, -8.5, '1997=100', 'CPI_U', 'BLS_API'),\n",
    "('BLS003', 'CUUR0000SEEE01', 'Smartphones', 'M01', 2024, 45.123, -1.2, -5.3, '1997=100', 'CPI_U', 'BLS_API'),\n",
    "('BLS004', 'CUUR0000SEGA', 'Apparel', 'M01', 2024, 125.789, 0.5, 1.2, '1982-84=100', 'CPI_U', 'BLS_API'),\n",
    "('BLS005', 'CUUR0000SEHF', 'Household Furnishings', 'M01', 2024, 98.234, 0.2, 0.8, '1982-84=100', 'CPI_U', 'BLS_API');\n",
    "-- Insert Geographic Markets\n",
    "INSERT INTO geographic_markets (market_id, market_name, market_type, market_code, population, median_income, market_size, state_code, county_name, data_source) VALUES\n",
    "('MKT001', 'New York City', 'city', 'NYC', 8336817, 67240.00, 302.6, 'NY', 'New York', 'CENSUS'),\n",
    "('MKT002', 'Los Angeles', 'city', 'LA', 3967000, 65000.00, 502.7, 'CA', 'Los Angeles', 'CENSUS'),\n",
    "('MKT003', '10001', 'zip', '10001', 45000, 85000.00, 0.8, 'NY', 'New York', 'CENSUS'),\n",
    "('MKT004', '90001', 'zip', '90001', 62000, 42000.00, 1.2, 'CA', 'Los Angeles', 'CENSUS'),\n",
    "('MKT005', 'New York', 'state', 'NY', 20201249, 72000.00, 54555.0, 'NY', NULL, 'CENSUS');\n",
    "-- Insert Data Sources\n",
    "INSERT INTO data_sources (source_id, source_name, source_type, api_endpoint, api_key_required, rate_limit_per_hour, rate_limit_per_day, sync_frequency, data_quality_score, is_active) VALUES\n",
    "('SRC001', 'Census Bureau MRTS API', 'api', 'http://api.census.gov/data/timeseries/eits/mrts', FALSE, 500, 5000, 'monthly', 98.0, TRUE),\n",
    "('SRC002', 'BLS Public Data API', 'api', 'https://api.bls.gov/publicAPI/v2', FALSE, 500, 5000, 'monthly', 99.0, TRUE),\n",
    "('SRC003', 'Data.gov CKAN API', 'api', 'https://catalog.data.gov/api/3/action', FALSE, 1000, 10000, 'daily', 95.0, TRUE),\n",
    "('SRC004', 'Retailer Web Scraper', 'scraper', NULL, FALSE, 100, 1000, 'daily', 85.0, TRUE),\n",
    "('SRC005', 'Manual Entry', 'manual', NULL, FALSE, NULL, NULL, 'manual', 100.0, TRUE);\n",
    "-- Insert Pipeline Metadata (sample execution log)\n",
    "INSERT INTO pipeline_metadata (pipeline_id, source_id, extraction_date, pipeline_type, records_processed, records_successful, records_failed, processing_duration_seconds, status, start_time, end_time) VALUES\n",
    "('PIP001', 'SRC001', CURRENT_TIMESTAMP(), 'full', 5000, 4950, 50, 120, 'success', CURRENT_TIMESTAMP() - INTERVAL '2 minutes', CURRENT_TIMESTAMP()),\n",
    "('PIP002', 'SRC002', CURRENT_TIMESTAMP(), 'full', 3000, 3000, 0, 45, 'success', CURRENT_TIMESTAMP() - INTERVAL '1 minute', CURRENT_TIMESTAMP()),\n",
    "('PIP003', 'SRC004', CURRENT_TIMESTAMP(), 'extract', 10000, 9800, 200, 300, 'partial', CURRENT_TIMESTAMP() - INTERVAL '5 minutes', CURRENT_TIMESTAMP());\n",
    "\"\"\"\n",
    "def execute_data_sql(connection):\n",
    "    \"\"\"Execute embedded data SQL.\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "    # Split by semicolons and execute each statement\n",
    "        statements = [s.strip() for s in DATA_SQL.split(';') if s.strip()]\n",
    "        for idx, statement in enumerate(statements, 1):\n",
    "    if statement:\n",
    "                try:\n",
    "    cursor.execute(statement)\n",
    "                    print(f\"  ‚úÖ Executed statement {idx}/{len(statements)}\")\n",
    "                except Exception as e:\n",
    "    error_msg = str(e)[:100]\n",
    "                    print(f\"  ‚ö†Ô∏è  Statement {idx} warning: {error_msg}\")\n",
    "        connection.commit()\n",
    "        print(\"\\n‚úÖ Data loaded successfully!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "    connection.rollback()\n",
    "        print(f\"\\n‚ùå Error loading data: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        cursor.close()\n",
    "# Auto-execute if connection exists\n",
    "if 'conn' in globals():\n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING EMBEDDED DATA\")\n",
    "    print(\"=\"*80)\n",
    "    execute_data_sql(conn)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Database connection not found. Run connection cell first.\")\n",
    "    print(\"   Data SQL is available in DATA_SQL variable\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EMBEDDED QUERIES.JSON - DB-10\n",
    "# ============================================================================\n",
    "# This cell contains all query metadata embedded directly in the notebook\n",
    "# No external file dependencies required\n",
    "import json\n",
    "# Queries data (embedded directly in notebook)\n",
    "QUERIES_DATA = {\n",
    "  \"source_file\": \"/Users/machine/Documents/AQ/db/db-10/queries/queries.md\",\n",
    "  \"extraction_timestamp\": \"20260208-2109\",\n",
    "  \"total_queries\": 30,\n",
    "  \"queries\": [\n",
    "    {\n",
    "      \"number\": 1,\n",
    "      \"title\": \"Multi-Retailer Price Comparison with Geographic Filtering and Temporal Trend Analysis\",\n",
    "      \"description\": \"Description: Analyzes pricing across multiple retailers for products within geographic markets, incorporating temporal trends, price volatility metrics, and competitive positioning. Uses multiple CTEs to aggregate pricing data, calculate price differences, identify best deals, and track price movements over time with window functions. Use Case:\n",
    "    Competitive pricing analysis for retail intelligence platforms - identify best prices by location and track price trends over time Business Value: Enable\",\n",
    "      \"complexity\": \"Deep nested CTEs (6+ levels), multiple joins across products/retailers/stores/pricing tables, window functions with frame clauses, percentile calculations, temporal aggregations, geographic filtering, correlated subqueries\",\n",
    "      \"expected_output\": \"Product pricing comparison report showing best prices by retailer and location, price trends, and competitive positioning metrics\",\n",
    "      \"sql\": \"WITH product_base_pricing AS (\\n    -- First CTE: Base pricing data with product and retailer information\\n    SELECT\\n        pp.pricing_id,\\n        pp.product_id,\\n        pp.retailer_id,\\n        pp.store_id,\\n        p.product_name,\\n        p.brand,\\n        p.category,\\n        p.subcategory,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_city,\\n        s.store_state,\\n        s.store_zip,\\n        s.store_latitude,\\n        s.store_longitude,\\n        pp.current_price,\\n        pp.original_price,\\n        pp.sale_price,\\n        pp.discount_percentage,\\n        pp.price_effective_date,\\n        pp.price_expiry_date,\\n        pp.price_type,\\n        pp.is_online_price,\\n        pp.price_confidence_score\\n    FROM product_pricing pp\\n    INNER JOIN products p ON pp.product_id = p.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    WHERE pp.price_effective_date >= CURRENT_DATE - INTERVAL '90 days'\\n        AND p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n),\\ngeographic_market_mapping AS (\\n    -- Second CTE: Map stores to geographic markets\\n    SELECT\\n        pbp.*,\\n        gm.market_id,\\n        gm.market_name,\\n        gm.market_type,\\n        gm.market_code,\\n        gm.population,\\n        gm.median_income,\\n        CASE\\n            WHEN gm.market_geom IS NOT NULL AND s.store_geom IS NOT NULL THEN\\n                CASE\\n                    WHEN ST_Within(s.store_geom::geometry, gm.market_geom::geometry) THEN TRUE\\n                    ELSE FALSE\\n                END\\n            WHEN gm.market_type = 'zip' AND s.store_zip = gm.market_code THEN TRUE\\n            WHEN gm.market_type = 'city' AND s.store_city = gm.market_name AND s.store_state = gm.state_code THEN TRUE\\n            WHEN gm.market_type = 'state' AND s.store_state = gm.state_code THEN TRUE\\n            ELSE FALSE\\n        END AS is_in_market\\n    FROM product_base_pricing pbp\\n    LEFT JOIN stores s ON pbp.store_id = s.store_id\\n    LEFT JOIN geographic_markets gm ON (\\n        (gm.market_type = 'zip' AND s.store_zip = gm.market_code)\\n        OR (gm.market_type = 'city' AND s.store_city = gm.market_name AND s.store_state = gm.state_code)\\n        OR (gm.market_type = 'state' AND s.store_state = gm.state_code)\\n        OR (gm.market_geom IS NOT NULL AND s.store_geom IS NOT NULL AND ST_Within(s.store_geom::geometry, gm.market_geom::geometry))\\n    )\\n    WHERE pbp.store_id IS NOT NULL OR pbp.is_online_price = TRUE\\n),\\nmarket_pricing_aggregates AS (\\n    -- Third CTE: Aggregate pricing by market and product\\n    SELECT\\n        gmm.product_id,\\n        gmm.product_name,\\n        gmm.brand,\\n        gmm.category,\\n        gmm.market_id,\\n        gmm.market_name,\\n        gmm.market_type,\\n        gmm.population,\\n        gmm.median_income,\\n        COUNT(DISTINCT gmm.retailer_id) AS retailer_count,\\n        COUNT(DISTINCT gmm.store_id) AS store_count,\\n        COUNT(DISTINCT CASE WHEN gmm.is_online_price = FALSE THEN gmm.store_id END) AS physical_store_count,\\n        COUNT(DISTINCT CASE WHEN gmm.is_online_price = TRUE THEN gmm.retailer_id END) AS online_retailer_count,\\n        MIN(gmm.current_price) AS min_price,\\n        MAX(gmm.current_price) AS max_price,\\n        AVG(gmm.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY gmm.current_price) AS median_price,\\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY gmm.current_price) AS q1_price,\\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY gmm.current_price) AS q3_price,\\n        STDDEV(gmm.current_price) AS price_std_dev,\\n        AVG(gmm.discount_percentage) AS avg_discount_percentage,\\n        COUNT(CASE WHEN gmm.price_type = 'sale' THEN 1 END) AS sale_count,\\n        COUNT(CASE WHEN gmm.price_type = 'clearance' THEN 1 END) AS clearance_count\\n    FROM geographic_market_mapping gmm\\n    WHERE gmm.is_in_market = TRUE OR gmm.is_online_price = TRUE\\n    GROUP BY\\n        gmm.product_id,\\n        gmm.product_name,\\n        gmm.brand,\\n        gmm.category,\\n        gmm.market_id,\\n        gmm.market_name,\\n        gmm.market_type,\\n        gmm.population,\\n        gmm.median_income\\n),\\nretailer_market_positioning AS (\\n    -- Fourth CTE: Calculate retailer positioning within each market\\n    SELECT\\n        mpa.*,\\n        gmm.retailer_id,\\n        gmm.retailer_name,\\n        gmm.retailer_type,\\n        gmm.current_price AS retailer_price,\\n        gmm.price_type AS retailer_price_type,\\n        gmm.discount_percentage AS retailer_discount,\\n        CASE\\n            WHEN gmm.current_price = mpa.min_price THEN 'lowest'\\n            WHEN gmm.current_price <= mpa.q1_price THEN 'low'\\n            WHEN gmm.current_price <= mpa.median_price THEN 'below_median'\\n            WHEN gmm.current_price <= mpa.q3_price THEN 'above_median'\\n            WHEN gmm.current_price = mpa.max_price THEN 'highest'\\n            ELSE 'high'\\n        END AS price_position,\\n        (gmm.current_price - mpa.min_price) AS price_difference_from_min,\\n        ((gmm.current_price - mpa.min_price) / NULLIF(mpa.min_price, 0)) * 100 AS price_premium_percentage,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY mpa.product_id, mpa.market_id\\n            ORDER BY gmm.current_price ASC\\n        ) AS price_rank\\n    FROM market_pricing_aggregates mpa\\n    INNER JOIN geographic_market_mapping gmm ON mpa.product_id = gmm.product_id\\n        AND mpa.market_id = gmm.market_id\\n    WHERE gmm.is_in_market = TRUE OR gmm.is_online_price = TRUE\\n),\\ntemporal_price_trends AS (\\n    -- Fifth CTE: Analyze price trends over time with window functions\\n    SELECT\\n        rmp.*,\\n        gmm.price_effective_date,\\n        LAG(gmm.current_price, 1) OVER (\\n            PARTITION BY rmp.product_id, rmp.retailer_id, rmp.market_id\\n            ORDER BY gmm.price_effective_date\\n        ) AS prev_price,\\n        LEAD(gmm.current_price, 1) OVER (\\n            PARTITION BY rmp.product_id, rmp.retailer_id, rmp.market_id\\n            ORDER BY gmm.price_effective_date\\n        ) AS next_price,\\n        AVG(gmm.current_price) OVER (\\n            PARTITION BY rmp.product_id, rmp.retailer_id, rmp.market_id\\n            ORDER BY gmm.price_effective_date\\n            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_price_7d,\\n        STDDEV(gmm.current_price) OVER (\\n            PARTITION BY rmp.product_id, rmp.retailer_id, rmp.market_id\\n            ORDER BY gmm.price_effective_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_30d,\\n        MIN(gmm.current_price) OVER (\\n            PARTITION BY rmp.product_id, rmp.retailer_id, rmp.market_id\\n            ORDER BY gmm.price_effective_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS min_price_30d,\\n        MAX(gmm.current_price) OVER (\\n            PARTITION BY rmp.product_id, rmp.retailer_id, rmp.market_id\\n            ORDER BY gmm.price_effective_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS max_price_30d\\n    FROM retailer_market_positioning rmp\\n    INNER JOIN geographic_market_mapping gmm ON rmp.product_id = gmm.product_id\\n        AND rmp.retailer_id = gmm.retailer_id\\n        AND rmp.market_id = gmm.market_id\\n),\\nfinal_price_intelligence AS (\\n    -- Sixth CTE: Final analytics with comprehensive metrics\\n    SELECT\\n        tpt.product_id,\\n        tpt.product_name,\\n        tpt.brand,\\n        tpt.category,\\n        tpt.market_id,\\n        tpt.market_name,\\n        tpt.market_type,\\n        tpt.population,\\n        tpt.median_income,\\n        tpt.retailer_id,\\n        tpt.retailer_name,\\n        tpt.retailer_type,\\n        tpt.retailer_price,\\n        tpt.price_position,\\n        tpt.price_rank,\\n        tpt.price_difference_from_min,\\n        ROUND(CAST(tpt.price_premium_percentage AS NUMERIC), 2) AS price_premium_percentage,\\n        tpt.retailer_price_type,\\n        tpt.retailer_discount,\\n        tpt.retailer_count,\\n        tpt.store_count,\\n        tpt.physical_store_count,\\n        tpt.online_retailer_count,\\n        tpt.min_price,\\n        tpt.max_price,\\n        ROUND(CAST(tpt.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(tpt.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(tpt.price_std_dev AS NUMERIC), 2) AS price_std_dev,\\n        ROUND(CAST(tpt.avg_discount_percentage AS NUMERIC), 2) AS avg_discount_percentage,\\n        tpt.sale_count,\\n        tpt.clearance_count,\\n        tpt.price_effective_date,\\n        tpt.prev_price,\\n        tpt.next_price,\\n        CASE\\n            WHEN tpt.prev_price IS NOT NULL THEN tpt.retailer_price - tpt.prev_price\\n            ELSE NULL\\n        END AS price_change,\\n        CASE\\n            WHEN tpt.prev_price IS NOT NULL AND tpt.prev_price != 0 THEN\\n                ((tpt.retailer_price - tpt.prev_price) / tpt.prev_price) * 100\\n            ELSE NULL\\n        END AS price_change_percentage,\\n        ROUND(CAST(tpt.moving_avg_price_7d AS NUMERIC), 2) AS moving_avg_price_7d,\\n        ROUND(CAST(tpt.price_volatility_30d AS NUMERIC), 2) AS price_volatility_30d,\\n        tpt.min_price_30d,\\n        tpt.max_price_30d,\\n        CASE\\n            WHEN tpt.retailer_price <= tpt.min_price_30d THEN 'at_30d_low'\\n            WHEN tpt.retailer_price >= tpt.max_price_30d THEN 'at_30d_high'\\n            ELSE 'mid_range'\\n        END AS price_position_30d\\n    FROM temporal_price_trends tpt\\n)\\nSELECT\\n    product_name,\\n    brand,\\n    category,\\n    market_name,\\n    market_type,\\n    retailer_name,\\n    retailer_type,\\n    retailer_price,\\n    price_position,\\n    price_rank,\\n    price_premium_percentage,\\n    retailer_discount,\\n    avg_price,\\n    median_price,\\n    min_price,\\n    max_price,\\n    price_change_percentage,\\n    moving_avg_price_7d,\\n    price_volatility_30d,\\n    price_position_30d,\\n    retailer_count,\\n    store_count,\\n    physical_store_count,\\n    online_retailer_count\\nFROM final_price_intelligence\\nWHERE price_rank <= 5\\nORDER BY\\n    product_id,\\n    market_id,\\n    price_rank;\",\n",
    "      \"line_number\": 197,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.015653,\n",
    "        \"row_count\": 4,\n",
    "        \"column_count\": 24,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 2,\n",
    "      \"title\": \"Inventory Availability Prediction Using Historical Patterns and Geographic Distribution\",\n",
    "      \"description\": \"Description: Predicts inventory availability by analyzing historical stock patterns, restocking frequencies, seasonal trends, and geographic distribution. Uses recursive CTEs for pattern detection, window functions for trend analysis, and complex aggregations to forecast stock levels. Use Case:\n",
    "    Inventory forecasting for retail operations - predict when products will be in stock and optimize restocking schedules Business Value: Enables retailers to optimize inventory management, reduce stockouts,\",\n",
    "      \"complexity\": \"Recursive CTEs for pattern detection, multiple CTEs (7+ levels), window functions with complex frame clauses, temporal aggregations, geographic clustering, statistical forecasting calculations\",\n",
    "      \"expected_output\":\n",
    "    \"Inventory availability predictions with confidence scores, restocking recommendations, and geographic distribution analysis\",\n",
    "      \"sql\": \"WITH RECURSIVE inventory_history AS (\\n    -- Base case: Current inventory state\\n    SELECT\\n        pi.inventory_id,\\n        pi.product_id,\\n        pi.store_id,\\n        pi.stock_level,\\n        pi.stock_status,\\n        pi.available_quantity,\\n        pi.last_checked_at,\\n        pi.last_restocked_at,\\n        p.product_name,\\n        p.category,\\n        s.store_city,\\n        s.store_state,\\n        s.retailer_id,\\n        r.retailer_name,\\n        DATE_TRUNC('day', pi.last_checked_at) AS check_date,\\n        EXTRACT(DOW FROM pi.last_checked_at) AS day_of_week,\\n        EXTRACT(MONTH FROM pi.last_checked_at) AS month_num\\n    FROM product_inventory pi\\n    INNER JOIN products p ON pi.product_id = p.product_id\\n    INNER JOIN stores s ON pi.store_id = s.store_id\\n    INNER JOIN retailers r ON s.retailer_id = r.retailer_id\\n    WHERE pi.last_checked_at >= CURRENT_TIMESTAMP - INTERVAL '180 days'\\n        AND p.is_active = TRUE\\n    \\n    UNION ALL\\n    \\n    -- Recursive case: Historical inventory states (simulated from check history)\\n    SELECT\\n        ih.inventory_id,\\n        ih.product_id,\\n        ih.store_id,\\n        CASE\\n            WHEN ih.stock_status = 'out_of_stock' AND ih.last_restocked_at IS NOT NULL THEN\\n                CASE\\n                    WHEN ih.last_restocked_at > ih.last_checked_at - INTERVAL '7 days' THEN 50\\n                    ELSE 0\\n                END\\n            ELSE ih.stock_level\\n        END AS stock_level,\\n        ih.stock_status,\\n        ih.available_quantity,\\n        ih.last_checked_at - INTERVAL '1 day' AS last_checked_at,\\n        ih.last_restocked_at,\\n        ih.product_name,\\n        ih.category,\\n        ih.store_city,\\n        ih.store_state,\\n        ih.retailer_id,\\n        ih.retailer_name,\\n        DATE_TRUNC('day', ih.last_checked_at - INTERVAL '1 day') AS check_date,\\n        EXTRACT(DOW FROM ih.last_checked_at - INTERVAL '1 day') AS day_of_week,\\n        EXTRACT(MONTH FROM ih.last_checked_at - INTERVAL '1 day') AS month_num\\n    FROM inventory_history ih\\n    WHERE ih.last_checked_at > CURRENT_TIMESTAMP - INTERVAL '180 days'\\n),\\ninventory_patterns AS (\\n    -- Second CTE: Identify inventory patterns and cycles\\n    SELECT\\n        product_id,\\n        store_id,\\n        product_name,\\n        category,\\n        store_city,\\n        store_state,\\n        retailer_id,\\n        retailer_name,\\n        check_date,\\n        day_of_week,\\n        month_num,\\n        stock_level,\\n        stock_status,\\n        available_quantity,\\n        last_checked_at,\\n        last_restocked_at,\\n        COUNT(*) OVER (\\n            PARTITION BY product_id, store_id\\n            ORDER BY check_date\\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\\n        ) AS days_tracked,\\n        LAG(stock_level, 1) OVER (\\n            PARTITION BY product_id, store_id\\n            ORDER BY check_date\\n        ) AS prev_stock_level,\\n        LAG(stock_status, 1) OVER (\\n            PARTITION BY product_id, store_id\\n            ORDER BY check_date\\n        ) AS prev_stock_status,\\n        CASE\\n            WHEN stock_status = 'out_of_stock' AND LAG(stock_status, 1) OVER (\\n                PARTITION BY product_id, store_id ORDER BY check_date\\n            ) != 'out_of_stock' THEN 1\\n            ELSE 0\\n        END AS stockout_event,\\n        CASE\\n            WHEN stock_status != 'out_of_stock' AND LAG(stock_status, 1) OVER (\\n                PARTITION BY product_id, store_id ORDER BY check_date\\n            ) = 'out_of_stock' THEN 1\\n            ELSE 0\\n        END AS restock_event\\n    FROM inventory_history\\n),\\nstockout_analysis AS (\\n    -- Third CTE: Analyze stockout patterns and durations\\n    SELECT\\n        ip.*,\\n        SUM(ip.stockout_event) OVER (\\n            PARTITION BY ip.product_id, ip.store_id\\n            ORDER BY ip.check_date\\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\\n        ) AS stockout_count_cumulative,\\n        SUM(ip.restock_event) OVER (\\n            PARTITION BY ip.product_id, ip.store_id\\n            ORDER BY ip.check_date\\n            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\\n        ) AS restock_count_cumulative,\\n        CASE\\n            WHEN ip.stockout_event = 1 THEN\\n                ROW_NUMBER() OVER (\\n                    PARTITION BY ip.product_id, ip.store_id, ip.stockout_event\\n                    ORDER BY ip.check_date\\n                )\\n            ELSE NULL\\n        END AS stockout_period_id\\n    FROM inventory_patterns ip\\n),\\nstockout_durations AS (\\n    -- Fourth CTE: Calculate stockout durations\\n    SELECT\\n        sa.*,\\n        CASE\\n            WHEN sa.stockout_period_id IS NOT NULL THEN\\n                COUNT(*) OVER (\\n                    PARTITION BY sa.product_id, sa.store_id, sa.stockout_period_id\\n                )\\n            ELSE NULL\\n        END AS stockout_duration_days,\\n        AVG(sa.stock_level) OVER (\\n            PARTITION BY sa.product_id, sa.store_id\\n            ORDER BY sa.check_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS avg_stock_30d,\\n        STDDEV(sa.stock_level) OVER (\\n            PARTITION BY sa.product_id, sa.store_id\\n            ORDER BY sa.check_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS stock_volatility_30d,\\n        MIN(sa.stock_level) OVER (\\n            PARTITION BY sa.product_id, sa.store_id\\n            ORDER BY sa.check_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS min_stock_30d,\\n        MAX(sa.stock_level) OVER (\\n            PARTITION BY sa.product_id, sa.store_id\\n            ORDER BY sa.check_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS max_stock_30d\\n    FROM stockout_analysis sa\\n),\\nseasonal_patterns AS (\\n    -- Fifth CTE: Identify seasonal and weekly patterns\\n    SELECT\\n        sd.*,\\n        AVG(sd.stock_level) OVER (\\n            PARTITION BY sd.product_id, sd.store_id, sd.day_of_week\\n        ) AS avg_stock_by_dow,\\n        AVG(sd.stock_level) OVER (\\n            PARTITION BY sd.product_id, sd.store_id, sd.month_num\\n        ) AS avg_stock_by_month,\\n        COUNT(CASE WHEN sd.stock_status = 'out_of_stock' THEN 1 END) OVER (\\n            PARTITION BY sd.product_id, sd.store_id, sd.day_of_week\\n        ) AS stockout_count_by_dow,\\n        COUNT(CASE WHEN sd.stock_status = 'out_of_stock' THEN 1 END) OVER (\\n            PARTITION BY sd.product_id, sd.store_id, sd.month_num\\n        ) AS stockout_count_by_month\\n    FROM stockout_durations sd\\n),\\ngeographic_clustering AS (\\n    -- Sixth CTE: Analyze geographic distribution patterns\\n    SELECT\\n        sp.*,\\n        COUNT(*) OVER (PARTITION BY sp.product_id, sp.store_state\\n        ) AS store_count_by_state,\\n        AVG(sp.stock_level) OVER (\\n            PARTITION BY sp.product_id, sp.store_state\\n        ) AS avg_stock_by_state,\\n        COUNT(CASE WHEN sp.stock_status = 'out_of_stock' THEN 1 END) OVER (\\n            PARTITION BY sp.product_id, sp.store_state\\n        ) AS stockout_count_by_state,\\n        COUNT(*) OVER (PARTITION BY sp.product_id, sp.store_city, sp.store_state\\n        ) AS store_count_by_city,\\n        AVG(sp.stock_level) OVER (\\n            PARTITION BY sp.product_id, sp.store_city, sp.store_state\\n        ) AS avg_stock_by_city\\n    FROM seasonal_patterns sp\\n),\\navailability_prediction AS (\\n    -- Seventh CTE: Generate availability predictions\\n    SELECT\\n        gc.product_id,\\n        gc.product_name,\\n        gc.category,\\n        gc.store_id,\\n        gc.store_city,\\n        gc.store_state,\\n        gc.retailer_id,\\n        gc.retailer_name,\\n        gc.check_date,\\n        gc.stock_level,\\n        gc.stock_status,\\n        gc.available_quantity,\\n        gc.avg_stock_30d,\\n        gc.stock_volatility_30d,\\n        gc.min_stock_30d,\\n        gc.max_stock_30d,\\n        gc.avg_stock_by_dow,\\n        gc.avg_stock_by_month,\\n        gc.stockout_count_by_dow,\\n        gc.stockout_count_by_month,\\n        gc.store_count_by_state,\\n        gc.avg_stock_by_state,\\n        gc.stockout_count_by_state,\\n        gc.store_count_by_city,\\n        gc.avg_stock_by_city,\\n        -- Prediction calculations\\n        CASE\\n            WHEN gc.stock_level > gc.avg_stock_30d + (gc.stock_volatility_30d * 2) THEN 'high'\\n            WHEN gc.stock_level < gc.avg_stock_30d - (gc.stock_volatility_30d * 2) THEN 'low'\\n            ELSE 'normal'\\n        END AS stock_level_classification,\\n        CASE\\n            WHEN gc.stock_status = 'out_of_stock' THEN\\n                CASE\\n                    WHEN gc.stockout_duration_days > 7 THEN 'extended_outage'\\n                    WHEN gc.stockout_duration_days > 3 THEN 'moderate_outage'\\n                    ELSE 'short_outage'\\n                END\\n            ELSE 'in_stock'\\n        END AS outage_severity,\\n        -- Forecast next 7 days availability\\n        CASE\\n            WHEN gc.stock_level > 0 AND gc.stock_level > gc.avg_stock_by_dow THEN 'likely_available'\\n            WHEN gc.stock_level = 0 AND gc.stockout_count_by_dow < 2 THEN 'possibly_available'\\n            ELSE 'unlikely_available'\\n        END AS next_7d_availability_prediction,\\n        -- Confidence score\\n        CASE\\n            WHEN gc.days_tracked >= 90 AND gc.stock_volatility_30d < 10 THEN 0.95\\n            WHEN gc.days_tracked >= 60 AND gc.stock_volatility_30d < 20 THEN 0.85\\n            WHEN gc.days_tracked >= 30 THEN 0.75\\n            ELSE 0.60\\n        END AS prediction_confidence\\n    FROM geographic_clustering gc\\n)\\nSELECT\\n    product_name,\\n    category,\\n    store_city,\\n    store_state,\\n    retailer_name,\\n    check_date,\\n    stock_level,\\n    stock_status,\\n    stock_level_classification,\\n    outage_severity,\\n    next_7d_availability_prediction,\\n    ROUND(CAST(prediction_confidence AS NUMERIC), 2) AS prediction_confidence,\\n    ROUND(CAST(avg_stock_30d AS NUMERIC), 0) AS avg_stock_30d,\\n    ROUND(CAST(stock_volatility_30d AS NUMERIC), 2) AS stock_volatility_30d,\\n    avg_stock_by_dow,\\n    avg_stock_by_month,\\n    store_count_by_state,\\n    avg_stock_by_state\\nFROM availability_prediction\\nWHERE check_date >= CURRENT_DATE - INTERVAL '7 days'\\nORDER BY\\n    product_id,\\n    store_id,\\n    check_date DESC;\",\n",
    "      \"line_number\": 475,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.017986,\n",
    "        \"row_count\": 80,\n",
    "        \"column_count\": 18,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 3,\n",
    "      \"title\": \"Market Share Analysis with Competitive Positioning and Temporal Trends\",\n",
    "      \"description\": \"Description: Analyzes market share by retailer and product category, incorporating competitive positioning metrics, temporal trends, and geographic distribution. Uses multiple CTEs to calculate market share percentages, competitive rankings, share changes over time, and market concentration metrics with window functions. Use Case: Competitive market analysis for retail intelligence - identify market leaders, track share changes, and analyze competitive dynamics Business Value:\n",
    "    Enables retailers \",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), complex aggregations, window functions with frame clauses, percentile rankings, temporal comparisons, market concentration calculations\",\n",
    "      \"expected_output\": \"Market share report showing retailer rankings, share percentages, competitive positioning, and temporal trends by product category\",\n",
    "      \"sql\": \"WITH retailer_product_sales AS (\\n    SELECT\\n        r.retailer_id,\\n        r.retailer_name,\\n        r.retailer_type,\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        COUNT(DISTINCT pp.pricing_id) AS pricing_records_count,\\n        AVG(pp.current_price) AS avg_price,\\n        COUNT(DISTINCT pp.store_id) AS store_count,\\n        COUNT(DISTINCT CASE WHEN pi.stock_status = 'in_stock' THEN pi.store_id END) AS stores_in_stock,\\n        SUM(CASE WHEN pi.stock_level > 0 THEN 1 ELSE 0 END) AS inventory_units\\n    FROM retailers r\\n    INNER JOIN product_pricing pp ON r.retailer_id = pp.retailer_id\\n    INNER JOIN products p ON pp.product_id = p.product_id\\n    LEFT JOIN product_inventory pi ON pp.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE r.retailer_status = 'active' AND p.is_active = TRUE\\n    GROUP BY r.retailer_id, r.retailer_name, r.retailer_type, p.product_id, p.product_name, p.category, p.subcategory\\n),\\ncategory_market_totals AS (\\n    SELECT\\n        category,\\n        subcategory,\\n        COUNT(DISTINCT retailer_id) AS total_retailers,\\n        COUNT(DISTINCT product_id) AS total_products,\\n        SUM(pricing_records_count) AS total_pricing_records,\\n        SUM(store_count) AS total_stores,\\n        SUM(stores_in_stock) AS total_stores_in_stock,\\n        SUM(inventory_units) AS total_inventory_units\\n    FROM retailer_product_sales\\n    GROUP BY category, subcategory\\n),\\nretailer_category_share AS (\\n    SELECT\\n        rps.*,\\n        cmt.total_retailers,\\n        cmt.total_products,\\n        cmt.total_pricing_records,\\n        cmt.total_stores,\\n        cmt.total_stores_in_stock,\\n        cmt.total_inventory_units,\\n        CASE\\n            WHEN cmt.total_pricing_records > 0 THEN\\n                (rps.pricing_records_count::NUMERIC / cmt.total_pricing_records::NUMERIC) * 100\\n            ELSE 0\\n        END AS pricing_records_share,\\n        CASE\\n            WHEN cmt.total_stores > 0 THEN\\n                (rps.store_count::NUMERIC / cmt.total_stores::NUMERIC) * 100\\n            ELSE 0\\n        END AS store_count_share,\\n        CASE\\n            WHEN cmt.total_stores_in_stock > 0 THEN\\n                (rps.stores_in_stock::NUMERIC / cmt.total_stores_in_stock::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_share,\\n        CASE\\n            WHEN cmt.total_inventory_units > 0 THEN\\n                (rps.inventory_units::NUMERIC / cmt.total_inventory_units::NUMERIC) * 100\\n            ELSE 0\\n        END AS inventory_share\\n    FROM retailer_product_sales rps\\n    INNER JOIN category_market_totals cmt ON rps.category = cmt.category AND rps.subcategory = cmt.subcategory\\n),\\nmarket_share_rankings AS (\\n    SELECT\\n        rcs.*,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY rcs.category, rcs.subcategory\\n            ORDER BY rcs.pricing_records_share DESC\\n        ) AS pricing_rank,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY rcs.category, rcs.subcategory\\n            ORDER BY rcs.store_count_share DESC\\n        ) AS store_rank,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY rcs.category, rcs.subcategory\\n            ORDER BY rcs.availability_share DESC\\n        ) AS availability_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY rcs.category, rcs.subcategory\\n            ORDER BY rcs.pricing_records_share DESC\\n        ) AS pricing_percentile,\\n        NTILE(4) OVER (\\n            PARTITION BY rcs.category, rcs.subcategory\\n            ORDER BY rcs.pricing_records_share DESC\\n        ) AS market_position_quartile\\n    FROM retailer_category_share rcs\\n),\\ntemporal_share_analysis AS (\\n    SELECT\\n        msr.*,\\n        pp.price_effective_date,\\n        LAG(msr.pricing_records_share, 1) OVER (\\n            PARTITION BY msr.retailer_id, msr.product_id\\n            ORDER BY pp.price_effective_date\\n        ) AS prev_pricing_share,\\n        AVG(msr.pricing_records_share) OVER (\\n            PARTITION BY msr.retailer_id, msr.product_id\\n            ORDER BY pp.price_effective_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_share_30d,\\n        STDDEV(msr.pricing_records_share) OVER (\\n            PARTITION BY msr.retailer_id, msr.product_id\\n            ORDER BY pp.price_effective_date\\n            ROWS BETWEEN 89 PRECEDING AND CURRENT ROW\\n        ) AS share_volatility_90d\\n    FROM market_share_rankings msr\\n    INNER JOIN product_pricing pp ON msr.retailer_id = pp.retailer_id AND msr.product_id = pp.product_id\\n),\\nmarket_concentration AS (\\n    SELECT\\n        tsa.category,\\n        tsa.subcategory,\\n        COUNT(DISTINCT tsa.retailer_id) AS retailer_count,\\n        SUM(tsa.pricing_records_share) AS total_share,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY tsa.pricing_records_share) AS median_share,\\n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY tsa.pricing_records_share) AS q1_share,\\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY tsa.pricing_records_share) AS q3_share,\\n        -- Herfindahl-Hirschman Index (HHI) for market concentration\\n        SUM(POWER(tsa.pricing_records_share / 100.0, 2)) * 10000 AS hhi_index,\\n        CASE\\n            WHEN SUM(POWER(tsa.pricing_records_share / 100.0, 2)) * 10000 > 2500 THEN 'highly_concentrated'\\n            WHEN SUM(POWER(tsa.pricing_records_share / 100.0, 2)) * 10000 > 1500 THEN 'moderately_concentrated'\\n            ELSE 'competitive'\\n        END AS concentration_level\\n    FROM temporal_share_analysis tsa\\n    GROUP BY tsa.category, tsa.subcategory\\n),\\nfinal_market_share_intelligence AS (\\n    SELECT\\n        tsa.retailer_id,\\n        tsa.retailer_name,\\n        tsa.retailer_type,\\n        tsa.product_id,\\n        tsa.product_name,\\n        tsa.category,\\n        tsa.subcategory,\\n        ROUND(CAST(tsa.pricing_records_share AS NUMERIC), 2) AS pricing_records_share,\\n        ROUND(CAST(tsa.store_count_share AS NUMERIC), 2) AS store_count_share,\\n        ROUND(CAST(tsa.availability_share AS NUMERIC), 2) AS availability_share,\\n        ROUND(CAST(tsa.inventory_share AS NUMERIC), 2) AS inventory_share,\\n        tsa.pricing_rank,\\n        tsa.store_rank,\\n        tsa.availability_rank,\\n        ROUND(CAST(tsa.pricing_percentile * 100 AS NUMERIC), 2) AS pricing_percentile,\\n        tsa.market_position_quartile,\\n        CASE\\n            WHEN tsa.prev_pricing_share IS NOT NULL THEN\\n                tsa.pricing_records_share - tsa.prev_pricing_share\\n            ELSE NULL\\n        END AS share_change,\\n        CASE\\n            WHEN tsa.prev_pricing_share IS NOT NULL AND tsa.prev_pricing_share != 0 THEN\\n                ((tsa.pricing_records_share - tsa.prev_pricing_share) / tsa.prev_pricing_share) * 100\\n            ELSE NULL\\n        END AS share_change_percentage,\\n        ROUND(CAST(tsa.moving_avg_share_30d AS NUMERIC), 2) AS moving_avg_share_30d,\\n        ROUND(CAST(tsa.share_volatility_90d AS NUMERIC), 2) AS share_volatility_90d,\\n        mc.hhi_index,\\n        mc.concentration_level,\\n        CASE\\n            WHEN tsa.pricing_rank = 1 THEN 'market_leader'\\n            WHEN tsa.pricing_rank <= 3 THEN 'top_3'\\n            WHEN tsa.pricing_rank <= 5 THEN 'top_5'\\n            ELSE 'other'\\n        END AS competitive_position\\n    FROM temporal_share_analysis tsa\\n    INNER JOIN market_concentration mc ON tsa.category = mc.category AND tsa.subcategory = mc.subcategory\\n)\\nSELECT\\n    retailer_name,\\n    retailer_type,\\n    product_name,\\n    category,\\n    subcategory,\\n    pricing_records_share,\\n    store_count_share,\\n    availability_share,\\n    inventory_share,\\n    pricing_rank,\\n    competitive_position,\\n    share_change_percentage,\\n    moving_avg_share_30d,\\n    share_volatility_90d,\\n    hhi_index,\\n    concentration_level\\nFROM final_market_share_intelligence\\nWHERE pricing_rank <= 10\\nORDER BY category, subcategory, pricing_rank;\",\n",
    "      \"line_number\":\n",
    "    774,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.00661,\n",
    "        \"row_count\": 10,\n",
    "        \"column_count\": 16,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 4,\n",
    "      \"title\": \"Deal Detection and Alert Generation with Temporal Patterns\",\n",
    "      \"description\": \"Description: Detects deals and generates alerts by analyzing price changes, discount patterns, and temporal trends. Uses recursive CTEs for pattern detection, window functions for trend analysis, and complex aggregations to identify optimal deals. Use Case:\n",
    "    Automated deal detection for retail intelligence platforms Business Value: Enables consumers and retailers to identify best deals automatically, supporting $1M+ ARR deal aggregation platforms Purpose: Provides comprehensive analysis for marke\",\n",
    "      \"complexity\": \"Recursive CTEs, multiple CTEs (7+ levels), window functions with frame clauses, temporal pattern detection, discount analysis\",\n",
    "      \"expected_output\": \"Detailed analysis report with metrics and insights\",\n",
    "      \"sql\": \"WITH RECURSIVE deal_price_history AS (\\n    -- Base case: Current deal pricing\\n    SELECT\\n        da.deal_id,\\n        da.product_id,\\n        da.retailer_id,\\n        da.store_id,\\n        da.deal_type,\\n        da.discount_percentage,\\n        da.deal_price,\\n        da.original_price,\\n        da.deal_start_date,\\n        da.deal_end_date,\\n        da.deal_status,\\n        p.product_name,\\n        p.category,\\n        r.retailer_name,\\n        s.store_city,\\n        s.store_state,\\n        DATE_TRUNC('day', da.deal_start_date) AS deal_date,\\n        EXTRACT(DOW FROM da.deal_start_date) AS day_of_week\\n    FROM deal_alerts da\\n    INNER JOIN products p ON da.product_id = p.product_id\\n    INNER JOIN retailers r ON da.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON da.store_id = s.store_id\\n    WHERE da.deal_status = 'active'\\n        AND p.is_active = TRUE\\n    \\n    UNION ALL\\n    \\n    -- Recursive case: Historical price patterns\\n    SELECT\\n        dph.deal_id,\\n        dph.product_id,\\n        dph.retailer_id,\\n        dph.store_id,\\n        dph.deal_type,\\n        dph.discount_percentage,\\n        dph.deal_price,\\n        dph.original_price,\\n        dph.deal_start_date - INTERVAL '1 day' AS deal_start_date,\\n        dph.deal_end_date,\\n        dph.deal_status,\\n        dph.product_name,\\n        dph.category,\\n        dph.retailer_name,\\n        dph.store_city,\\n        dph.store_state,\\n        DATE_TRUNC('day', dph.deal_start_date - INTERVAL '1 day') AS deal_date,\\n        EXTRACT(DOW FROM dph.deal_start_date - INTERVAL '1 day') AS day_of_week\\n    FROM deal_price_history dph\\n    WHERE dph.deal_start_date > CURRENT_DATE - INTERVAL '180 days'\\n),\\nprice_change_detection AS (\\n    -- Second CTE: Detect price changes and deal triggers\\n    SELECT\\n        dph.*,\\n        pp.current_price AS current_market_price,\\n        pp.price_effective_date,\\n        CASE\\n            WHEN pp.current_price < dph.deal_price THEN 'better_deal_available'\\n            WHEN pp.current_price = dph.deal_price THEN 'price_match'\\n            ELSE 'deal_better'\\n        END AS price_comparison,\\n        ABS(pp.current_price - dph.deal_price) AS price_difference,\\n        CASE\\n            WHEN dph.deal_price < pp.current_price THEN\\n                ((pp.current_price - dph.deal_price) / pp.current_price) * 100\\n            ELSE NULL\\n        END AS savings_percentage\\n    FROM deal_price_history dph\\n    LEFT JOIN product_pricing pp ON dph.product_id = pp.product_id\\n        AND dph.retailer_id = pp.retailer_id\\n        AND pp.price_effective_date BETWEEN dph.deal_start_date AND COALESCE(dph.deal_end_date, CURRENT_DATE)\\n),\\ndeal_pattern_analysis AS (\\n    -- Third CTE: Analyze deal patterns and frequencies\\n    SELECT\\n        pcd.*,\\n        COUNT(*) OVER (\\n            PARTITION BY pcd.product_id, pcd.retailer_id\\n            ORDER BY pcd.deal_date\\n            ROWS BETWEEN 89 PRECEDING AND CURRENT ROW\\n        ) AS deals_count_90d,\\n        AVG(pcd.discount_percentage) OVER (\\n            PARTITION BY pcd.product_id, pcd.retailer_id\\n            ORDER BY pcd.deal_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS avg_discount_30d,\\n        LAG(pcd.deal_price, 1) OVER (\\n            PARTITION BY pcd.product_id, pcd.retailer_id\\n            ORDER BY pcd.deal_date\\n        ) AS prev_deal_price,\\n        LEAD(pcd.deal_price, 1) OVER (\\n            PARTITION BY pcd.product_id, pcd.retailer_id\\n            ORDER BY pcd.deal_date\\n        ) AS next_deal_price,\\n        MIN(pcd.deal_price) OVER (\\n            PARTITION BY pcd.product_id, pcd.retailer_id\\n            ORDER BY pcd.deal_date\\n            ROWS BETWEEN 89 PRECEDING AND CURRENT ROW\\n        ) AS min_deal_price_90d,\\n        MAX(pcd.deal_price) OVER (\\n            PARTITION BY pcd.product_id, pcd.retailer_id\\n            ORDER BY pcd.deal_date\\n            ROWS BETWEEN 89 PRECEDING AND CURRENT ROW\\n        ) AS max_deal_price_90d\\n    FROM price_change_detection pcd\\n),\\ndeal_alert_scoring AS (\\n    -- Fourth CTE: Score deals for alert generation\\n    SELECT\\n        dpa.*,\\n        CASE\\n            WHEN dpa.prev_deal_price IS NOT NULL THEN\\n                dpa.deal_price - dpa.prev_deal_price\\n            ELSE NULL\\n        END AS price_change_from_prev,\\n        CASE\\n            WHEN dpa.deal_price <= dpa.min_deal_price_90d * 1.05 THEN 'best_price_90d'\\n            WHEN dpa.deal_price <= dpa.min_deal_price_90d * 1.15 THEN 'near_best_price'\\n            ELSE 'regular_deal'\\n        END AS deal_quality,\\n        CASE\\n            WHEN dpa.discount_percentage >= 50 THEN 100\\n            WHEN dpa.discount_percentage >= 30 THEN 80\\n            WHEN dpa.discount_percentage >= 20 THEN 60\\n            WHEN dpa.discount_percentage >= 10 THEN 40\\n            ELSE 20\\n        END AS discount_score,\\n        CASE\\n            WHEN dpa.deals_count_90d <= 2 THEN 100\\n            WHEN dpa.deals_count_90d <= 5 THEN 80\\n            WHEN dpa.deals_count_90d <= 10 THEN 60\\n            ELSE 40\\n        END AS rarity_score,\\n        CASE\\n            WHEN dpa.savings_percentage >= 30 THEN 100\\n            WHEN dpa.savings_percentage >= 20 THEN 80\\n            WHEN dpa.savings_percentage >= 10 THEN 60\\n            ELSE 40\\n        END AS savings_score\\n    FROM deal_pattern_analysis dpa\\n),\\ntemporal_deal_trends AS (\\n    -- Fifth CTE:\n",
    "    Analyze temporal trends\\n    SELECT\\n        das.*,\\n        AVG(das.deal_price) OVER (\\n            PARTITION BY das.product_id, das.day_of_week\\n        ) AS avg_price_by_dow,\\n        AVG(das.deal_price) OVER (\\n            PARTITION BY das.product_id, EXTRACT(MONTH FROM das.deal_date)\\n        ) AS avg_price_by_month,\\n        COUNT(CASE WHEN das.deal_type = 'clearance' THEN 1 END) OVER (\\n            PARTITION BY das.product_id\\n            ORDER BY das.deal_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS clearance_count_30d,\\n        COUNT(CASE WHEN das.deal_type = 'sale' THEN 1 END) OVER (\\n            PARTITION BY das.product_id\\n            ORDER BY das.deal_date\\n            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\\n        ) AS sale_count_30d\\n    FROM deal_alert_scoring das\\n),\\nfinal_deal_intelligence AS (\\n    -- Sixth CTE: Final deal intelligence with comprehensive metrics\\n    SELECT\\n        tdt.product_id,\\n        tdt.product_name,\\n        tdt.category,\\n        tdt.retailer_id,\\n        tdt.retailer_name,\\n        tdt.store_city,\\n        tdt.store_state,\\n        tdt.deal_id,\\n        tdt.deal_type,\\n        tdt.deal_price,\\n        tdt.original_price,\\n        ROUND(CAST(tdt.discount_percentage AS NUMERIC), 2) AS discount_percentage,\\n        tdt.deal_start_date,\\n        tdt.deal_end_date,\\n        tdt.deal_quality,\\n        ROUND(CAST((tdt.discount_score + tdt.rarity_score + tdt.savings_score) / 3.0 AS NUMERIC), 2) AS overall_deal_score,\\n        tdt.price_comparison,\\n        ROUND(CAST(tdt.savings_percentage AS NUMERIC), 2) AS savings_percentage,\\n        ROUND(CAST(tdt.avg_discount_30d AS NUMERIC), 2) AS avg_discount_30d,\\n        tdt.deals_count_90d,\\n        tdt.clearance_count_30d,\\n        tdt.sale_count_30d,\\n        CASE\\n            WHEN (tdt.discount_score + tdt.rarity_score + tdt.savings_score) / 3.0 >= 80 THEN 'high_priority_alert'\\n            WHEN (tdt.discount_score + tdt.rarity_score + tdt.savings_score) / 3.0 >= 60 THEN 'medium_priority_alert'\\n            ELSE 'low_priority_alert'\\n        END AS alert_priority\\n    FROM temporal_deal_trends tdt\\n)\\nSELECT\\n    product_name,\\n    category,\\n    retailer_name,\\n    store_city,\\n    store_state,\\n    deal_type,\\n    deal_price,\\n    original_price,\\n    discount_percentage,\\n    deal_start_date,\\n    deal_end_date,\\n    deal_quality,\\n    overall_deal_score,\\n    alert_priority,\\n    savings_percentage,\\n    avg_discount_30d,\\n    deals_count_90d\\nFROM final_deal_intelligence\\nWHERE overall_deal_score >= 60\\nORDER BY overall_deal_score DESC, deal_start_date DESC;\",\n",
    "      \"line_number\": 987,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.015857,\n",
    "        \"row_count\": 14,\n",
    "        \"column_count\": 17,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 5,\n",
    "      \"title\": \"Product Category Trend Analysis with Seasonal Decomposition\",\n",
    "      \"description\": \"Description: Analyzes product category trends with seasonal decomposition, identifying cyclical patterns, growth trends, and category performance metrics. Uses multiple CTEs for trend decomposition, window functions for seasonal analysis, and statistical calculations. Use Case:\n",
    "    Category performance analysis for retail strategy Business Value: Enables retailers to understand category trends and optimize product mix, supporting $1M+ ARR retail analytics platforms Purpose: Provides comprehensive an\",\n",
    "      \"complexity\": \"Multiple CTEs (8+ levels), seasonal decomposition, window functions with RANGE frames, trend analysis, statistical calculations\",\n",
    "      \"expected_output\": \"Detailed analysis report with metrics and insights\",\n",
    "      \"sql\": \"WITH category_sales_base AS (\\n    SELECT\\n        p.category,\\n        p.subcategory,\\n        p.product_id,\\n        p.product_name,\\n        pp.price_effective_date,\\n        DATE_TRUNC('month', pp.price_effective_date) AS sale_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num,\\n        EXTRACT(QUARTER FROM pp.price_effective_date) AS quarter_num,\\n        pp.current_price,\\n        pp.price_type,\\n        COUNT(DISTINCT pp.store_id) AS store_count,\\n        COUNT(DISTINCT pp.retailer_id) AS retailer_count\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    WHERE pp.price_effective_date >= CURRENT_DATE - INTERVAL '2 years'\\n        AND p.is_active = TRUE\\n    GROUP BY p.category, p.subcategory, p.product_id, p.product_name, pp.price_effective_date, pp.current_price, pp.price_type\\n),\\nmonthly_category_aggregates AS (\\n    SELECT\\n        category,\\n        subcategory,\\n        sale_month,\\n        month_num,\\n        quarter_num,\\n        COUNT(DISTINCT product_id) AS products_count,\\n        SUM(retailer_count) AS retailers_count,\\n        SUM(store_count) AS total_stores,\\n        AVG(current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY current_price) AS median_price,\\n        MIN(current_price) AS min_price,\\n        MAX(current_price) AS max_price,\\n        STDDEV(current_price) AS price_std_dev,\\n        COUNT(CASE WHEN price_type = 'sale' THEN 1 END) AS sale_count,\\n        COUNT(CASE WHEN price_type = 'clearance' THEN 1 END) AS clearance_count\\n    FROM category_sales_base\\n    GROUP BY category, subcategory, sale_month, month_num, quarter_num\\n),\\nseasonal_decomposition AS (\\n    SELECT\\n        mca.*,\\n        AVG(mca.avg_price) OVER (\\n            PARTITION BY mca.category, mca.subcategory\\n            ORDER BY mca.sale_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        AVG(mca.avg_price) OVER (\\n            PARTITION BY mca.category, mca.subcategory, mca.month_num\\n        ) AS seasonal_avg_by_month,\\n        mca.avg_price - AVG(mca.avg_price) OVER (\\n            PARTITION BY mca.category, mca.subcategory, mca.month_num\\n        ) AS seasonal_component,\\n        LAG(mca.avg_price, 12) OVER (\\n            PARTITION BY mca.category, mca.subcategory\\n            ORDER BY mca.sale_month\\n        ) AS year_ago_price,\\n        LEAD(mca.avg_price, 12) OVER (\\n            PARTITION BY mca.category, mca.subcategory\\n            ORDER BY mca.sale_month\\n        ) AS year_ahead_price\\n    FROM monthly_category_aggregates mca\\n),\\ntrend_analysis AS (\\n    SELECT\\n        sd.*,\\n        CASE\\n            WHEN sd.year_ago_price IS NOT NULL THEN\\n                ((sd.avg_price - sd.year_ago_price) / sd.year_ago_price) * 100\\n            ELSE NULL\\n        END AS yoy_price_change,\\n        AVG(sd.avg_price) OVER (\\n            PARTITION BY sd.category, sd.subcategory\\n            ORDER BY sd.sale_month\\n            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_3m,\\n        STDDEV(sd.avg_price) OVER (\\n            PARTITION BY sd.category, sd.subcategory\\n            ORDER BY sd.sale_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY sd.category, sd.subcategory\\n            ORDER BY sd.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY sd.category, sd.subcategory\\n            ORDER BY sd.avg_price DESC\\n        ) AS price_percentile\\n    FROM seasonal_decomposition sd\\n),\\ncategory_performance_metrics AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.yoy_price_change > 5 THEN 'strong_growth'\\n            WHEN ta.yoy_price_change > 0 THEN 'moderate_growth'\\n            WHEN ta.yoy_price_change > -5 THEN 'stable'\\n            WHEN ta.yoy_price_change > -10 THEN 'moderate_decline'\\n            ELSE 'strong_decline'\\n        END AS trend_classification,\\n        CASE\\n            WHEN ta.price_volatility_12m < ta.avg_price * 0.1 THEN 'low_volatility'\\n            WHEN ta.price_volatility_12m < ta.avg_price * 0.2 THEN 'moderate_volatility'\\n            ELSE 'high_volatility'\\n        END AS volatility_classification,\\n        ta.sale_count + ta.clearance_count AS total_promotions,\\n        CASE\\n            WHEN ta.sale_count + ta.clearance_count > ta.products_count * 0.5 THEN 'high_promotion'\\n            WHEN ta.sale_count + ta.clearance_count > ta.products_count * 0.25 THEN 'moderate_promotion'\\n            ELSE 'low_promotion'\\n        END AS promotion_level\\n    FROM trend_analysis ta\\n),\\nfinal_category_intelligence AS (\\n    SELECT\\n        cpm.category,\\n        cpm.subcategory,\\n        cpm.sale_month,\\n        cpm.month_num,\\n        cpm.quarter_num,\\n        ROUND(CAST(cpm.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(cpm.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(cpm.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(cpm.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(cpm.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(cpm.seasonal_component AS NUMERIC), 2) AS seasonal_component,\\n        ROUND(CAST(cpm.yoy_price_change AS NUMERIC), 2) AS yoy_price_change,\\n        ROUND(CAST(cpm.moving_avg_3m AS NUMERIC), 2) AS moving_avg_3m,\\n        ROUND(CAST(cpm.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        cpm.trend_classification,\\n        cpm.volatility_classification,\\n        cpm.promotion_level,\\n        cpm.products_count,\\n        cpm.retailers_count,\\n        cpm.total_stores,\\n        cpm.sale_count,\\n        cpm.clearance_count,\\n        cpm.total_promotions\\n    FROM category_performance_metrics cpm\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    sale_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    seasonal_component,\\n    yoy_price_change,\\n    trend_classification,\\n    volatility_classification,\\n    promotion_level,\\n    products_count,\\n    retailers_count,\\n    total_promotions\\nFROM final_category_intelligence\\nWHERE sale_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, sale_month DESC;\",\n",
    "      \"line_number\": 1225,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006889,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 6,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 6\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 1402,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.007628,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 7,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 7\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 1577,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006769,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 8,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 8\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 1753,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.007265,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 9,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 9\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 1929,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006293,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 10,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 10\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 2105,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006798,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 11,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 11\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 2281,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.007299,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 12,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 12\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 2457,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006599,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 13,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 13\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 2633,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.016642,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 14,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 14\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 2809,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.012253,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 15,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 15\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 2985,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006488,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 16,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 16\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 3161,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.009664,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 17,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 17\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 3337,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.019719,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 18,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 18\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 3513,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.034263,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 19,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 19\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 3689,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.007766,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 20,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 20\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 3865,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006694,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 21,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 21\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 4041,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.008384,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 22,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 22\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 4217,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006888,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 23,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 23\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 4393,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.007253,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 24,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 24\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 4569,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006461,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 25,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 25\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 4745,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006269,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 26,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 26\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 4921,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.007061,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 27,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 27\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 5097,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.008649,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 28,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 28\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 5273,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.007428,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 29,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 29\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 5449,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006432,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"number\": 30,\n",
    "      \"title\": \"Marketing Intelligence Analysis Query 30\",\n",
    "      \"description\": \"Description: Comprehensive marketing intelligence analysis with multiple CTEs, window functions, and complex aggregations. Use Case: Marketing intelligence for retail operations Business Value:\n",
    "    Supports $1M+ ARR marketing intelligence platforms Purpose: Provides detailed marketing intelligence analysis Complexity: Multiple CTEs (6+ levels), window functions, complex aggregations Expected Output: Analysis report with comprehensive metrics\",\n",
    "      \"complexity\": \"Multiple CTEs (6+ levels), window functions, complex aggregations\",\n",
    "      \"expected_output\": \"Analysis report with comprehensive metrics\",\n",
    "      \"sql\": \"WITH base_analysis AS (\\n    SELECT\\n        p.product_id,\\n        p.product_name,\\n        p.category,\\n        p.subcategory,\\n        p.brand,\\n        pp.pricing_id,\\n        pp.retailer_id,\\n        pp.current_price,\\n        pp.price_effective_date,\\n        r.retailer_name,\\n        r.retailer_type,\\n        s.store_id,\\n        s.store_city,\\n        s.store_state,\\n        pi.stock_level,\\n        pi.stock_status,\\n        DATE_TRUNC('month', pp.price_effective_date) AS price_month,\\n        EXTRACT(MONTH FROM pp.price_effective_date) AS month_num\\n    FROM products p\\n    INNER JOIN product_pricing pp ON p.product_id = pp.product_id\\n    INNER JOIN retailers r ON pp.retailer_id = r.retailer_id\\n    LEFT JOIN stores s ON pp.store_id = s.store_id\\n    LEFT JOIN product_inventory pi ON p.product_id = pi.product_id AND pp.store_id = pi.store_id\\n    WHERE p.is_active = TRUE\\n        AND r.retailer_status = 'active'\\n        AND pp.price_effective_date >= CURRENT_DATE - INTERVAL '180 days'\\n),\\naggregated_metrics AS (\\n    SELECT\\n        ba.category,\\n        ba.subcategory,\\n        ba.brand,\\n        ba.price_month,\\n        ba.month_num,\\n        COUNT(DISTINCT ba.product_id) AS products_count,\\n        COUNT(DISTINCT ba.retailer_id) AS retailers_count,\\n        COUNT(DISTINCT ba.store_id) AS stores_count,\\n        AVG(ba.current_price) AS avg_price,\\n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ba.current_price) AS median_price,\\n        MIN(ba.current_price) AS min_price,\\n        MAX(ba.current_price) AS max_price,\\n        STDDEV(ba.current_price) AS price_std_dev,\\n        COUNT(CASE WHEN ba.stock_status = 'in_stock' THEN 1 END) AS in_stock_count,\\n        COUNT(CASE WHEN ba.stock_status = 'out_of_stock' THEN 1 END) AS out_of_stock_count\\n    FROM base_analysis ba\\n    GROUP BY ba.category, ba.subcategory, ba.brand, ba.price_month, ba.month_num\\n),\\ntemporal_analysis AS (\\n    SELECT\\n        am.*,\\n        LAG(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS prev_month_avg_price,\\n        LEAD(am.avg_price, 1) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n        ) AS next_month_avg_price,\\n        AVG(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS moving_avg_12m,\\n        STDDEV(am.avg_price) OVER (\\n            PARTITION BY am.category, am.subcategory, am.brand\\n            ORDER BY am.price_month\\n            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW\\n        ) AS price_volatility_12m\\n    FROM aggregated_metrics am\\n),\\ntrend_calculations AS (\\n    SELECT\\n        ta.*,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL THEN\\n                ((ta.avg_price - ta.prev_month_avg_price) / ta.prev_month_avg_price) * 100\\n            ELSE NULL\\n        END AS mom_price_change,\\n        CASE\\n            WHEN ta.prev_month_avg_price IS NOT NULL AND ta.prev_month_avg_price != 0 THEN\\n                ta.avg_price - ta.prev_month_avg_price\\n            ELSE NULL\\n        END AS price_change_amount,\\n        CASE\\n            WHEN ta.in_stock_count > 0 THEN\\n                (ta.in_stock_count::NUMERIC / (ta.in_stock_count + ta.out_of_stock_count)::NUMERIC) * 100\\n            ELSE 0\\n        END AS availability_rate\\n    FROM temporal_analysis ta\\n),\\nmarket_intelligence AS (\\n    SELECT\\n        tc.*,\\n        CASE\\n            WHEN tc.mom_price_change > 5 THEN 'strong_increase'\\n            WHEN tc.mom_price_change > 0 THEN 'moderate_increase'\\n            WHEN tc.mom_price_change > -5 THEN 'stable'\\n            WHEN tc.mom_price_change > -10 THEN 'moderate_decrease'\\n            ELSE 'strong_decrease'\\n        END AS price_trend,\\n        CASE\\n            WHEN tc.availability_rate >= 80 THEN 'high_availability'\\n            WHEN tc.availability_rate >= 50 THEN 'moderate_availability'\\n            ELSE 'low_availability'\\n        END AS availability_classification,\\n        ROW_NUMBER() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_rank,\\n        PERCENT_RANK() OVER (\\n            PARTITION BY tc.category, tc.subcategory\\n            ORDER BY tc.avg_price DESC\\n        ) AS price_percentile\\n    FROM trend_calculations tc\\n),\\nfinal_analysis AS (\\n    SELECT\\n        mi.category,\\n        mi.subcategory,\\n        mi.brand,\\n        mi.price_month,\\n        ROUND(CAST(mi.avg_price AS NUMERIC), 2) AS avg_price,\\n        ROUND(CAST(mi.median_price AS NUMERIC), 2) AS median_price,\\n        ROUND(CAST(mi.min_price AS NUMERIC), 2) AS min_price,\\n        ROUND(CAST(mi.max_price AS NUMERIC), 2) AS max_price,\\n        ROUND(CAST(mi.moving_avg_12m AS NUMERIC), 2) AS moving_avg_12m,\\n        ROUND(CAST(mi.mom_price_change AS NUMERIC), 2) AS mom_price_change,\\n        ROUND(CAST(mi.price_volatility_12m AS NUMERIC), 2) AS price_volatility_12m,\\n        ROUND(CAST(mi.availability_rate AS NUMERIC), 2) AS availability_rate,\\n        mi.price_trend,\\n        mi.availability_classification,\\n        mi.products_count,\\n        mi.retailers_count,\\n        mi.stores_count,\\n        mi.price_rank,\\n        ROUND(CAST(mi.price_percentile * 100 AS NUMERIC), 2) AS price_percentile\\n    FROM market_intelligence mi\\n)\\nSELECT\\n    category,\\n    subcategory,\\n    brand,\\n    price_month,\\n    avg_price,\\n    median_price,\\n    moving_avg_12m,\\n    mom_price_change,\\n    price_trend,\\n    availability_rate,\\n    availability_classification,\\n    products_count,\\n    retailers_count,\\n    price_percentile\\nFROM final_analysis\\nWHERE price_month >= CURRENT_DATE - INTERVAL '12 months'\\nORDER BY category, subcategory, brand, price_month DESC;\",\n",
    "      \"line_number\": 5625,\n",
    "      \"execution\": {\n",
    "        \"success\": true,\n",
    "        \"execution_time_seconds\": 0.006509,\n",
    "        \"row_count\": 8,\n",
    "        \"column_count\": 14,\n",
    "        \"tested_at\": \"2026-02-08T21:06:12.984360\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"execution_test_results\": {\n",
    "    \"test_timestamp\": \"2026-02-08T21:06:12.984360\",\n",
    "    \"total_queries\": 30,\n",
    "    \"passed\": 30,\n",
    "    \"failed\": 0,\n",
    "    \"success_rate\": 100.0,\n",
    "    \"average_execution_time\": 0.009882300000000002,\n",
    "    \"total_execution_time\": 0.29646900000000004\n",
    "  }\n",
    "}\n",
    "# Extract queries list\n",
    "queries = QUERIES_DATA.get('queries', [])\n",
    "total_queries = len(queries)\n",
    "print(\"=\"*80)\n",
    "print(\"EMBEDDED QUERIES LOADED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Queries: {total_queries}\")\n",
    "print(f\"Source: Embedded in notebook (no file dependency)\")\n",
    "if queries:\n",
    "    print(f\"\\nQuery Overview:\")\n",
    "    for q in queries[:5]:\n",
    "        title = q.get('title', 'N/A')[:60]\n",
    "        print(f\"  Query {q.get('number')}: {title}...\")\n",
    "    if total_queries > 5:\n",
    "    print(f\"  ... and {total_queries - 5} more queries\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ Queries ready to execute!\")\n",
    "print(\"=\"*80)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD QUERIES (FROM EMBEDDED DATA)\n",
    "# ============================================================================\n",
    "# Queries are already loaded from embedded QUERIES_DATA cell above\n",
    "# If not loaded, use the embedded queries cell\n",
    "if 'queries' not in globals():\n",
    "    print(\"‚ö†Ô∏è  Queries not found. Run the 'Embedded Queries' cell first.\")\n",
    "    print(\"   Looking for embedded queries...\")\n",
    "    # Try to find embedded queries\n",
    "    for cell_num in range(len(notebook['cells'])):\n",
    "    cell_text = ''.join(notebook['cells'][cell_num].get('source', []))\n",
    "        if 'EMBEDDED QUERIES.JSON' in cell_text or 'QUERIES_DATA' in cell_text:\n",
    "    print(f\"   ‚úÖ Found embedded queries in cell\")\n",
    "            break\n",
    "else:\n",
    "    print(\"=\"*80)\n",
    "    print(\"QUERIES LOADED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total Queries: {len(queries)}\")\n",
    "    if queries:\n",
    "    print(f\"\\nQuery Overview:\")\n",
    "        for q in queries[:5]:\n",
    "            title = q.get('title', 'N/A')[:60]\n",
    "            print(f\"  Query {q.get('number')}: {title}...\")\n",
    "        if len(queries) > 5:\n",
    "    print(f\"  ... and {len(queries) - 5} more queries\")\n",
    "    print(\"=\"*80)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Query Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================# POSTGRESQL DATABASE CONNECTION (Colab Only)# ============================================================================import psycopg2from pathlib import Path# Database nameDB_NAME = \"db-10\"def create_postgresql_connection():        \"\"\"Create PostgreSQL connection for Colab.\"\"\"    if not IS_COLAB:\n",
    "    raise RuntimeError(\"This notebook requires Google Colab\")        # Colab PostgreSQL defaults    try:\n",
    "    conn = psycopg2.connect(            host='localhost',            port=5432,            user='postgres',            password='postgres',  # Default Colab PostgreSQL password            database='postgres'  # Connect to default database first        )        print(\"‚úÖ Connected to PostgreSQL\")        return conn    except Exception as e:\n",
    "    print(f\"‚ùå PostgreSQL connection failed: {e}\")        print(\"\\nTroubleshooting:\")        print(\"1. Make sure PostgreSQL is installed (run the installation cell above)\")        print(\"2. Check if PostgreSQL service is running:     !service postgresql status\")        print(\"3. Try restarting PostgreSQL: !service postgresql restart\")        raise# Create connectionconn = create_postgresql_connection()print(f\"\\nDatabase connection: PostgreSQL (Colab)\")print(f\"Host: localhost\")\n",
    "print(f\"Port: 5432\")print(f\"User: postgres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Execute All Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Query Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUERY EXECUTION FUNCTION WITH METRICS\n",
    "# ============================================================================\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def execute_query_with_metrics(db_name: str, query_sql: str, query_num: int, db_config: dict = None):\n",
    "    \"\"\"\n",
    "    Execute SQL query with metrics collection.\n",
    "    \n",
    "    Args:\n",
    "        db_name: Database name\n",
    "        query_sql: SQL query string\n",
    "        query_num: Query number\n",
    "        db_config: Database configuration (optional, uses global conn if None)\n",
    "    \n",
    "    Returns:\n",
    "    dict: Query execution results with metrics\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'query_number': query_num,\n",
    "        'success': False,\n",
    "        'execution_time': 0.0,\n",
    "        'row_count': 0,\n",
    "        'column_count': 0,\n",
    "        'dataframe': None,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "    # Use global connection if db_config not provided\n",
    "        if db_config is None:\n",
    "    # Use the global conn variable\n",
    "            if 'conn' not in globals():\n",
    "    raise RuntimeError(\"Database connection not available. Run connection cell first.\")\n",
    "            exec_conn = globals()['conn']\n",
    "        else:\n",
    "            # Create new connection from config\n",
    "            exec_conn = psycopg2.connect(**db_config)\n",
    "        \n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Execute query\n",
    "        cursor = exec_conn.cursor()\n",
    "        cursor.execute(query_sql)\n",
    "        \n",
    "        # Fetch results\n",
    "        columns = [desc[0] for desc in cursor.description] if cursor.description else []\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        # Calculate execution time\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Create DataFrame\n",
    "        if rows and columns:\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "        \n",
    "        # Update result\n",
    "        result['success'] = True\n",
    "        result['execution_time'] = execution_time\n",
    "        result['row_count'] = len(df)\n",
    "        result['column_count'] = len(columns)\n",
    "        result['dataframe'] = df\n",
    "        \n",
    "        # Close cursor\n",
    "        cursor.close()\n",
    "        \n",
    "        # Close connection if we created it\n",
    "        if db_config is not None:\n",
    "    exec_conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "    result['success'] = False\n",
    "        result['error'] = str(e)\n",
    "        result['execution_time'] = time.time() - start_time if 'start_time' in locals() else 0.0\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Database configuration (for reference, uses global conn by default)\n",
    "DB_CONFIG = {\n",
    "    'host':\n",
    "    'localhost',\n",
    "    'port': 5432,\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "    'database': 'postgres'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Query execution function loaded\")\n",
    "print(\"   Function: execute_query_with_metrics(db_name, query_sql, query_num, db_config=None)\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTE ALL QUERIES - END-TO-END TESTING\n",
    "# ============================================================================\n",
    "\n",
    "all_results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXECUTING ALL QUERIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for query_info in queries:\n",
    "    query_num = query_info.get('number')\n",
    "    query_sql = query_info.get('sql', '')\n",
    "    query_title = query_info.get('title', f'Query {query_num}')\n",
    "    \n",
    "    result = execute_query_with_metrics(DB_NAME, query_sql, query_num, DB_CONFIG)\n",
    "    result['query_number'] = query_num\n",
    "    result['query_title'] = query_title\n",
    "    result['query_info'] = query_info\n",
    "    \n",
    "    all_results.append(result)\n",
    "    \n",
    "    status = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
    "    print(f\"{status} Query {query_num:2d}: {query_title[:50]:<50} ({result['execution_time']:.3f}s, {result['row_count']:4d} rows)\")\n",
    "\n",
    "# Summary\n",
    "passed = sum(1 for r in all_results if r['success'])\n",
    "failed = sum(1 for r in all_results if not r['success'])\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"EXECUTION SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total Queries:\n",
    "    {total_queries}\")\n",
    "print(f\"Passed: {passed}\")\n",
    "print(f\"Failed: {failed}\")\n",
    "print(f\"Success Rate: {passed/total_queries*100:.1f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pdimport matplotlib.pyplot as plt# ============================================================================\n",
    "# PERFORMANCE VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# Create performance metrics DataFrame\n",
    "perf_data = []\n",
    "for r in all_results:\n",
    "    perf_data.append({\n",
    "        'Query': r['query_number'],\n",
    "        'Title': r['query_title'][:40] + '...' if len(r['query_title']) > 40 else r['query_title'],\n",
    "        'Execution Time (s)':\n",
    "    r['execution_time'],\n",
    "        'Row Count': r['row_count'],\n",
    "        'Column Count': r['column_count'],\n",
    "        'Status': 'Passed' if r['success'] else 'Failed'\n",
    "    })\n",
    "\n",
    "perf_df = pd.DataFrame(perf_data)\n",
    "\n",
    "# Visualization:\n",
    "    Execution Time Distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Execution time bar chart\n",
    "axes[0, 0].bar(perf_df['Query'], perf_df['Execution Time (s)'], color='steelblue', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Query Number')\n",
    "axes[0, 0].set_ylabel('Execution Time (seconds)')\n",
    "axes[0, 0].set_title('Query Execution Time by Query Number')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Execution time histogram\n",
    "axes[0, 1].hist(perf_df['Execution Time (s)'], bins=20, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Execution Time (seconds)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Execution Times')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Row count bar chart\n",
    "axes[1, 0].bar(perf_df['Query'], perf_df['Row Count'], color='green', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Query Number')\n",
    "axes[1, 0].set_ylabel('Row Count')\n",
    "axes[1, 0].set_title('Rows Returned by Query')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Status pie chart\n",
    "status_counts = perf_df['Status'].value_counts()\n",
    "axes[1, 1].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 1].set_title('Query Execution Status')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display performance summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Average execution time: {perf_df['Execution Time (s)'].mean():.3f}s\")\n",
    "print(f\"Median execution time: {perf_df['Execution Time (s)'].median():.3f}s\")\n",
    "print(f\"Max execution time: {perf_df['Execution Time (s)'].max():.3f}s\")\n",
    "print(f\"Min execution time: {perf_df['Execution Time (s)'].min():.3f}s\")\n",
    "print(f\"Total rows returned: {perf_df['Row Count'].sum():,}\")\n",
    "print(f\"Average rows per query: {perf_df['Row Count'].mean():.1f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Individual Query Documentation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as npimport matplotlib.pyplot as pltimport seaborn as snsfrom IPython.display import display, HTML, Markdown# ============================================================================\n",
    "# INDIVIDUAL QUERY DOCUMENTATION AND VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def document_and_visualize_query(query_result: dict, query_num: int):\n",
    "    \"\"\"Create comprehensive documentation and visualization for a single query.\"\"\"\n",
    "    query_info = query_result['query_info']\n",
    "    \n",
    "    # Create markdown documentation\n",
    "    doc = f\"\"\"\n",
    "## Query {query_num}:\n",
    "    {query_info.get('title', 'N/A')}\n",
    "\n",
    "### Execution Status\n",
    "- **Status:** {'‚úÖ PASSED' if query_result['success'] else '‚ùå FAILED'}\n",
    "- **Execution Time:** {query_result['execution_time']:.3f} seconds\n",
    "- **Rows Returned:** {query_result['row_count']:,}\n",
    "- **Columns Returned:** {query_result['column_count']}\n",
    "\n",
    "### Query Information\n",
    "- **Description:** {query_info.get('description', 'N/A')[:300]}...\n",
    "- **Use Case:** {query_info.get('use_case', 'N/A')}\n",
    "- **Business Value:** {query_info.get('business_value', 'N/A')}\n",
    "- **Complexity:** {query_info.get('complexity', 'N/A')}\n",
    "- **Expected Output:** {query_info.get('expected_output', 'N/A')}\n",
    "\n",
    "### SQL Query\n",
    "```sql\n",
    "{query_info.get('sql', '')[:1000]}...\n",
    "```\n",
    "\n",
    "### Results Preview\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "    display(Markdown(doc))\n",
    "    except:\n",
    "        print(doc)\n",
    "    \n",
    "    if query_result['success'] and query_result['dataframe'] is not None:\n",
    "    df = query_result['dataframe']\n",
    "        \n",
    "        if len(df) > 0:\n",
    "    print(f\"\\nFirst 10 rows of Query {query_num}:\")\n",
    "            try:\n",
    "    display(df.head(10))\n",
    "            except:\n",
    "                print(df.head(10).to_string())\n",
    "            \n",
    "            # Create visualizations if numeric data exists\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            if len(numeric_cols) > 0:\n",
    "    num_plots = min(3, len(numeric_cols))\n",
    "                fig, axes = plt.subplots(1, num_plots, figsize=(15, 4))\n",
    "                if num_plots == 1:\n",
    "    axes = [axes]\n",
    "                \n",
    "                for idx, col in enumerate(numeric_cols[:num_plots]):\n",
    "                    if df[col].notna().sum() > 0:\n",
    "    axes[idx].hist(df[col].dropna(), bins=min(20, len(df)), alpha=0.7, edgecolor='black')\n",
    "                        axes[idx].set_title(f'Distribution of {col[:30]}')\n",
    "                        axes[idx].set_xlabel(col[:30])\n",
    "                        axes[idx].set_ylabel('Frequency')\n",
    "                        axes[idx].grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Create correlation heatmap if multiple numeric columns\n",
    "                if len(numeric_cols) > 1:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "                    corr_matrix = df[numeric_cols].corr()\n",
    "                    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax)\n",
    "                    ax.set_title('Correlation Matrix of Numeric Columns')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "        else:\n",
    "            print(f\"\\nQuery {query_num} returned 0 rows.\")\n",
    "    else:\n",
    "        if query_result.get('error'):\n",
    "    print(f\"\\n‚ùå Error: {query_result['error'][:500]}\")\n",
    "\n",
    "# Document and visualize each query\n",
    "print(\"=\"*80)\n",
    "print(\"INDIVIDUAL QUERY DOCUMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for query_result in all_results:\n",
    "    query_num = query_result['query_number']\n",
    "    document_and_visualize_query(query_result, query_num)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Comprehensive Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GENERATE COMPREHENSIVE REPORT\n",
    "# ============================================================================\n",
    "\n",
    "# Create comprehensive report\n",
    "report_data = {\n",
    "    'database': DB_NAME,\n",
    "    'test_timestamp': datetime.now().isoformat(),\n",
    "    'total_queries': total_queries,\n",
    "    'passed': passed,\n",
    "    'failed': failed,\n",
    "    'success_rate': passed / total_queries * 100 if total_queries > 0 else 0,\n",
    "    'average_execution_time':\n",
    "    perf_df['Execution Time (s)'].mean(),\n",
    "    'total_execution_time': perf_df['Execution Time (s)'].sum(),\n",
    "    'queries': []\n",
    "}\n",
    "\n",
    "for r in all_results:\n",
    "    query_report = {\n",
    "        'number': r['query_number'],\n",
    "        'title': r['query_title'],\n",
    "        'success': r['success'],\n",
    "        'execution_time': r['execution_time'],\n",
    "        'row_count': r['row_count'],\n",
    "        'column_count': r['column_count'],\n",
    "        'columns': r['columns']\n",
    "    }\n",
    "    if not r['success']:\n",
    "    query_report['error'] = r['error']\n",
    "    \n",
    "    report_data['queries'].append(query_report)\n",
    "\n",
    "# Save report\n",
    "report_file = DB_DIR / 'results' / f'{DB_NAME}_comprehensive_report.json'\n",
    "report_file.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(report_data, f, indent=2, default=str)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE TEST REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Database: {DB_NAME}\")\n",
    "print(f\"Total Queries: {total_queries}\")\n",
    "print(f\"Passed: {passed}\")\n",
    "print(f\"Failed: {failed}\")\n",
    "print(f\"Success Rate: {passed/total_queries*100:.1f}%\")\n",
    "print(f\"Average Execution Time: {perf_df['Execution Time (s)'].mean():.3f}s\")\n",
    "print(f\"Total Execution Time: {perf_df['Execution Time (s)'].sum():.3f}s\")\n",
    "print(f\"\\n‚úÖ Report saved to: {report_file}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"END-TO-END TESTING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Database '{DB_NAME}' initialized and tested\")\n",
    "print(f\"‚úÖ All {total_queries} queries executed\")\n",
    "print(f\"‚úÖ Performance metrics collected\")\n",
    "print(f\"‚úÖ Comprehensive report generated\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2",
   "version_info": [
    3,
    14,
    2
   ]
  },
  "python_version": "3.14.2",
  "python_executable": "python3"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}